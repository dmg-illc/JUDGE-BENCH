{"Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.9163386938250186, "spearman": 0.9057009496514822, "kendall": 0.8468429502522921}, "p_value": {"pearson": 4.708185282657675e-77, "spearman": 2.300216518697228e-72, "kendall": 9.857620545445508e-38}, "kappa_score": 0.5348628556780313, "total_responses": 200, "valid_responses": 191, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6426414884734983, "spearman": 0.7236480677268118, "kendall": 0.664181279148308}, "p_value": {"pearson": 3.6007852052111463e-23, "spearman": 1.296967689364478e-31, "kendall": 9.091940905415187e-24}, "kappa_score": 0.3936624907885041, "total_responses": 200, "valid_responses": 187, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.2878721294339304, "spearman": -0.2878721294339304, "kendall": -0.2878721294339304}, "p_value": {"pearson": 8.508653065503626e-05, "spearman": 8.50865306550362e-05, "kendall": 0.00011236595725207856}, "kappa_score": -0.27989915759699935, "total_responses": 200, "valid_responses": 181, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.470199507048237, "spearman": -0.47019950704823704, "kendall": -0.470199507048237}, "p_value": {"pearson": 1.2756755546716608e-11, "spearman": 1.2756755546716758e-11, "kendall": 1.6012265532244488e-10}, "kappa_score": -0.3056050288108958, "total_responses": 200, "valid_responses": 186, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.7521945503019912, "spearman": 0.7430548808792762, "kendall": 0.6799116984008109}, "p_value": {"pearson": 1.5450571893014506e-37, "spearman": 3.3097740233360724e-36, "kendall": 6.291055889444376e-26}, "kappa_score": 0.42288211747406257, "total_responses": 200, "valid_responses": 199, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.39784097537485774, "spearman": 0.5277244027306793, "kendall": 0.4788166254415575}, "p_value": {"pearson": 7.728197492877348e-09, "spearman": 1.9003729445043315e-15, "kendall": 1.9952826726028956e-13}, "kappa_score": 0.25114155251141557, "total_responses": 200, "valid_responses": 196, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.19408799236753382, "spearman": 0.19408799236753388, "kendall": 0.1940879923675339}, "p_value": {"pearson": 0.0058898684682697384, "spearman": 0.005889868468269695, "kendall": 0.006182383826982369}, "kappa_score": 0.07260524710189131, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.19611892360293892, "spearman": -0.19611892360293895, "kendall": -0.19611892360293898}, "p_value": {"pearson": 0.005500152597526355, "spearman": 0.0055001525975263196, "kendall": 0.005786546484787551}, "kappa_score": -0.18540580789277739, "total_responses": 200, "valid_responses": 199, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6299229129863825, "spearman": 0.6673243399505956, "kendall": 0.6118725128174439}, "p_value": {"pearson": 2.739712933554335e-23, "spearman": 6.986502147545126e-27, "kendall": 1.5200271302653354e-21}, "kappa_score": 0.33790476190476193, "total_responses": 200, "valid_responses": 198, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3792523499376237, "spearman": 0.48933533127906037, "kendall": 0.44701904608645315}, "p_value": {"pearson": 6.286246323432027e-08, "spearman": 6.810920710003792e-13, "kendall": 1.1059499944160518e-11}, "kappa_score": 0.31552718517274203, "total_responses": 200, "valid_responses": 191, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.7028084895534912, "spearman": 0.7028084895534912, "kendall": 0.7028084895534912}, "p_value": {"pearson": 8.279766089101102e-31, "spearman": 8.279766089101132e-31, "kendall": 5.939600226846945e-23}, "kappa_score": 0.6987283990870558, "total_responses": 200, "valid_responses": 198, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.10794636487357348, "spearman": 0.10794636487357351, "kendall": 0.10794636487357348}, "p_value": {"pearson": 0.14469108115986548, "spearman": 0.14469108115986531, "kendall": 0.14421551072179195}, "kappa_score": 0.0522979397781298, "total_responses": 200, "valid_responses": 184, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5710457022852578, "spearman": 0.5831578466203874, "kendall": 0.5384153784092086}, "p_value": {"pearson": 1.0553445630157983e-18, "spearman": 1.2979104314198076e-19, "kendall": 6.841592086823335e-17}, "kappa_score": 0.4085974048901051, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3297756995955432, "spearman": 0.3994078256189236, "kendall": 0.3708192142531759}, "p_value": {"pearson": 1.855336868553417e-06, "spearman": 4.6637874283647334e-09, "kendall": 1.0930560502192526e-08}, "kappa_score": 0.23664122137404575, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.5017524257233199, "spearman": -0.5017524257233199, "kendall": -0.5017524257233199}, "p_value": {"pearson": 3.7726563069502465e-14, "spearman": 3.772656306950238e-14, "kendall": 1.4615585777370912e-12}, "kappa_score": -0.47928994082840237, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 200, "valid_responses": 199, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.9227792404094046, "spearman": 0.90929629911552, "kendall": 0.8444791496717573}, "p_value": {"pearson": 7.221720923217705e-82, "spearman": 2.063088281547055e-75, "kendall": 2.2368153284077243e-37}, "kappa_score": 0.5156482861400894, "total_responses": 200, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6314459246197559, "spearman": 0.7009759613462893, "kendall": 0.630796980486951}, "p_value": {"pearson": 1.5465620508962296e-23, "spearman": 9.706069993725913e-31, "kendall": 1.0219843991441002e-23}, "kappa_score": 0.33666666666666667, "total_responses": 200, "valid_responses": 199, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.8007305683898376, "spearman": 0.8007305683898377, "kendall": 0.8007305683898377}, "p_value": {"pearson": 1.6971321299808892e-45, "spearman": 1.6971321299807376e-45, "kendall": 2.629645330203438e-29}, "kappa_score": 0.7996164908916586, "total_responses": 200, "valid_responses": 198, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.3033118906555624, "spearman": -0.30331189065556247, "kendall": -0.30331189065556247}, "p_value": {"pearson": 1.3317814758235813e-05, "spearman": 1.3317814758235973e-05, "kendall": 1.9725399883159434e-05}, "kappa_score": -0.24639429983336192, "total_responses": 200, "valid_responses": 199, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3.1-8B-Instruct (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.9099764190413409, "spearman": 0.8740497515473781, "kendall": 0.7961745250002727}, "p_value": {"pearson": 1.2491768078476952e-77, "spearman": 5.443634094628017e-64, "kendall": 1.0585806304986118e-36}, "kappa_score": 0.5066711514743805, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6322027310354438, "spearman": 0.7221662598587026, "kendall": 0.6636504435914242}, "p_value": {"pearson": 1.7086835097575557e-23, "spearman": 3.318311226241784e-33, "kendall": 1.6627512307397522e-24}, "kappa_score": 0.34537339339587547, "total_responses": 200, "valid_responses": 198, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.010110979619189366, "spearman": 0.010110979619189359, "kendall": 0.01011097961918936}, "p_value": {"pearson": 0.890760484910425, "spearman": 0.8907604849104247, "kendall": 0.8903231039812187}, "kappa_score": 0.009571820560270505, "total_responses": 200, "valid_responses": 187, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.24078818214636832, "spearman": 0.24078818214636835, "kendall": 0.24078818214636832}, "p_value": {"pearson": 0.0006534412519578215, "spearman": 0.000653441251957828, "kendall": 0.0007488646532781055}, "kappa_score": 0.22756748605036947, "total_responses": 200, "valid_responses": 197, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.9367125542062618, "spearman": 0.895811778274816, "kendall": 0.8159174711730843}, "p_value": {"pearson": 3.396572139406659e-92, "spearman": 1.1643402451411084e-71, "kendall": 2.010347314448509e-38}, "kappa_score": 0.5461189322255557, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6873220665130717, "spearman": 0.7292724288337725, "kendall": 0.6581567400424565}, "p_value": {"pearson": 2.634711197628501e-29, "spearman": 1.8091422337913503e-34, "kendall": 3.61582692623612e-26}, "kappa_score": 0.4169096209912536, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.7387585882049729, "spearman": 0.7387585882049729, "kendall": 0.7387585882049728}, "p_value": {"pearson": 8.987050866292171e-36, "spearman": 8.987050866292596e-36, "kendall": 1.9786603144853344e-25}, "kappa_score": 0.7061416397296503, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.4502672309404692, "spearman": 0.4502672309404692, "kendall": 0.4502672309404692}, "p_value": {"pearson": 2.2376695418703277e-11, "spearman": 2.2376695418702563e-11, "kendall": 2.1280858620104817e-10}, "kappa_score": 0.3371310201967893, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.12090672867809665, "spearman": 0.1186373610083012, "kendall": 0.11214501339483232}, "p_value": {"pearson": 0.09837113983497515, "spearman": 0.10489832538806718, "kendall": 0.10385722876855544}, "kappa_score": 0.009147634336947985, "total_responses": 200, "valid_responses": 188, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": -0.07223811065773378, "spearman": 0.019454753503974884, "kendall": 0.01710949547053571}, "p_value": {"pearson": 0.3421052278967128, "spearman": 0.7983044973958104, "kendall": 0.8097939201154699}, "kappa_score": 0.036608863198458574, "total_responses": 200, "valid_responses": 175, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.1087271661064528, "spearman": -0.10872716610645279, "kendall": -0.10872716610645279}, "p_value": {"pearson": 0.21110695060315354, "spearman": 0.21110695060315307, "kendall": 0.20987731943158505}, "kappa_score": -0.06452237938384031, "total_responses": 200, "valid_responses": 134, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.07093269021319087, "spearman": -0.07093269021319087, "kendall": -0.07093269021319087}, "p_value": {"pearson": 0.4299500807916246, "spearman": 0.4299500807916249, "kendall": 0.42774776839694806}, "kappa_score": -0.024390243902439046, "total_responses": 200, "valid_responses": 126, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.881729574715922, "spearman": 0.8853298786888456, "kendall": 0.8101439401291691}, "p_value": {"pearson": 1.5959079165860097e-66, "spearman": 9.000811900126196e-68, "kendall": 9.307155742776201e-38}, "kappa_score": 0.46581196581196593, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6357583902783757, "spearman": 0.7286153073410531, "kendall": 0.6457751700590398}, "p_value": {"pearson": 4.8126577930928834e-24, "spearman": 2.216914840234302e-34, "kendall": 6.795992048040437e-25}, "kappa_score": 0.3868080875041432, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.7313097329929557, "spearman": 0.7313097329929557, "kendall": 0.7313097329929557}, "p_value": {"pearson": 9.596938534318696e-35, "spearman": 9.596938534318796e-35, "kendall": 5.941319538216122e-25}, "kappa_score": 0.6969104419241299, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.35894481740668566, "spearman": 0.35894481740668566, "kendall": 0.35894481740668566}, "p_value": {"pearson": 1.794891149389774e-07, "spearman": 1.7948911493897344e-07, "kendall": 4.115424789006094e-07}, "kappa_score": 0.3435114503816794, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.9470038258710273, "spearman": 0.9060816689009489, "kendall": 0.8334202202349635}, "p_value": {"pearson": 1.3303897905116979e-99, "spearman": 6.787577750546169e-76, "kendall": 1.1946051758339088e-38}, "kappa_score": 0.5733754690894727, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6639224563309923, "spearman": 0.7360166192656468, "kendall": 0.6612611517339523}, "p_value": {"pearson": 8.667902292011488e-27, "spearman": 2.1690488345874088e-35, "kendall": 3.7171268779468475e-26}, "kappa_score": 0.39569736524051247, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.8501621658374553, "spearman": 0.8501621658374553, "kendall": 0.8501621658374553}, "p_value": {"pearson": 4.602834471941722e-57, "spearman": 4.602834471942e-57, "kendall": 3.865820137581323e-33}, "kappa_score": 0.8390827717992557, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.2737204965699868, "spearman": -0.27372049656998687, "kendall": -0.2737204965699869}, "p_value": {"pearson": 8.785588249501884e-05, "spearman": 8.785588249501843e-05, "kendall": 0.00011278403301765295}, "kappa_score": -0.25316812165587166, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}