{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.5828905486917706, "spearman": 0.5828905486917706, "kendall": 0.5828905486917705}, "p_value": {"pearson": 1.5317396748046317e-87, "spearman": 1.5317396748046038e-87, "kendall": 4.2739081976927316e-72}, "kappa_score": 0.5781875530753366, "total_responses": 953, "valid_responses": 950, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.6651077604637159, "spearman": 0.6651077604637159, "kendall": 0.6651077604637158}, "p_value": {"pearson": 1.2384581762512496e-115, "spearman": 1.2384581762513102e-115, "kendall": 3.4110235430687153e-88}, "kappa_score": 0.6648360719840808, "total_responses": 953, "valid_responses": 897, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Starling-LM-7B-alpha (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.49029234124678667, "spearman": 0.4902923412467864, "kendall": 0.49029234124678656}, "p_value": {"pearson": 8.76288704361572e-59, "spearman": 8.762887043616079e-59, "kendall": 1.0630948499380755e-51}, "kappa_score": 0.48903451401929676, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.5114403026246018, "spearman": 0.5114403026246018, "kendall": 0.5114403026246019}, "p_value": {"pearson": 7.521565188516951e-64, "spearman": 7.521565188516383e-64, "kendall": 2.057497885745913e-55}, "kappa_score": 0.4559886918436593, "total_responses": 953, "valid_responses": 941, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "c4ai-command-r-v01 (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.4213546342636536, "spearman": 0.42135463426365355, "kendall": 0.4213546342636536}, "p_value": {"pearson": 2.922935670481761e-42, "spearman": 2.922935670481988e-42, "kendall": 1.325762138291278e-38}, "kappa_score": 0.3427503115911924, "total_responses": 953, "valid_responses": 952, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "c4ai-command-r-plus (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.29478365005262597, "spearman": 0.294783650052626, "kendall": 0.294783650052626}, "p_value": {"pearson": 2.020132849595524e-20, "spearman": 2.0201328495953985e-20, "kendall": 1.281969401486475e-19}, "kappa_score": 0.19215403416586618, "total_responses": 953, "valid_responses": 946, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.6962676004223266, "spearman": 0.6962676004223265, "kendall": 0.6962676004223265}, "p_value": {"pearson": 4.155048370395064e-139, "spearman": 4.1550483703960855e-139, "kendall": 2.2459120417219813e-102}, "kappa_score": 0.6961699606628325, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.16278394083866538, "spearman": 0.16278394083866538, "kendall": 0.16278394083866538}, "p_value": {"pearson": 0.0003573015834503897, "spearman": 0.0003573015834503949, "kendall": 0.00038300372047584183}, "kappa_score": 0.07425029737682354, "total_responses": 953, "valid_responses": 477, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "gemini-1.5-flash-latest (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.6646786130982592, "spearman": 0.6646786130982592, "kendall": 0.6646786130982593}, "p_value": {"pearson": 1.5451882189816746e-122, "spearman": 1.54518821898179e-122, "kendall": 1.8143771502438065e-93}, "kappa_score": 0.6643955169034788, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}, "gpt-4o (SP: None, AP: 9)": {"Factual Consistency": {"corr_coeff": {"pearson": 0.6946033885761388, "spearman": 0.6946033885761388, "kendall": 0.6946033885761389}, "p_value": {"pearson": 3.510043860933065e-138, "spearman": 3.510043860932693e-138, "kendall": 6.775367122394132e-102}, "kappa_score": 0.6946013802500599, "total_responses": 953, "valid_responses": 953, "krippendorff_alpha": 0.4878830126174004, "type": "categorical", "expert": "false", "task": "Summarisation"}}}