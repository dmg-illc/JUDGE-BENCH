{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.40755201370017047, "spearman": 0.41749959393653935, "kendall": 0.3477246834714682}, "p_value": {"pearson": 3.3530230070033567e-09, "spearman": 1.2618630356724463e-09, "kendall": 5.991653121438608e-09}, "kappa_score": 0.10809174682181999, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.33374887503832273, "spearman": 0.3386823926611103, "kendall": 0.2840154828614006}, "p_value": {"pearson": 1.860532648102718e-06, "spearman": 1.2793797073588196e-06, "kendall": 2.3650467211174235e-06}, "kappa_score": 0.11025606101879604, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.028370121110382934, "spearman": 0.028370121110382923, "kendall": 0.028370121110382923}, "p_value": {"pearson": 0.6938029908256514, "spearman": 0.6938029908256517, "kendall": 0.6927321444387466}, "kappa_score": 0.006286612373196276, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.22075528090489663, "spearman": -0.22075528090489666, "kendall": -0.22075528090489666}, "p_value": {"pearson": 0.002035116075388307, "spearman": 0.0020351160753883098, "kendall": 0.002221699028581734}, "kappa_score": -0.22029950083194683, "total_responses": 195, "valid_responses": 193, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6303154970852365, "spearman": 0.6382583298935357, "kendall": 0.5508258207267702}, "p_value": {"pearson": 1.1717708254802119e-22, "spearman": 2.3332000653798637e-23, "kendall": 3.8233410027391045e-19}, "kappa_score": 0.26531488037764184, "total_responses": 195, "valid_responses": 192, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.45174647449781374, "spearman": 0.46580063429979257, "kendall": 0.40495966533097333}, "p_value": {"pearson": 7.660058689213151e-11, "spearman": 1.6285645013329882e-11, "kendall": 1.8761308339952132e-10}, "kappa_score": 0.22818482677726126, "total_responses": 195, "valid_responses": 188, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.22925148691087432, "spearman": -0.22925148691087432, "kendall": -0.22925148691087432}, "p_value": {"pearson": 0.0018517757592053433, "spearman": 0.0018517757592053543, "kendall": 0.002040569016632177}, "kappa_score": -0.20055549126258554, "total_responses": 195, "valid_responses": 182, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.42218567093251846, "spearman": -0.42218567093251846, "kendall": -0.42218567093251846}, "p_value": {"pearson": 2.155376904745977e-09, "spearman": 2.1553769047459578e-09, "kendall": 1.0233964601633326e-08}, "kappa_score": -0.3701923076923077, "total_responses": 195, "valid_responses": 185, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.42499649812262735, "spearman": 0.42091423234298075, "kendall": 0.36764317017098014}, "p_value": {"pearson": 5.913817606268798e-10, "spearman": 8.955659841035317e-10, "kendall": 1.5467784664173051e-09}, "kappa_score": 0.23331608898085865, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.2464084527083773, "spearman": 0.22695912497155574, "kendall": 0.1898545438722557}, "p_value": {"pearson": 0.0005156689462749918, "spearman": 0.0014194005067953899, "kendall": 0.0017769003422889154}, "kappa_score": 0.06471521777464295, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.09136589059548576, "spearman": 0.09136589059548576, "kendall": 0.09136589059548578}, "p_value": {"pearson": 0.20397383220177528, "spearman": 0.20397383220177429, "kendall": 0.20316726152998943}, "kappa_score": 0.016557236654296426, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.20542067522634652, "spearman": -0.20542067522634655, "kendall": -0.20542067522634655}, "p_value": {"pearson": 0.004060843812570244, "spearman": 0.004060843812570201, "kendall": 0.004320036761057571}, "kappa_score": -0.20404693079408265, "total_responses": 195, "valid_responses": 194, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6898912647568434, "spearman": 0.6894619293468792, "kendall": 0.6041028585860784}, "p_value": {"pearson": 4.847484922057771e-28, "spearman": 5.390669015141066e-28, "kendall": 3.87553539150092e-22}, "kappa_score": 0.26510887275959116, "total_responses": 195, "valid_responses": 189, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.37990137202194474, "spearman": 0.3976850733404499, "kendall": 0.33424026737952717}, "p_value": {"pearson": 8.200382904248544e-08, "spearman": 1.740532993895315e-08, "kendall": 7.772929111609805e-08}, "kappa_score": 0.17180013689253937, "total_responses": 195, "valid_responses": 187, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.15800803218077183, "spearman": -0.15800803218077183, "kendall": -0.15800803218077183}, "p_value": {"pearson": 0.030336337197042724, "spearman": 0.03033633719704254, "kendall": 0.03071640747786786}, "kappa_score": -0.11295054484492861, "total_responses": 195, "valid_responses": 188, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.4207869734933308, "spearman": -0.4207869734933307, "kendall": -0.4207869734933307}, "p_value": {"pearson": 1.495199657047187e-09, "spearman": 1.4951996570471982e-09, "kendall": 7.2570814351144626e-09}, "kappa_score": -0.39012597022521933, "total_responses": 195, "valid_responses": 190, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.7249761870641169, "spearman": 0.7235125281641853, "kendall": 0.6369302783933266}, "p_value": {"pearson": 4.41662678084825e-33, "spearman": 6.804931649653013e-33, "kendall": 1.519394629445664e-24}, "kappa_score": 0.15990259740259738, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.5087197587248237, "spearman": 0.5068521375264385, "kendall": 0.45438426192439046}, "p_value": {"pearson": 3.1258132595403054e-14, "spearman": 4.014283878763112e-14, "kendall": 7.317926227536335e-13}, "kappa_score": 0.27133558341369335, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.28648508085797464, "spearman": -0.2864850808579747, "kendall": -0.28648508085797464}, "p_value": {"pearson": 6.429027566776498e-05, "spearman": 6.429027566776449e-05, "kendall": 8.562476324488378e-05}, "kappa_score": -0.2672117743254292, "total_responses": 195, "valid_responses": 189, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.3626507690165558, "spearman": -0.3626507690165558, "kendall": -0.3626507690165558}, "p_value": {"pearson": 2.0308750301356997e-07, "spearman": 2.0308750301356938e-07, "kendall": 4.701622933474955e-07}, "kappa_score": -0.33886285931366333, "total_responses": 195, "valid_responses": 194, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6968412833636469, "spearman": 0.6950912166688821, "kendall": 0.6119685892621882}, "p_value": {"pearson": 7.553427327249447e-24, "spearman": 1.0868386509979501e-23, "kendall": 1.1139739669530191e-18}, "kappa_score": 0.29192580769442456, "total_responses": 195, "valid_responses": 155, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.44420839896121955, "spearman": 0.4479392141236627, "kendall": 0.3842229258529263}, "p_value": {"pearson": 8.834501176133906e-09, "spearman": 6.404918962897622e-09, "kendall": 3.499325265890007e-08}, "kappa_score": 0.19042751488184706, "total_responses": 195, "valid_responses": 153, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.14094347455496903, "spearman": -0.140943474554969, "kendall": -0.14094347455496903}, "p_value": {"pearson": 0.05242285427202208, "spearman": 0.05242285427202226, "kendall": 0.052665642158316074}, "kappa_score": -0.11507021588765465, "total_responses": 195, "valid_responses": 190, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.4160078265424615, "spearman": -0.41600782654246155, "kendall": -0.4160078265424615}, "p_value": {"pearson": 1.7792303590212154e-09, "spearman": 1.7792303590212276e-09, "kendall": 8.196170832484978e-09}, "kappa_score": -0.3700899195456697, "total_responses": 195, "valid_responses": 193, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.681060226859618, "spearman": 0.7034744685496706, "kendall": 0.6110414262946214}, "p_value": {"pearson": 6.303027184666904e-28, "spearman": 1.9363598165546542e-30, "kendall": 6.040370385584654e-25}, "kappa_score": 0.30318105381165916, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.40055175570215673, "spearman": 0.3976303787980573, "kendall": 0.333619149879811}, "p_value": {"pearson": 7.16023467482757e-09, "spearman": 9.409347679915995e-09, "kendall": 2.4726026937530623e-08}, "kappa_score": 0.1837494826872671, "total_responses": 195, "valid_responses": 194, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.0884565837588512, "spearman": 0.08845658375885117, "kendall": 0.08845658375885117}, "p_value": {"pearson": 0.218809697412895, "spearman": 0.21880969741289452, "kendall": 0.21792755186792245}, "kappa_score": 0.02780221713883524, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.056604727496014806, "spearman": 0.05660472749601481, "kendall": 0.056604727496014806}, "p_value": {"pearson": 0.43548394002140667, "spearman": 0.4354839400214079, "kendall": 0.4340424596242469}, "kappa_score": 0.034120734908136496, "total_responses": 195, "valid_responses": 192, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.39913097086183275, "spearman": 0.4026533394288024, "kendall": 0.34800516481540295}, "p_value": {"pearson": 0.000185706983828865, "spearman": 0.00016079542391720414, "kendall": 0.0002507321772545104}, "kappa_score": 0.1170212765957448, "total_responses": 195, "valid_responses": 83, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.22192353917259294, "spearman": 0.2013363536429405, "kendall": 0.1778104683477611}, "p_value": {"pearson": 0.0689338182381426, "spearman": 0.09968384688362342, "kendall": 0.08996519329316353}, "kappa_score": 0.10231023102310233, "total_responses": 195, "valid_responses": 68, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.15416749476599212, "spearman": -0.15416749476599215, "kendall": -0.15416749476599212}, "p_value": {"pearson": 0.03718539973469918, "spearman": 0.03718539973469914, "kendall": 0.03754083361672138}, "kappa_score": -0.14851310927327122, "total_responses": 195, "valid_responses": 183, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.36058603817926277, "spearman": -0.36058603817926277, "kendall": -0.3605860381792628}, "p_value": {"pearson": 1.2978291889095053e-05, "spearman": 1.29782918890951e-05, "kendall": 2.2761088798373234e-05}, "kappa_score": -0.31832552054943863, "total_responses": 195, "valid_responses": 139, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6086562307948996, "spearman": 0.6317984314091861, "kendall": 0.5548467562863199}, "p_value": {"pearson": 3.76800434683304e-21, "spearman": 4.020792785515644e-23, "kendall": 3.423373370323395e-19}, "kappa_score": 0.21997028458226986, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.43974452929260655, "spearman": 0.479278556779357, "kendall": 0.4187023327676585}, "p_value": {"pearson": 1.2599655362924283e-10, "spearman": 1.3585775682810078e-12, "kendall": 3.749475451255975e-11}, "kappa_score": 0.15075143683289904, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.32628128156837516, "spearman": -0.32628128156837527, "kendall": -0.32628128156837527}, "p_value": {"pearson": 3.239693952384009e-06, "spearman": 3.23969395238398e-06, "kendall": 5.504689079756992e-06}, "kappa_score": -0.3194878201124296, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.19477594615635466, "spearman": -0.19477594615635468, "kendall": -0.19477594615635466}, "p_value": {"pearson": 0.006360497941661455, "spearman": 0.006360497941661453, "kendall": 0.006669421062643341}, "kappa_score": -0.19439071566731148, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.7162251628683107, "spearman": 0.7195574943479051, "kendall": 0.6350838285994467}, "p_value": {"pearson": 5.621548685344348e-32, "spearman": 2.1583657746455933e-32, "kendall": 1.4459101251572405e-26}, "kappa_score": 0.313116869528825, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.4151436711081674, "spearman": 0.42316074439597573, "kendall": 0.3578952610901308}, "p_value": {"pearson": 1.5950991358489917e-09, "spearman": 7.132033342322872e-10, "kendall": 2.6317964870013746e-09}, "kappa_score": 0.16825605992301562, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.2418832621258539, "spearman": -0.24188326212585398, "kendall": -0.24188326212585395}, "p_value": {"pearson": 0.0006574625364918421, "spearman": 0.0006574625364918409, "kendall": 0.0007542938869492457}, "kappa_score": -0.24034064027755875, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.38497718259735386, "spearman": -0.3849771825973539, "kendall": -0.3849771825973539}, "p_value": {"pearson": 2.744105572851636e-08, "spearman": 2.7441055728515818e-08, "kendall": 8.225465813464021e-08}, "kappa_score": -0.33003300330033003, "total_responses": 195, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}