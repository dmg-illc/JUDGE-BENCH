{"c4ai-command-r-v01 (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": 0.21353677935150217, "spearman": 0.2135367793515022, "kendall": 0.21353677935150214}, "p_value": {"pearson": 1.0785462072544756e-11, "spearman": 1.078546207254397e-11, "kendall": 1.7903742953095357e-11}, "kappa_score": 0.11799924955544328, "total_responses": 1043, "valid_responses": 992, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.16618385348501374, "spearman": 0.16618385348501363, "kendall": 0.1661838534850136}, "p_value": {"pearson": 1.0094910162746346e-07, "spearman": 1.0094910162745818e-07, "kendall": 1.2108295223207028e-07}, "kappa_score": 0.16479606962856286, "total_responses": 1043, "valid_responses": 1015, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.01783576231095721, "spearman": 0.017835762310957227, "kendall": 0.01783576231095723}, "p_value": {"pearson": 0.5691831795035637, "spearman": 0.5691831795035658, "kendall": 0.5689296479557093}, "kappa_score": 0.012644752346511634, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": -0.003927910891611978, "spearman": -0.00392791089161195, "kendall": -0.003927910891611949}, "p_value": {"pearson": 0.9027089926125098, "spearman": 0.9027089926125089, "kendall": 0.9026344352280017}, "kappa_score": -0.0012895543848217006, "total_responses": 1043, "valid_responses": 971, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": -0.05898483060472514, "spearman": -0.05898483060472514, "kendall": -0.05898483060472515}, "p_value": {"pearson": 0.05930460578790973, "spearman": 0.05930460578791129, "kendall": 0.0593393837175285}, "kappa_score": -0.024230482845523982, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.028192245864892444, "spearman": 0.028192245864892454, "kendall": 0.028192245864892457}, "p_value": {"pearson": 0.36864160098794196, "spearman": 0.36864160098794263, "kendall": 0.36838375419694813}, "kappa_score": 0.027744360278439184, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": -0.08265150185973626, "spearman": -0.08265150185973627, "kendall": -0.08265150185973628}, "p_value": {"pearson": 0.008048485276278213, "spearman": 0.008048485276278102, "kendall": 0.008110623103204855}, "kappa_score": -0.05875509016870284, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.16270784356913687, "spearman": 0.1627078435691368, "kendall": 0.1627078435691368}, "p_value": {"pearson": 1.766316348686426e-07, "spearman": 1.7663163486864651e-07, "kendall": 2.087470206387837e-07}, "kappa_score": 0.0832090279751656, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.12668881252837452, "spearman": 0.1266888125283745, "kendall": 0.12668881252837452}, "p_value": {"pearson": 4.917636037774642e-05, "spearman": 4.9176360377746746e-05, "kendall": 5.2074390597145444e-05}, "kappa_score": 0.06214477355450343, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.1433479604909499, "spearman": 0.14334796049094992, "kendall": 0.14334796049094997}, "p_value": {"pearson": 3.7762068527454896e-06, "spearman": 3.7762068527453325e-06, "kendall": 4.168750853693094e-06}, "kappa_score": 0.11484290357529792, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": -0.058157779429927864, "spearman": -0.05815777942992789, "kendall": -0.05815777942992789}, "p_value": {"pearson": 0.06546803115095078, "spearman": 0.06546803115095472, "kendall": 0.06549459699797737}, "kappa_score": -0.05186553713049746, "total_responses": 1043, "valid_responses": 1004, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.011075181618808582, "spearman": 0.011075181618808603, "kendall": 0.011075181618808605}, "p_value": {"pearson": 0.7260938252166608, "spearman": 0.7260938252166602, "kendall": 0.7259049282827408}, "kappa_score": 0.010503899852179144, "total_responses": 1043, "valid_responses": 1003, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": -0.049437367511958465, "spearman": -0.04943736751195848, "kendall": -0.049437367511958465}, "p_value": {"pearson": 0.16033165213353662, "spearman": 0.160331652133535, "kendall": 0.16019853561164743}, "kappa_score": -0.028732137427789795, "total_responses": 1043, "valid_responses": 808, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.16614904860868884, "spearman": 0.1661490486086888, "kendall": 0.16614904860868876}, "p_value": {"pearson": 8.79045775512018e-08, "spearman": 8.790457755121064e-08, "kendall": 1.0562570146294195e-07}, "kappa_score": 0.12703466390735063, "total_responses": 1043, "valid_responses": 1025, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.1452243776381428, "spearman": 0.14522437763814275, "kendall": 0.14522437763814278}, "p_value": {"pearson": 2.8378048394481398e-06, "spearman": 2.8378048394482478e-06, "kendall": 3.1502097341310105e-06}, "kappa_score": 0.059445076070935854, "total_responses": 1043, "valid_responses": 1031, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.07851462476456933, "spearman": 0.07851462476456932, "kendall": 0.07851462476456932}, "p_value": {"pearson": 0.012214434129971514, "spearman": 0.012214434129972272, "kendall": 0.012284464412953609}, "kappa_score": 0.07453337799101345, "total_responses": 1043, "valid_responses": 1018, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.02511493563563203, "spearman": 0.025114935635632003, "kendall": 0.025114935635632}, "p_value": {"pearson": 0.4282779278166747, "spearman": 0.42827792781665985, "kendall": 0.42800274983622255}, "kappa_score": 0.011346724738077407, "total_responses": 1043, "valid_responses": 997, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": -0.020278819071913007, "spearman": -0.020278819071912958, "kendall": -0.020278819071912955}, "p_value": {"pearson": 0.5292190723055673, "spearman": 0.529219072305568, "kendall": 0.5289407091049547}, "kappa_score": -0.01953229714742255, "total_responses": 1043, "valid_responses": 965, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.15575422250478052, "spearman": 0.1557542225047806, "kendall": 0.15575422250478058}, "p_value": {"pearson": 5.767970174143445e-07, "spearman": 5.76797017414349e-07, "kendall": 6.628214165040288e-07}, "kappa_score": 0.0915692948037028, "total_responses": 1043, "valid_responses": 1020, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.17958646925158384, "spearman": 0.1795864692515839, "kendall": 0.17958646925158392}, "p_value": {"pearson": 5.958040894570579e-09, "spearman": 5.958040894570397e-09, "kendall": 7.706320164975301e-09}, "kappa_score": 0.10767138628909678, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.1552231758339122, "spearman": 0.15522317583391218, "kendall": 0.15522317583391215}, "p_value": {"pearson": 1.737923749113418e-06, "spearman": 1.737923749113479e-06, "kendall": 1.9695837403104414e-06}, "kappa_score": 0.11533393893267196, "total_responses": 1043, "valid_responses": 940, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.0011710357583435659, "spearman": 0.0011710357583435624, "kendall": 0.0011710357583435622}, "p_value": {"pearson": 0.9701296323719818, "spearman": 0.9701296323719559, "kendall": 0.9701077528725861}, "kappa_score": 0.0009316417641694885, "total_responses": 1043, "valid_responses": 1025, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.09720224635562975, "spearman": 0.09720224635562975, "kendall": 0.09720224635562975}, "p_value": {"pearson": 0.0026934508978663924, "spearman": 0.002693450897866383, "kendall": 0.0027356936105576235}, "kappa_score": 0.023137675061565277, "total_responses": 1043, "valid_responses": 951, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.0532901501355003, "spearman": 0.05329015013550027, "kendall": 0.05329015013550028}, "p_value": {"pearson": 0.09003533420503257, "spearman": 0.09003533420503011, "kendall": 0.09002545410308868}, "kappa_score": 0.05184705723479266, "total_responses": 1043, "valid_responses": 1013, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.1710401164969677, "spearman": 0.1710401164969677, "kendall": 0.17104011649696768}, "p_value": {"pearson": 4.248297674000854e-08, "spearman": 4.2482976740007723e-08, "kendall": 5.215377592636127e-08}, "kappa_score": 0.11079706048615046, "total_responses": 1043, "valid_responses": 1014, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.05070131426619212, "spearman": 0.05070131426619215, "kendall": 0.050701314266192156}, "p_value": {"pearson": 0.10542132870283634, "spearman": 0.10542132870283935, "kendall": 0.10538915590871516}, "kappa_score": 0.02782545410437587, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.06139875517914398, "spearman": 0.06139875517914398, "kendall": 0.06139875517914396}, "p_value": {"pearson": 0.054675629435743764, "spearman": 0.05467562943574365, "kendall": 0.05471857746486251}, "kappa_score": 0.029218277721804076, "total_responses": 1043, "valid_responses": 980, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.01858147277367555, "spearman": 0.01858147277367559, "kendall": 0.018581472773675587}, "p_value": {"pearson": 0.5572617938949156, "spearman": 0.5572617938949134, "kendall": 0.5569996289728554}, "kappa_score": 0.00583096892383983, "total_responses": 1043, "valid_responses": 1000, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.05530302862574624, "spearman": 0.05530302862574631, "kendall": 0.05530302862574631}, "p_value": {"pearson": 0.0829340100377556, "spearman": 0.08293401003775862, "kendall": 0.0829346743873098}, "kappa_score": 0.03610349967422066, "total_responses": 1043, "valid_responses": 984, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.016087025005477814, "spearman": 0.01608702500547787, "kendall": 0.016087025005477873}, "p_value": {"pearson": 0.6147881077970913, "spearman": 0.6147881077970911, "kendall": 0.614540004072955}, "kappa_score": 0.004833882734054162, "total_responses": 1043, "valid_responses": 981, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.04514165838382453, "spearman": 0.045141658383824584, "kendall": 0.045141658383824584}, "p_value": {"pearson": 0.15108447916128492, "spearman": 0.15108447916128798, "kendall": 0.1509898031869624}, "kappa_score": 0.012122326875958822, "total_responses": 1043, "valid_responses": 1013, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": -0.011237876600957375, "spearman": -0.011237876600957389, "kendall": -0.01123787660095739}, "p_value": {"pearson": 0.7229015720022893, "spearman": 0.7229015720022876, "kendall": 0.7227099084638218}, "kappa_score": -0.002967499799893636, "total_responses": 1043, "valid_responses": 998, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.002665006574976014, "spearman": 0.0026650065749760365, "kendall": 0.002665006574976037}, "p_value": {"pearson": 0.931889696314138, "spearman": 0.9318896963141412, "kendall": 0.9318402928574508}, "kappa_score": 0.001821815986174924, "total_responses": 1043, "valid_responses": 1031, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.1773627109793819, "spearman": 0.1773627109793818, "kendall": 0.1773627109793818}, "p_value": {"pearson": 9.833275930477377e-09, "spearman": 9.833275930477718e-09, "kendall": 1.2540531818504056e-08}, "kappa_score": 0.1377526491857135, "total_responses": 1043, "valid_responses": 1031, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.5437764237025925, "spearman": 0.5437764237025924, "kendall": 0.5437764237025925}, "p_value": {"pearson": 3.711463674201059e-81, "spearman": 3.71146367420107e-81, "kendall": 7.574807276847929e-69}, "kappa_score": 0.5433898182315706, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.18544699722683697, "spearman": 0.18544699722683688, "kendall": 0.1854469972268369}, "p_value": {"pearson": 1.777715308518175e-09, "spearman": 1.7777153085181567e-09, "kendall": 2.3875022819384975e-09}, "kappa_score": 0.18103033472803343, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.025579222525491795, "spearman": 0.025579222525491867, "kendall": 0.025579222525491874}, "p_value": {"pearson": 0.4124054759639002, "spearman": 0.4124054759638982, "kendall": 0.41214071114352435}, "kappa_score": 0.006943870654297024, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.06845426716408087, "spearman": 0.06845426716408086, "kendall": 0.06845426716408087}, "p_value": {"pearson": 0.030009562905735396, "spearman": 0.03000956290573614, "kendall": 0.030079715159152053}, "kappa_score": 0.025998329461274006, "total_responses": 1043, "valid_responses": 1005, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": -0.005426805914427811, "spearman": -0.005426805914427824, "kendall": -0.005426805914427823}, "p_value": {"pearson": 0.862969080271592, "spearman": 0.8629690802715679, "kendall": 0.8628695268488664}, "kappa_score": -0.0009689461170745428, "total_responses": 1043, "valid_responses": 1014, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.02450086808825343, "spearman": 0.02450086808825351, "kendall": 0.02450086808825351}, "p_value": {"pearson": 0.4538005141732295, "spearman": 0.453800514173229, "kendall": 0.45350623791900546}, "kappa_score": 0.018697795601420264, "total_responses": 1043, "valid_responses": 937, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.039699362102270916, "spearman": 0.0396993621022709, "kendall": 0.0396993621022709}, "p_value": {"pearson": 0.21132895980930663, "spearman": 0.21132895980929506, "kendall": 0.21116355687266997}, "kappa_score": 0.01224550584419537, "total_responses": 1043, "valid_responses": 993, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": -0.0006378477262781526, "spearman": -0.0006378477262781573, "kendall": -0.0006378477262781573}, "p_value": {"pearson": 0.9840568770848371, "spearman": 0.9840568770848328, "kendall": 0.9840447032939116}, "kappa_score": -0.0001946039115383602, "total_responses": 1043, "valid_responses": 984, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.01808411358128909, "spearman": 0.018084113581289092, "kendall": 0.018084113581289096}, "p_value": {"pearson": 0.5667011190924435, "spearman": 0.5667011190924574, "kendall": 0.566443091066354}, "kappa_score": 0.002453667332233289, "total_responses": 1043, "valid_responses": 1006, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.0024016385686522947, "spearman": 0.0024016385686522453, "kendall": 0.0024016385686522457}, "p_value": {"pearson": 0.9393257908302083, "spearman": 0.9393257908302104, "kendall": 0.9392806845662368}, "kappa_score": 0.0007681292056145317, "total_responses": 1043, "valid_responses": 1007, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.03275312995729657, "spearman": 0.03275312995729663, "kendall": 0.03275312995729663}, "p_value": {"pearson": 0.3086804792143731, "spearman": 0.30868047921437225, "kendall": 0.30843481766424874}, "kappa_score": 0.010265975820379913, "total_responses": 1043, "valid_responses": 968, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.052603683170223944, "spearman": 0.052603683170223924, "kendall": 0.05260368317022393}, "p_value": {"pearson": 0.09507801452008638, "spearman": 0.09507801452008141, "kendall": 0.0950606086592166}, "kappa_score": 0.038907284768211814, "total_responses": 1043, "valid_responses": 1008, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.018221034488957955, "spearman": 0.01822103448895797, "kendall": 0.018221034488957972}, "p_value": {"pearson": 0.5597156650448047, "spearman": 0.5597156650447883, "kendall": 0.5594610397418238}, "kappa_score": 0.003183884790891156, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.023741279786909444, "spearman": 0.023741279786909465, "kendall": 0.023741279786909472}, "p_value": {"pearson": 0.450367286624681, "spearman": 0.4503672866246802, "kendall": 0.45009518689581207}, "kappa_score": 0.005978269669835168, "total_responses": 1043, "valid_responses": 1013, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": -0.0038718322974165, "spearman": -0.0038718322974165033, "kendall": -0.0038718322974165033}, "p_value": {"pearson": 0.9027701210588359, "spearman": 0.9027701210588355, "kendall": 0.9026976295277559}, "kappa_score": -0.002492804487048028, "total_responses": 1043, "valid_responses": 998, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.029654646473767962, "spearman": 0.02965464647376797, "kendall": 0.029654646473767973}, "p_value": {"pearson": 0.3569620845995212, "spearman": 0.3569620845995213, "kendall": 0.3566942417318122}, "kappa_score": 0.007065529626763101, "total_responses": 1043, "valid_responses": 967, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.021267285241352973, "spearman": 0.021267285241353, "kendall": 0.021267285241353004}, "p_value": {"pearson": 0.5058350243996327, "spearman": 0.5058350243996308, "kendall": 0.5055572683511529}, "kappa_score": 0.006497646182680561, "total_responses": 1043, "valid_responses": 981, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.07947717854092343, "spearman": 0.07947717854092334, "kendall": 0.07947717854092334}, "p_value": {"pearson": 0.010953185870149805, "spearman": 0.010953185870150118, "kendall": 0.011021147689939333}, "kappa_score": 0.012553945291779334, "total_responses": 1043, "valid_responses": 1024, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.05652991912483561, "spearman": 0.05652991912483558, "kendall": 0.05652991912483558}, "p_value": {"pearson": 0.08693207548747754, "spearman": 0.08693207548747742, "kendall": 0.08692625876929956}, "kappa_score": 0.020486555697823206, "total_responses": 1043, "valid_responses": 918, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.1437253004739736, "spearman": 0.1437253004739736, "kendall": 0.14372530047397358}, "p_value": {"pearson": 4.055139718630328e-06, "spearman": 4.055139718630443e-06, "kendall": 4.475826475013712e-06}, "kappa_score": 0.08960448022401124, "total_responses": 1043, "valid_responses": 1020, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": -0.14048084182488568, "spearman": -0.14048084182488568, "kendall": -0.14048084182488565}, "p_value": {"pearson": 6.8982897186368805e-06, "spearman": 6.898289718636677e-06, "kendall": 7.541888817872077e-06}, "kappa_score": -0.06963901115806537, "total_responses": 1043, "valid_responses": 1017, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.05446037910895275, "spearman": 0.05446037910895274, "kendall": 0.05446037910895274}, "p_value": {"pearson": 0.08333861260743534, "spearman": 0.08333861260743175, "kendall": 0.08333865369501858}, "kappa_score": 0.019754673709083348, "total_responses": 1043, "valid_responses": 1012, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.10242069099946713, "spearman": 0.10242069099946717, "kendall": 0.10242069099946717}, "p_value": {"pearson": 0.0010187204070709187, "spearman": 0.001018720407070919, "kendall": 0.0010415273416914297}, "kappa_score": 0.10142016927270114, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.11654964978034005, "spearman": 0.11654964978033987, "kendall": 0.11654964978033985}, "p_value": {"pearson": 0.0001777253678196584, "spearman": 0.0001777253678196684, "kendall": 0.0001849867031641336}, "kappa_score": 0.07653686381160152, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.15396824950410773, "spearman": 0.15396824950410767, "kendall": 0.1539682495041077}, "p_value": {"pearson": 8.177194216278268e-07, "spearman": 8.177194216277982e-07, "kendall": 9.329205812903351e-07}, "kappa_score": 0.05655617071974217, "total_responses": 1043, "valid_responses": 1016, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.2800208447592488, "spearman": 0.280020844759249, "kendall": 0.280020844759249}, "p_value": {"pearson": 4.406307507451973e-20, "spearman": 4.406307507451488e-20, "kendall": 2.2580236527014157e-19}, "kappa_score": 0.2332688805872083, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.1064385077298117, "spearman": 0.1064385077298117, "kendall": 0.1064385077298117}, "p_value": {"pearson": 0.0007212372994696474, "spearman": 0.0007212372994696536, "kendall": 0.0007400760496012208}, "kappa_score": 0.04309287938785, "total_responses": 1043, "valid_responses": 1006, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.19968326663122046, "spearman": 0.1996832666312205, "kendall": 0.19968326663122052}, "p_value": {"pearson": 8.344311581161652e-11, "spearman": 8.344311581161472e-11, "kendall": 1.2478319769477274e-10}, "kappa_score": 0.14962716846552215, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.09041390012497028, "spearman": 0.09041390012497033, "kendall": 0.09041390012497033}, "p_value": {"pearson": 0.0037838208704642578, "spearman": 0.0037838208704640513, "kendall": 0.003830030043806739}, "kappa_score": 0.04163759013724122, "total_responses": 1043, "valid_responses": 1024, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": 0.08014718266151664, "spearman": 0.08014718266151666, "kendall": 0.08014718266151667}, "p_value": {"pearson": 0.016474282275514084, "spearman": 0.016474282275513924, "kendall": 0.01655758178297989}, "kappa_score": 0.06867845993756494, "total_responses": 1043, "valid_responses": 895, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.2938898777652998, "spearman": 0.2938898777652998, "kendall": 0.2938898777652998}, "p_value": {"pearson": 9.484409235964428e-22, "spearman": 9.484409235964934e-22, "kendall": 6.795156248489062e-21}, "kappa_score": 0.26392658542736125, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.03506012215014752, "spearman": 0.03506012215014754, "kendall": 0.03506012215014754}, "p_value": {"pearson": 0.2731090762563066, "spearman": 0.27310907625630476, "kendall": 0.2728884964288727}, "kappa_score": 0.03106846249838624, "total_responses": 1043, "valid_responses": 979, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.15965158668010437, "spearman": 0.15965158668010435, "kendall": 0.15965158668010432}, "p_value": {"pearson": 2.9671743949891993e-07, "spearman": 2.967174394989278e-07, "kendall": 3.4624141395683854e-07}, "kappa_score": 0.11700844390832321, "total_responses": 1043, "valid_responses": 1020, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.059051032654922286, "spearman": 0.05905103265492225, "kendall": 0.059051032654922245}, "p_value": {"pearson": 0.05779141243308087, "spearman": 0.057791412433080905, "kendall": 0.05782792973516149}, "kappa_score": 0.05904400674959309, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.3086764601227125, "spearman": 0.3086764601227125, "kendall": 0.3086764601227125}, "p_value": {"pearson": 3.929426713317881e-24, "spearman": 3.9294267133175505e-24, "kendall": 4.504532544125988e-23}, "kappa_score": 0.2513907261939131, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.167489671712037, "spearman": 0.16748967171203696, "kendall": 0.167489671712037}, "p_value": {"pearson": 6.130643550765998e-08, "spearman": 6.130643550765547e-08, "kendall": 7.425243366843758e-08}, "kappa_score": 0.0868631400253701, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.4489669008901085, "spearman": 0.44896690089010827, "kendall": 0.4489669008901082}, "p_value": {"pearson": 3.099923578968105e-52, "spearman": 3.0999235789683255e-52, "kendall": 5.028671058835556e-47}, "kappa_score": 0.4436476745702099, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.35880631576030186, "spearman": 0.3588063157603017, "kendall": 0.35880631576030164}, "p_value": {"pearson": 1.9256235318146334e-32, "spearman": 1.9256235318147788e-32, "kendall": 1.854039535426481e-30}, "kappa_score": 0.3554367541766109, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.19239938436159548, "spearman": 0.19239938436159548, "kendall": 0.1923993843615955}, "p_value": {"pearson": 7.485297608800505e-10, "spearman": 7.485297608800386e-10, "kendall": 1.0446913489569232e-09}, "kappa_score": 0.12686870168618636, "total_responses": 1043, "valid_responses": 1007, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.20779098486062098, "spearman": 0.20779098486062098, "kendall": 0.20779098486062098}, "p_value": {"pearson": 1.6472003414366588e-11, "spearman": 1.64720034143671e-11, "kendall": 2.637201609037877e-11}, "kappa_score": 0.1905466970387244, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.33444105532679724, "spearman": 0.33444105532679724, "kendall": 0.3344410553267972}, "p_value": {"pearson": 2.3812983855474344e-27, "spearman": 2.381298385547391e-27, "kendall": 6.400977157907871e-26}, "kappa_score": 0.31609222633928147, "total_responses": 1043, "valid_responses": 992, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.1213713502828199, "spearman": 0.1213713502828199, "kendall": 0.12137135028281991}, "p_value": {"pearson": 0.00011561738516580625, "spearman": 0.00011561738516580073, "kendall": 0.00012111809900099843}, "kappa_score": 0.06383226196661052, "total_responses": 1043, "valid_responses": 1004, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.7600233341174196, "spearman": 0.7600233341174196, "kendall": 0.7600233341174197}, "p_value": {"pearson": 3.597057424249887e-195, "spearman": 3.5970574242503536e-195, "kendall": 1.1688995684951425e-131}, "kappa_score": 0.7592677306035784, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.3135846135907253, "spearman": 0.3135846135907255, "kendall": 0.3135846135907254}, "p_value": {"pearson": 4.266495838267728e-25, "spearman": 4.266495838267593e-25, "kendall": 5.912680363413364e-24}, "kappa_score": 0.31318279105112345, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.1445947670510853, "spearman": 0.14459476705108523, "kendall": 0.14459476705108523}, "p_value": {"pearson": 6.493345403878473e-06, "spearman": 6.493345403878217e-06, "kendall": 7.141439602447539e-06}, "kappa_score": 0.1133279093959596, "total_responses": 1043, "valid_responses": 965, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.051355489849186954, "spearman": 0.05135548984918692, "kendall": 0.05135548984918691}, "p_value": {"pearson": 0.10598160253704508, "spearman": 0.10598160253704868, "kendall": 0.10594766459088077}, "kappa_score": 0.032710792118409104, "total_responses": 1043, "valid_responses": 992, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.08618882503072792, "spearman": 0.08618882503072796, "kendall": 0.08618882503072797}, "p_value": {"pearson": 0.005665173084050405, "spearman": 0.005665173084050093, "kendall": 0.005719841937815942}, "kappa_score": 0.07870216306156397, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.44485016294976, "spearman": 0.44485016294976004, "kendall": 0.44485016294975993}, "p_value": {"pearson": 1.4354529992424934e-49, "spearman": 1.435452999242533e-49, "kendall": 9.905240092286175e-45}, "kappa_score": 0.41589215191376905, "total_responses": 1043, "valid_responses": 996, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.21130278781766482, "spearman": 0.2113027878176648, "kendall": 0.2113027878176648}, "p_value": {"pearson": 6.539192333746937e-12, "spearman": 6.5391923337469825e-12, "kendall": 1.0859458231812881e-11}, "kappa_score": 0.20372364979227564, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.5536473457037852, "spearman": 0.5536473457037852, "kendall": 0.5536473457037852}, "p_value": {"pearson": 1.675414532815797e-84, "spearman": 1.6754145328156448e-84, "kendall": 3.6206713550195653e-71}, "kappa_score": 0.5446001732837267, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.03661057753511472, "spearman": 0.036610577535114694, "kendall": 0.0366105775351147}, "p_value": {"pearson": 0.23950883542185197, "spearman": 0.2395088354218474, "kendall": 0.2393250180323695}, "kappa_score": 0.035623770807566846, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.5014546409187313, "spearman": 0.5014546409187314, "kendall": 0.5014546409187314}, "p_value": {"pearson": 6.157996454755503e-67, "spearman": 6.157996454755266e-67, "kendall": 1.940695809983734e-58}, "kappa_score": 0.4853577794754266, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.30995344188893115, "spearman": 0.30995344188893126, "kendall": 0.30995344188893126}, "p_value": {"pearson": 1.5015896586685966e-24, "spearman": 1.5015896586684722e-24, "kendall": 1.8409356365097975e-23}, "kappa_score": 0.3054419540498807, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.34629434173106877, "spearman": 0.3462943417310689, "kendall": 0.3462943417310688}, "p_value": {"pearson": 1.3873002338776004e-30, "spearman": 1.3873002338776593e-30, "kendall": 7.476364225060917e-29}, "kappa_score": 0.34221861631509076, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.3905798082910926, "spearman": 0.3905798082910927, "kendall": 0.3905798082910926}, "p_value": {"pearson": 3.65224977346709e-39, "spearman": 3.6522497734667786e-39, "kendall": 2.8027773983486632e-36}, "kappa_score": 0.3101220009739021, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.1482423135607921, "spearman": 0.14824231356079196, "kendall": 0.14824231356079196}, "p_value": {"pearson": 1.539031357894045e-06, "spearman": 1.5390313578941618e-06, "kendall": 1.7272493376052725e-06}, "kappa_score": 0.06236926061399317, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.02802518679019953, "spearman": 0.028025186790199545, "kendall": 0.02802518679019955}, "p_value": {"pearson": 0.37101695195816603, "spearman": 0.371016951958144, "kendall": 0.3707589228702939}, "kappa_score": 0.020459616242748835, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.24867627668106562, "spearman": 0.24867627668106557, "kendall": 0.24867627668106557}, "p_value": {"pearson": 5.551179644753032e-16, "spearman": 5.551179644752815e-16, "kendall": 1.4987815713255289e-15}, "kappa_score": 0.15526523996063368, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.08634347433905665, "spearman": 0.08634347433905665, "kendall": 0.08634347433905666}, "p_value": {"pearson": 0.005556106325729947, "spearman": 0.005556106325730035, "kendall": 0.0056103028120885615}, "kappa_score": 0.04444281471159839, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.1332263324911715, "spearman": 0.1332263324911714, "kendall": 0.1332263324911714}, "p_value": {"pearson": 1.789483957503203e-05, "spearman": 1.789483957503157e-05, "kendall": 1.9230893241954785e-05}, "kappa_score": 0.0676347691908119, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.12594924931670015, "spearman": 0.12594924931670012, "kendall": 0.12594924931670012}, "p_value": {"pearson": 6.72583191004212e-05, "spearman": 6.725831910041566e-05, "kendall": 7.100425422576749e-05}, "kappa_score": 0.0892977717758271, "total_responses": 1043, "valid_responses": 996, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": -0.0035696035290387167, "spearman": -0.00356960352903867, "kendall": -0.00356960352903867}, "p_value": {"pearson": 0.908550298048547, "spearman": 0.9085502980485476, "kendall": 0.9084846727082816}, "kappa_score": -0.0035208219099014393, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.5710361002038659, "spearman": 0.5710361002038659, "kendall": 0.5710361002038659}, "p_value": {"pearson": 5.876319396846414e-91, "spearman": 5.87631939684744e-91, "kendall": 1.3719852953521598e-75}, "kappa_score": 0.5644798412277474, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.7528109051064897, "spearman": 0.7528109051064895, "kendall": 0.7528109051064896}, "p_value": {"pearson": 2.296655396386207e-190, "spearman": 2.296655396387008e-190, "kendall": 7.956154138826994e-130}, "kappa_score": 0.7443468562665552, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.2625959839547109, "spearman": 0.26259598395471095, "kendall": 0.262595983954711}, "p_value": {"pearson": 1.214638793579186e-17, "spearman": 1.2146387935792972e-17, "kendall": 4.200093708157992e-17}, "kappa_score": 0.25241845466947777, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": -0.011107989076191526, "spearman": -0.011107989076191538, "kendall": -0.011107989076191538}, "p_value": {"pearson": 0.7202334332535207, "spearman": 0.7202334332535241, "kendall": 0.7200484327746228}, "kappa_score": -0.008114349915735453, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.16205199627885752, "spearman": 0.1620519962788577, "kendall": 0.1620519962788577}, "p_value": {"pearson": 1.8754605312170708e-07, "spearman": 1.8754605312169705e-07, "kendall": 2.2117654240761592e-07}, "kappa_score": 0.15174129353233834, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.07777515340961083, "spearman": 0.07777515340961093, "kendall": 0.07777515340961094}, "p_value": {"pearson": 0.012191968569207361, "spearman": 0.012191968569206737, "kendall": 0.012260617819796716}, "kappa_score": 0.07694467846110653, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.17121323252363435, "spearman": 0.17121323252363427, "kendall": 0.17121323252363427}, "p_value": {"pearson": 2.719923007008999e-08, "spearman": 2.7199230070090423e-08, "kendall": 3.3619274278212994e-08}, "kappa_score": 0.14069356226159346, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.07758815561950694, "spearman": 0.07758815561950697, "kendall": 0.07758815561950697}, "p_value": {"pearson": 0.012876122345360229, "spearman": 0.012876122345361007, "kendall": 0.01294625095768003}, "kappa_score": 0.05204382738781299, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.035643394611871757, "spearman": 0.03564339461187175, "kendall": 0.035643394611871757}, "p_value": {"pearson": 0.26156520786055826, "spearman": 0.2615652078605655, "kendall": 0.26135630928360987}, "kappa_score": 0.02253976285101067, "total_responses": 1043, "valid_responses": 994, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.12358158382271167, "spearman": 0.12358158382271167, "kendall": 0.12358158382271167}, "p_value": {"pearson": 0.0001033366479500949, "spearman": 0.0001033366479500972, "kendall": 0.0001085282472529353}, "kappa_score": 0.08654019026178572, "total_responses": 1043, "valid_responses": 982, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.01625744971398665, "spearman": 0.016257449713986655, "kendall": 0.016257449713986655}, "p_value": {"pearson": 0.6090476440758205, "spearman": 0.6090476440758206, "kendall": 0.6088000924821396}, "kappa_score": 0.009889968745986244, "total_responses": 1043, "valid_responses": 992, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.035374674582051374, "spearman": 0.035374674582051374, "kendall": 0.03537467458205139}, "p_value": {"pearson": 0.27479078876025737, "spearman": 0.2747907887602584, "kendall": 0.27456344607180383}, "kappa_score": 0.019846102304211133, "total_responses": 1043, "valid_responses": 955, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.23571377364003357, "spearman": 0.2357137736400335, "kendall": 0.2357137736400335}, "p_value": {"pearson": 2.1461703852453735e-14, "spearman": 2.146170385245378e-14, "kendall": 4.7301983506656153e-14}, "kappa_score": 0.19612523464114384, "total_responses": 1043, "valid_responses": 1024, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.10058226076186844, "spearman": 0.10058226076186842, "kendall": 0.10058226076186844}, "p_value": {"pearson": 0.0012902426496356626, "spearman": 0.00129024264963569, "kendall": 0.0013165855176620169}, "kappa_score": 0.0769743181034176, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.12421249261675257, "spearman": 0.12421249261675256, "kendall": 0.12421249261675255}, "p_value": {"pearson": 9.132855767407424e-05, "spearman": 9.132855767407233e-05, "kendall": 9.60531751041214e-05}, "kappa_score": 0.0838637349920438, "total_responses": 1043, "valid_responses": 987, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.10303639115207304, "spearman": 0.10303639115207323, "kendall": 0.10303639115207325}, "p_value": {"pearson": 0.000988293878262076, "spearman": 0.0009882938782620236, "kendall": 0.0010108454081812822}, "kappa_score": 0.09180035650623897, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.17022315960633352, "spearman": 0.17022315960633366, "kendall": 0.17022315960633366}, "p_value": {"pearson": 3.8717269662717286e-08, "spearman": 3.871726966271536e-08, "kendall": 4.7499987390710405e-08}, "kappa_score": 0.11071139490961412, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.06903682755004577, "spearman": 0.0690368275500458, "kendall": 0.06903682755004578}, "p_value": {"pearson": 0.026134781031596794, "spearman": 0.026134781031597134, "kendall": 0.026205190906024977}, "kappa_score": 0.06899865462233323, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.03189557652573616, "spearman": 0.031895576525736165, "kendall": 0.031895576525736165}, "p_value": {"pearson": 0.3083584428240597, "spearman": 0.30835844282406644, "kendall": 0.3081259465014895}, "kappa_score": 0.01564745077605678, "total_responses": 1043, "valid_responses": 1022, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.5216936424087313, "spearman": 0.5216936424087311, "kendall": 0.5216936424087312}, "p_value": {"pearson": 7.95877515489177e-73, "spearman": 7.958775154893507e-73, "kendall": 9.589355886596764e-63}, "kappa_score": 0.5014939399050626, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.2612655207743018, "spearman": 0.2612655207743019, "kendall": 0.26126552077430193}, "p_value": {"pearson": 1.2514318332439124e-17, "spearman": 1.2514318332437735e-17, "kendall": 4.268357175277311e-17}, "kappa_score": 0.14099498650212117, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.03779930550231243, "spearman": 0.03779930550231245, "kendall": 0.03779930550231244}, "p_value": {"pearson": 0.2245822752382392, "spearman": 0.22458227523824037, "kendall": 0.2244112239687328}, "kappa_score": 0.011213731099305124, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.1597036362420394, "spearman": 0.15970363624203943, "kendall": 0.15970363624203943}, "p_value": {"pearson": 2.2807919524446425e-07, "spearman": 2.2807919524445856e-07, "kendall": 2.670467720777539e-07}, "kappa_score": 0.06324089554165924, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.26846268558560454, "spearman": 0.2684626855856046, "kendall": 0.2684626855856046}, "p_value": {"pearson": 1.5196040105732802e-18, "spearman": 1.5196040105732668e-18, "kendall": 5.994596068481672e-18}, "kappa_score": 0.21699889160611563, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.16246444742582714, "spearman": 0.16246444742582727, "kendall": 0.16246444742582725}, "p_value": {"pearson": 1.3787550958866913e-07, "spearman": 1.3787550958866837e-07, "kendall": 1.6338325481957126e-07}, "kappa_score": 0.09687379390196826, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.4864082302747943, "spearman": 0.4864082302747944, "kendall": 0.4864082302747944}, "p_value": {"pearson": 5.4741020966182415e-62, "spearman": 5.474102096618455e-62, "kendall": 1.2574553319319064e-54}, "kappa_score": 0.47773361866911235, "total_responses": 1043, "valid_responses": 1025, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.5865053118670334, "spearman": 0.5865053118670327, "kendall": 0.5865053118670327}, "p_value": {"pearson": 9.305391027594771e-97, "spearman": 9.305391027599659e-97, "kendall": 2.062869642690416e-79}, "kappa_score": 0.5863663108346642, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.10000016070717146, "spearman": 0.10000016070717145, "kendall": 0.10000016070717146}, "p_value": {"pearson": 0.001760332013879151, "spearman": 0.0017603320138791134, "kendall": 0.0017931965823296848}, "kappa_score": 0.04273578788489718, "total_responses": 1043, "valid_responses": 976, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.341632984383318, "spearman": 0.34163298438331813, "kendall": 0.3416329843833181}, "p_value": {"pearson": 1.1993020035062923e-28, "spearman": 1.1993020035063614e-28, "kendall": 4.45245068721364e-27}, "kappa_score": 0.25207695350847625, "total_responses": 1043, "valid_responses": 996, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.24216249675040344, "spearman": 0.24216249675040333, "kendall": 0.24216249675040336}, "p_value": {"pearson": 3.935445278052117e-15, "spearman": 3.935445278052162e-15, "kendall": 9.527003029060336e-15}, "kappa_score": 0.16347939325246585, "total_responses": 1043, "valid_responses": 1024, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Starling-LM-7B-alpha (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": -0.03373077759415731, "spearman": -0.03373077759415731, "kendall": -0.03373077759415731}, "p_value": {"pearson": 0.2766688432405633, "spearman": 0.27666884324057084, "kendall": 0.2764592748038516}, "kappa_score": -0.020496975856021393, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.1289272485802252, "spearman": 0.1289272485802252, "kendall": 0.1289272485802252}, "p_value": {"pearson": 3.04339920062249e-05, "spearman": 3.043399200622596e-05, "kendall": 3.241804737867977e-05}, "kappa_score": 0.08036845788647418, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": -0.0221078844142691, "spearman": -0.02210788441426909, "kendall": -0.022107884414269096}, "p_value": {"pearson": 0.47719995064060566, "spearman": 0.47719995064057863, "kendall": 0.4769343209266954}, "kappa_score": -0.014234875444839812, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.073854320741183, "spearman": 0.07385432074118302, "kendall": 0.07385432074118302}, "p_value": {"pearson": 0.017213297651258733, "spearman": 0.01721329765125887, "kendall": 0.017285175513725274}, "kappa_score": 0.02841875151809581, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.11542602686723266, "spearman": 0.11542602686723266, "kendall": 0.11542602686723268}, "p_value": {"pearson": 0.0001871452420352966, "spearman": 0.00018714524203530326, "kendall": 0.00019457711210165687}, "kappa_score": 0.07766283771958105, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.22587417693158274, "spearman": 0.2258741769315828, "kendall": 0.2258741769315828}, "p_value": {"pearson": 1.6499323244300206e-13, "spearman": 1.6499323244301094e-13, "kendall": 3.235286820108372e-13}, "kappa_score": 0.1293844058032173, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.11884231526171606, "spearman": 0.11884231526171608, "kendall": 0.11884231526171607}, "p_value": {"pearson": 0.00012411246612923865, "spearman": 0.0001241124661292307, "kendall": 0.0001297051385042296}, "kappa_score": 0.0658162466739709, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.2315963008773999, "spearman": 0.23159630087740007, "kendall": 0.23159630087740007}, "p_value": {"pearson": 4.6663894076603095e-14, "spearman": 4.666389407660458e-14, "kendall": 9.799374521351431e-14}, "kappa_score": 0.17295688240581164, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.3741360919438789, "spearman": 0.37413609194387887, "kendall": 0.37413609194387887}, "p_value": {"pearson": 5.791425232154302e-36, "spearman": 5.79142523215523e-36, "kendall": 1.4970287370025517e-33}, "kappa_score": 0.33574984877390535, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.19003732429656767, "spearman": 0.1900373242965676, "kendall": 0.19003732429656758}, "p_value": {"pearson": 6.761513682892991e-10, "spearman": 6.761513682892663e-10, "kendall": 9.376701062144909e-10}, "kappa_score": 0.10992706081636261, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.07244952849493635, "spearman": 0.07244952849493635, "kendall": 0.07244952849493635}, "p_value": {"pearson": 0.01928041134669363, "spearman": 0.019280411346693872, "kendall": 0.019352385545713828}, "kappa_score": 0.051803571703724294, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.27235091011108026, "spearman": 0.2723509101110802, "kendall": 0.2723509101110802}, "p_value": {"pearson": 3.3979818264387813e-19, "spearman": 3.3979818264388723e-19, "kendall": 1.4758394032612486e-18}, "kappa_score": 0.16358769038451326, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.11644057878669278, "spearman": 0.11644057878669271, "kendall": 0.11644057878669271}, "p_value": {"pearson": 0.00016521184212001173, "spearman": 0.00016521184212001634, "kendall": 0.0001720306949286278}, "kappa_score": 0.04493460574742969, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.5480734623835987, "spearman": 0.5480734623835986, "kendall": 0.5480734623835986}, "p_value": {"pearson": 7.991534480507356e-83, "spearman": 7.991534480507753e-83, "kendall": 4.847958685621739e-70}, "kappa_score": 0.5139883203727798, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.3982495649780072, "spearman": 0.39824956497800706, "kendall": 0.39824956497800706}, "p_value": {"pearson": 7.361520769025928e-41, "spearman": 7.361520769025909e-41, "kendall": 1.0175894808552785e-37}, "kappa_score": 0.3398957730167922, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.1924800060118748, "spearman": 0.19248000601187482, "kendall": 0.19248000601187482}, "p_value": {"pearson": 3.7409911280961045e-10, "spearman": 3.7409911280958383e-10, "kendall": 5.289120467677632e-10}, "kappa_score": 0.14198743259022284, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.09495125991617473, "spearman": 0.09495125991617472, "kendall": 0.09495125991617473}, "p_value": {"pearson": 0.002142307250447491, "spearman": 0.002142307250447501, "kendall": 0.002176488750220529}, "kappa_score": 0.08077264216024449, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.048205282500444466, "spearman": 0.04820528250044442, "kendall": 0.04820528250044442}, "p_value": {"pearson": 0.12009954236313279, "spearman": 0.12009954236313558, "kendall": 0.12004764353599452}, "kappa_score": 0.04536018874373693, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.4303896821842323, "spearman": 0.4303896821842322, "kendall": 0.43038968218423224}, "p_value": {"pearson": 2.8164656016654734e-48, "spearman": 2.816465601666008e-48, "kendall": 6.985752845517994e-44}, "kappa_score": 0.40802122723499656, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.2203570575466266, "spearman": 0.22035705754662657, "kendall": 0.22035705754662657}, "p_value": {"pearson": 6.170990255577879e-13, "spearman": 6.170990255577217e-13, "kendall": 1.1343928079651489e-12}, "kappa_score": 0.12346859314885783, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.41498170289494657, "spearman": 0.4149817028949468, "kendall": 0.4149817028949468}, "p_value": {"pearson": 1.1235818623849157e-44, "spearman": 1.1235818623847626e-44, "kendall": 6.413848725468531e-41}, "kappa_score": 0.34479286783814955, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.10302814761801612, "spearman": 0.10302814761801608, "kendall": 0.1030281476180161}, "p_value": {"pearson": 0.0009178517722499351, "spearman": 0.000917851772249925, "kendall": 0.0009391441427008426}, "kappa_score": 0.08400321543408362, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.3620743918720355, "spearman": 0.3620743918720359, "kendall": 0.3620743918720359}, "p_value": {"pearson": 2.720133353138861e-33, "spearman": 2.7201333531384327e-33, "kendall": 3.250864968604034e-31}, "kappa_score": 0.36205797877744017, "total_responses": 1043, "valid_responses": 1031, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.23688825511014938, "spearman": 0.23688825511014935, "kendall": 0.23688825511014935}, "p_value": {"pearson": 9.05644661923443e-15, "spearman": 9.056446619234263e-15, "kendall": 2.0610849858628e-14}, "kappa_score": 0.12174440919594254, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.29219175205334713, "spearman": 0.2921917520533471, "kendall": 0.2921917520533471}, "p_value": {"pearson": 7.043256443266301e-22, "spearman": 7.04325644326589e-22, "kendall": 4.9945041871208546e-21}, "kappa_score": 0.2606295943536767, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.18866009713483578, "spearman": 0.18866009713483572, "kendall": 0.18866009713483572}, "p_value": {"pearson": 8.681741263113062e-10, "spearman": 8.68174126311272e-10, "kendall": 1.1930159230706147e-09}, "kappa_score": 0.11695284769643788, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.12881562370632205, "spearman": 0.12881562370632213, "kendall": 0.12881562370632213}, "p_value": {"pearson": 3.092393952721206e-05, "spearman": 3.0923939527211545e-05, "kendall": 3.2932111010756525e-05}, "kappa_score": 0.06542056074766367, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.2250709075340266, "spearman": 0.2250709075340266, "kendall": 0.22507090753402662}, "p_value": {"pearson": 1.9659454335330325e-13, "spearman": 1.9659454335330886e-13, "kendall": 3.819517748483993e-13}, "kappa_score": 0.11258271309266965, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.25122233700545155, "spearman": 0.2512223370054514, "kendall": 0.25122233700545143}, "p_value": {"pearson": 1.8395495358371022e-16, "spearman": 1.8395495358370768e-16, "kendall": 5.24983606311008e-16}, "kappa_score": 0.13652763271048662, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.1110560363415114, "spearman": 0.11105603634151147, "kendall": 0.11105603634151148}, "p_value": {"pearson": 0.00032852255125153106, "spearman": 0.00032852255125151973, "kendall": 0.00033944823672676824}, "kappa_score": 0.03470802300089326, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.14309469782667017, "spearman": 0.14309469782667011, "kendall": 0.1430946978266701}, "p_value": {"pearson": 3.929427518335992e-06, "spearman": 3.929427518336175e-06, "kendall": 4.334665397436809e-06}, "kappa_score": 0.07913522333265344, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.05507775213352384, "spearman": 0.05507775213352386, "kendall": 0.05507775213352387}, "p_value": {"pearson": 0.07653865799761672, "spearman": 0.07653865799761148, "kendall": 0.07654855348489621}, "kappa_score": 0.021543179022919245, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.0763464388746854, "spearman": 0.07634643887468533, "kendall": 0.07634643887468533}, "p_value": {"pearson": 0.014018405494649068, "spearman": 0.014018405494648816, "kendall": 0.014088999976474753}, "kappa_score": 0.0622876557191393, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.6211164952883419, "spearman": 0.6211164952883419, "kendall": 0.6211164952883419}, "p_value": {"pearson": 5.469421038016497e-112, "spearman": 5.469421038015875e-112, "kendall": 3.630464434204006e-89}, "kappa_score": 0.6010021922956468, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.7821494507669434, "spearman": 0.7821494507669431, "kendall": 0.7821494507669433}, "p_value": {"pearson": 4.527314893527067e-215, "spearman": 4.527314893529699e-215, "kendall": 5.539017121048223e-140}, "kappa_score": 0.7806406851838561, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.3047090060201903, "spearman": 0.30470900602019035, "kendall": 0.30470900602019035}, "p_value": {"pearson": 7.928482386664298e-24, "spearman": 7.92848238666333e-24, "kendall": 8.255168438422002e-23}, "kappa_score": 0.2560763854554371, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.2091556727103851, "spearman": 0.20915567271038518, "kendall": 0.20915567271038518}, "p_value": {"pearson": 9.817272633840575e-12, "spearman": 9.817272633841098e-12, "kendall": 1.5994308005104305e-11}, "kappa_score": 0.20672850436166934, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.1919199127260166, "spearman": 0.19191991272601647, "kendall": 0.19191991272601647}, "p_value": {"pearson": 4.379030033618828e-10, "spearman": 4.379030033618782e-10, "kendall": 6.161035391897699e-10}, "kappa_score": 0.12290299051787013, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.05939385097491499, "spearman": 0.05939385097491498, "kendall": 0.05939385097491496}, "p_value": {"pearson": 0.05552040707028259, "spearman": 0.05552040707027906, "kendall": 0.055559738569985126}, "kappa_score": 0.043824701195219196, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.08380123763971664, "spearman": 0.08380123763971663, "kendall": 0.08380123763971663}, "p_value": {"pearson": 0.006797176408587927, "spearman": 0.006797176408588134, "kendall": 0.006854995151361859}, "kappa_score": 0.05093126138518145, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.04923604431869985, "spearman": 0.04923604431869982, "kendall": 0.049236044318699816}, "p_value": {"pearson": 0.11236951497353243, "spearman": 0.11236951497353519, "kendall": 0.11232824207120194}, "kappa_score": 0.015339127673929531, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.015374826467643016, "spearman": 0.015374826467643028, "kendall": 0.015374826467643024}, "p_value": {"pearson": 0.6244916641251298, "spearman": 0.6244916641250947, "kendall": 0.6242559053391814}, "kappa_score": 0.014792960448946846, "total_responses": 1043, "valid_responses": 1016, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.020324545359594798, "spearman": 0.020324545359594822, "kendall": 0.020324545359594826}, "p_value": {"pearson": 0.5136616885674918, "spearman": 0.5136616885674926, "kendall": 0.5133995454265008}, "kappa_score": 0.010626866488867903, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.028298196735212486, "spearman": 0.028298196735212482, "kendall": 0.02829819673521248}, "p_value": {"pearson": 0.3626350639628412, "spearman": 0.3626350639628517, "kendall": 0.36238350208996783}, "kappa_score": 0.010922697383504931, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.08270618540930533, "spearman": 0.08270618540930529, "kendall": 0.08270618540930529}, "p_value": {"pearson": 0.007976043496156611, "spearman": 0.007976043496156356, "kendall": 0.008037940142756267}, "kappa_score": 0.02026758247586702, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.18999131259432078, "spearman": 0.18999131259432078, "kendall": 0.18999131259432075}, "p_value": {"pearson": 6.331314765893982e-10, "spearman": 6.331314765893679e-10, "kendall": 8.788972810542182e-10}, "kappa_score": 0.18874111526342785, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.03820101783720019, "spearman": 0.03820101783720018, "kendall": 0.03820101783720019}, "p_value": {"pearson": 0.21791194181661552, "spearman": 0.21791194181662654, "kendall": 0.21774820039129594}, "kappa_score": 0.02799514930400815, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.09637692336903902, "spearman": 0.09637692336903904, "kendall": 0.09637692336903905}, "p_value": {"pearson": 0.0018895262366462892, "spearman": 0.0018895262366461962, "kendall": 0.001921662866970796}, "kappa_score": 0.029724513458772583, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.10291413043166518, "spearman": 0.10291413043166514, "kendall": 0.10291413043166514}, "p_value": {"pearson": 0.0009036968843048094, "spearman": 0.0009036968843048033, "kendall": 0.0009246864839069358}, "kappa_score": 0.07316317318877352, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.13714100143747623, "spearman": 0.13714100143747623, "kendall": 0.13714100143747626}, "p_value": {"pearson": 9.718943416500055e-06, "spearman": 9.718943416500537e-06, "kendall": 1.054810955908058e-05}, "kappa_score": 0.09521250124415248, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.17497557754399481, "spearman": 0.17497557754399504, "kendall": 0.1749755775439951}, "p_value": {"pearson": 1.3264974927293998e-08, "spearman": 1.3264974927292978e-08, "kendall": 1.673136346006127e-08}, "kappa_score": 0.1591685399818995, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.04964655535027367, "spearman": 0.0496465553502736, "kendall": 0.04964655535027359}, "p_value": {"pearson": 0.11887809117887845, "spearman": 0.11887809117887847, "kendall": 0.1188251668650225}, "kappa_score": 0.029043148499283244, "total_responses": 1043, "valid_responses": 988, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.4762843354319412, "spearman": 0.476284335431941, "kendall": 0.47628433543194104}, "p_value": {"pearson": 1.9277559089901808e-59, "spearman": 1.9277559089903694e-59, "kendall": 1.0674803549972575e-52}, "kappa_score": 0.47547476747886974, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.2845428856003752, "spearman": 0.2845428856003751, "kendall": 0.2845428856003751}, "p_value": {"pearson": 1.0818483902262498e-20, "spearman": 1.081848390226236e-20, "kendall": 6.19513302090756e-20}, "kappa_score": 0.17380379506388433, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.14335303129326837, "spearman": 0.14335303129326848, "kendall": 0.14335303129326846}, "p_value": {"pearson": 3.940263795084588e-06, "spearman": 3.94026379508457e-06, "kendall": 4.348048584032187e-06}, "kappa_score": 0.14322288324461718, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.12979303169101716, "spearman": 0.1297930316910171, "kendall": 0.1297930316910171}, "p_value": {"pearson": 2.663735321731985e-05, "spearman": 2.6637353217320673e-05, "kendall": 2.8428924652771115e-05}, "kappa_score": 0.0650829748563807, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.425583694490143, "spearman": 0.425583694490143, "kendall": 0.425583694490143}, "p_value": {"pearson": 6.4712605550298445e-47, "spearman": 6.471260555029963e-47, "kendall": 9.49603838467482e-43}, "kappa_score": 0.42552636364355123, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.3060874155481723, "spearman": 0.3060874155481725, "kendall": 0.3060874155481724}, "p_value": {"pearson": 5.3790912939058446e-24, "spearman": 5.379091293904982e-24, "kendall": 5.82887166086348e-23}, "kappa_score": 0.22540257193498503, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.29960111462830546, "spearman": 0.29960111462830563, "kendall": 0.2996011146283056}, "p_value": {"pearson": 9.168877014831827e-23, "spearman": 9.168877014830914e-23, "kendall": 7.896597785922696e-22}, "kappa_score": 0.20543532311417623, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.4601614855413216, "spearman": 0.46016148554132197, "kendall": 0.46016148554132197}, "p_value": {"pearson": 1.1128027867647714e-55, "spearman": 1.1128027867644664e-55, "kendall": 8.10429640209579e-50}, "kappa_score": 0.4115851590585362, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.17490364038560358, "spearman": 0.17490364038560374, "kendall": 0.17490364038560371}, "p_value": {"pearson": 1.4338767784169875e-08, "spearman": 1.433876778416961e-08, "kendall": 1.8061189199718497e-08}, "kappa_score": 0.10716507310080048, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.3638369382133031, "spearman": 0.3638369382133032, "kendall": 0.36383693821330326}, "p_value": {"pearson": 6.206253279328185e-34, "spearman": 6.206253279327331e-34, "kendall": 8.594751611270364e-32}, "kappa_score": 0.33347561626293887, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.2391184297337688, "spearman": 0.23911842973376887, "kendall": 0.23911842973376887}, "p_value": {"pearson": 5.304099130559318e-15, "spearman": 5.304099130558846e-15, "kendall": 1.2450577082449088e-14}, "kappa_score": 0.1984010836830712, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Meta-Llama-3.1-8B-Instruct (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": 0.10639077988507004, "spearman": 0.10639077988507006, "kendall": 0.10639077988507006}, "p_value": {"pearson": 0.0006535471580334884, "spearman": 0.0006535471580334918, "kendall": 0.0006709597091346492}, "kappa_score": 0.05346933868154502, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.18496649751392868, "spearman": 0.1849664975139286, "kendall": 0.18496649751392863}, "p_value": {"pearson": 2.2216280783485104e-09, "spearman": 2.2216280783484897e-09, "kendall": 2.967955841804279e-09}, "kappa_score": 0.15303384402319742, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": -0.020091087160853435, "spearman": -0.020091087160853414, "kendall": -0.02009108716085341}, "p_value": {"pearson": 0.52735062431865, "spearman": 0.5273506243186533, "kendall": 0.5270794873706655}, "kappa_score": -0.010420747473164793, "total_responses": 1043, "valid_responses": 992, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.034647246948972546, "spearman": 0.03464724694897254, "kendall": 0.03464724694897254}, "p_value": {"pearson": 0.2732112892239381, "spearman": 0.27321128922392823, "kendall": 0.2729957074086068}, "kappa_score": 0.01725741895936239, "total_responses": 1043, "valid_responses": 1002, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.10779445194661025, "spearman": 0.10779445194661007, "kendall": 0.10779445194661008}, "p_value": {"pearson": 0.0006678501633767201, "spearman": 0.000667850163376718, "kendall": 0.0006860417630006885}, "kappa_score": 0.0608718080990458, "total_responses": 1043, "valid_responses": 993, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.40293495422785386, "spearman": 0.4029349542278539, "kendall": 0.4029349542278539}, "p_value": {"pearson": 1.2355829630956456e-40, "spearman": 1.2355829630954018e-40, "kendall": 1.9521072720245763e-37}, "kappa_score": 0.3508418428332365, "total_responses": 1043, "valid_responses": 1008, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.1863633472446831, "spearman": 0.1863633472446831, "kendall": 0.1863633472446831}, "p_value": {"pearson": 2.8842991374166045e-09, "spearman": 2.8842991374166913e-09, "kendall": 3.8531068436060965e-09}, "kappa_score": 0.09352597636247895, "total_responses": 1043, "valid_responses": 1000, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.46115382137230015, "spearman": 0.4611538213723002, "kendall": 0.4611538213723001}, "p_value": {"pearson": 7.557372689632323e-55, "spearman": 7.557372689631426e-55, "kendall": 4.7366505091612186e-49}, "kappa_score": 0.41777045522359024, "total_responses": 1043, "valid_responses": 1020, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.48529279674916337, "spearman": 0.48529279674916326, "kendall": 0.4852927967491632}, "p_value": {"pearson": 2.5746049904898295e-62, "spearman": 2.5746049904900355e-62, "kendall": 5.9792400557594636e-55}, "kappa_score": 0.41586859365024087, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.18160536615056094, "spearman": 0.18160536615056083, "kendall": 0.1816053661505608}, "p_value": {"pearson": 8.38140868153491e-09, "spearman": 8.38140868153555e-09, "kendall": 1.084436862982305e-08}, "kappa_score": 0.10398150155358044, "total_responses": 1043, "valid_responses": 992, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.24036371956111802, "spearman": 0.24036371956111796, "kendall": 0.240363719561118}, "p_value": {"pearson": 1.2725362214576864e-14, "spearman": 1.2725362214577042e-14, "kendall": 2.9392332138724293e-14}, "kappa_score": 0.1875777983466853, "total_responses": 1043, "valid_responses": 1001, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.4135749249473899, "spearman": 0.41357492494739007, "kendall": 0.41357492494739}, "p_value": {"pearson": 4.790145132431253e-43, "spearman": 4.790145132430982e-43, "kendall": 1.8516064291161794e-39}, "kappa_score": 0.3610039194780491, "total_responses": 1043, "valid_responses": 1011, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.32036264318499885, "spearman": 0.320362643184999, "kendall": 0.32036264318499896}, "p_value": {"pearson": 1.2387716518234593e-25, "spearman": 1.2387716518234568e-25, "kendall": 2.057719410053163e-24}, "kappa_score": 0.20967438358742718, "total_responses": 1043, "valid_responses": 1014, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.8580055941281819, "spearman": 0.8580055941281819, "kendall": 0.8580055941281819}, "p_value": {"pearson": 1.0465943674778711e-299, "spearman": 1.0465943674777982e-299, "kendall": 9.28369591070896e-167}, "kappa_score": 0.8523273966928984, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.339974446249218, "spearman": 0.33997444624921797, "kendall": 0.339974446249218}, "p_value": {"pearson": 1.2252470522377573e-28, "spearman": 1.225247052237781e-28, "kendall": 4.3833796718783086e-27}, "kappa_score": 0.21801062992508524, "total_responses": 1043, "valid_responses": 1006, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.3528633691058125, "spearman": 0.35286336910581245, "kendall": 0.3528633691058124}, "p_value": {"pearson": 7.241603070456891e-31, "spearman": 7.241603070457421e-31, "kendall": 4.754452750122087e-29}, "kappa_score": 0.35260304752347815, "total_responses": 1043, "valid_responses": 1006, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.09931408628643446, "spearman": 0.0993140862864345, "kendall": 0.0993140862864345}, "p_value": {"pearson": 0.0013784502031369099, "spearman": 0.0013784502031369454, "kendall": 0.0014054430228627776}, "kappa_score": 0.038239517923013944, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.009803042006394048, "spearman": 0.009803042006394027, "kendall": 0.009803042006394029}, "p_value": {"pearson": 0.7575599875534995, "spearman": 0.7575599875535021, "kendall": 0.7573880848582595}, "kappa_score": 0.009284039941674926, "total_responses": 1043, "valid_responses": 994, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.5741670227883544, "spearman": 0.5741670227883545, "kendall": 0.5741670227883545}, "p_value": {"pearson": 3.35547855246895e-89, "spearman": 3.3554785524684994e-89, "kendall": 5.860573524089668e-74}, "kappa_score": 0.5684453183266662, "total_responses": 1043, "valid_responses": 1005, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.3891700327381272, "spearman": 0.3891700327381273, "kendall": 0.3891700327381272}, "p_value": {"pearson": 7.173592165003401e-39, "spearman": 7.17359216500335e-39, "kendall": 4.9736551139181326e-36}, "kappa_score": 0.3038827939608625, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.4546988143650772, "spearman": 0.45469881436507725, "kendall": 0.4546988143650773}, "p_value": {"pearson": 2.383499638835621e-49, "spearman": 2.3834996388353552e-49, "kendall": 2.620519645046501e-44}, "kappa_score": 0.3798893422486168, "total_responses": 1043, "valid_responses": 944, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.10964280462046053, "spearman": 0.1096428046204605, "kendall": 0.10964280462046049}, "p_value": {"pearson": 0.0005140048148630414, "spearman": 0.0005140048148630566, "kendall": 0.0005292940059421045}, "kappa_score": 0.09251471004381295, "total_responses": 1043, "valid_responses": 1000, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.5145297170618814, "spearman": 0.5145297170618811, "kendall": 0.514529717061881}, "p_value": {"pearson": 1.9805232957874315e-71, "spearman": 1.980523295787845e-71, "kendall": 7.819865241594197e-62}, "kappa_score": 0.46423057128152345, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.5552584485314853, "spearman": 0.5552584485314851, "kendall": 0.555258448531485}, "p_value": {"pearson": 8.434790348153531e-84, "spearman": 8.43479034815532e-84, "kendall": 1.695835932234239e-70}, "kappa_score": 0.5447392341779342, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.5274938760670423, "spearman": 0.5274938760670422, "kendall": 0.5274938760670422}, "p_value": {"pearson": 9.003820228764659e-75, "spearman": 9.003820228765389e-75, "kendall": 3.624548543452664e-64}, "kappa_score": 0.47032304665122426, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.43397927639763534, "spearman": 0.4339792763976351, "kendall": 0.4339792763976352}, "p_value": {"pearson": 2.2778005610627942e-48, "spearman": 2.277800561063073e-48, "kendall": 6.87671655972956e-44}, "kappa_score": 0.35679543440195416, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.13425782905055542, "spearman": 0.13425782905055533, "kendall": 0.13425782905055533}, "p_value": {"pearson": 2.6007196447661354e-05, "spearman": 2.600719644766239e-05, "kendall": 2.788942572889493e-05}, "kappa_score": 0.07641656558655352, "total_responses": 1043, "valid_responses": 975, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.3459724921882662, "spearman": 0.34597249218826615, "kendall": 0.34597249218826615}, "p_value": {"pearson": 1.3921241519795474e-30, "spearman": 1.39212415197959e-30, "kendall": 7.444154429196185e-29}, "kappa_score": 0.2871248732175885, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.2988683593976869, "spearman": 0.2988683593976868, "kendall": 0.29886835939768686}, "p_value": {"pearson": 8.452723222557858e-23, "spearman": 8.452723222557475e-23, "kendall": 7.228718817627273e-22}, "kappa_score": 0.2672578108231918, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.15963663171931966, "spearman": 0.15963663171931952, "kendall": 0.15963663171931955}, "p_value": {"pearson": 2.637702879874343e-07, "spearman": 2.6377028798741926e-07, "kendall": 3.0823692655368027e-07}, "kappa_score": 0.0766509207211944, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.2231128107130445, "spearman": 0.22311281071304445, "kendall": 0.22311281071304445}, "p_value": {"pearson": 4.734377801526665e-13, "spearman": 4.734377801526916e-13, "kendall": 8.896731635158576e-13}, "kappa_score": 0.11148556928300712, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.1789513491752121, "spearman": 0.1789513491752122, "kendall": 0.17895134917521216}, "p_value": {"pearson": 8.6768328103287e-09, "spearman": 8.676832810328444e-09, "kendall": 1.113640928382399e-08}, "kappa_score": 0.10451154888300807, "total_responses": 1043, "valid_responses": 1020, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.13630322673003387, "spearman": 0.13630322673003384, "kendall": 0.13630322673003387}, "p_value": {"pearson": 1.8745991886118868e-05, "spearman": 1.8745991886118376e-05, "kendall": 2.020532909553999e-05}, "kappa_score": 0.1076934050866667, "total_responses": 1043, "valid_responses": 979, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.6607288329993782, "spearman": 0.6607288329993782, "kendall": 0.6607288329993783}, "p_value": {"pearson": 3.2229944127950833e-129, "spearman": 3.2229944127949904e-129, "kendall": 6.1278384030918255e-99}, "kappa_score": 0.6077877755771959, "total_responses": 1043, "valid_responses": 1022, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.9156843298394175, "spearman": 0.9156843298394173, "kendall": 0.9156843298394174}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 1.2171874258881199e-187}, "kappa_score": 0.9151568640511557, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.4885351092263689, "spearman": 0.48853510922636884, "kendall": 0.4885351092263687}, "p_value": {"pearson": 5.203152355074474e-63, "spearman": 5.203152355075551e-63, "kendall": 1.8719093189328536e-55}, "kappa_score": 0.4137939459089688, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.18116209237063202, "spearman": 0.1811620923706319, "kendall": 0.1811620923706319}, "p_value": {"pearson": 4.672022215214404e-09, "spearman": 4.6720222152144985e-09, "kendall": 6.094417206976184e-09}, "kappa_score": 0.11086387871106684, "total_responses": 1043, "valid_responses": 1031, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.2716925500567069, "spearman": 0.27169255005670684, "kendall": 0.27169255005670684}, "p_value": {"pearson": 6.141084189612989e-19, "spearman": 6.141084189613022e-19, "kendall": 2.5908485369537226e-18}, "kappa_score": 0.15285201908921153, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.13761175197348874, "spearman": 0.13761175197348868, "kendall": 0.13761175197348868}, "p_value": {"pearson": 9.327752978236761e-06, "spearman": 9.32775297823684e-06, "kendall": 1.013308455303056e-05}, "kappa_score": 0.06703670309126553, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.10511973251687415, "spearman": 0.1051197325168741, "kendall": 0.10511973251687412}, "p_value": {"pearson": 0.0007190047891667531, "spearman": 0.000719004789166754, "kendall": 0.0007373276471574482}, "kappa_score": 0.053852012750712275, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.12813783898387643, "spearman": 0.12813783898387643, "kendall": 0.12813783898387646}, "p_value": {"pearson": 4.463809144148237e-05, "spearman": 4.463809144148234e-05, "kendall": 4.7367491367776934e-05}, "kappa_score": 0.04314660399956183, "total_responses": 1043, "valid_responses": 1009, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.03882543405289257, "spearman": 0.03882543405289263, "kendall": 0.03882543405289263}, "p_value": {"pearson": 0.26243437964138866, "spearman": 0.26243437964138744, "kendall": 0.26218488003798535}, "kappa_score": 0.01913838252568889, "total_responses": 1043, "valid_responses": 835, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.11429846697798884, "spearman": 0.11429846697798887, "kendall": 0.11429846697798889}, "p_value": {"pearson": 0.0005832666379336916, "spearman": 0.0005832666379336894, "kendall": 0.000601674459963624}, "kappa_score": 0.06187544584249993, "total_responses": 1043, "valid_responses": 902, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.1439471316820841, "spearman": 0.1439471316820841, "kendall": 0.1439471316820841}, "p_value": {"pearson": 5.999661337344028e-06, "spearman": 5.999661337344182e-06, "kendall": 6.598085529223838e-06}, "kappa_score": 0.052189226742495154, "total_responses": 1043, "valid_responses": 981, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.06180365263531887, "spearman": 0.06180365263531877, "kendall": 0.061803652635318784}, "p_value": {"pearson": 0.05261180946420489, "spearman": 0.05261180946420408, "kendall": 0.052657457867409836}, "kappa_score": 0.01609949555662915, "total_responses": 1043, "valid_responses": 984, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.23160471034863245, "spearman": 0.23160471034863253, "kendall": 0.23160471034863253}, "p_value": {"pearson": 5.357030234192694e-14, "spearman": 5.3570302341927564e-14, "kendall": 1.120901834258826e-13}, "kappa_score": 0.23094546076252354, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.415536666577521, "spearman": 0.4155366665775209, "kendall": 0.41553666657752086}, "p_value": {"pearson": 1.609233477519391e-43, "spearman": 1.6092334775195406e-43, "kendall": 7.43167318474106e-40}, "kappa_score": 0.3252634577043577, "total_responses": 1043, "valid_responses": 1012, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.11470667391199359, "spearman": 0.11470667391199361, "kendall": 0.11470667391199361}, "p_value": {"pearson": 0.0004902867587354635, "spearman": 0.0004902867587354617, "kendall": 0.0005064259911491653}, "kappa_score": 0.04069275067750666, "total_responses": 1043, "valid_responses": 920, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.24449760572051546, "spearman": 0.2444976057205154, "kendall": 0.2444976057205154}, "p_value": {"pearson": 6.594944886221717e-14, "spearman": 6.59494488622154e-14, "kendall": 1.4937603555533453e-13}, "kappa_score": 0.14532254882619844, "total_responses": 1043, "valid_responses": 914, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.12730868111182908, "spearman": 0.12730868111182908, "kendall": 0.12730868111182905}, "p_value": {"pearson": 5.1353388077603304e-05, "spearman": 5.1353388077606645e-05, "kendall": 5.439197594172207e-05}, "kappa_score": 0.06528491406009784, "total_responses": 1043, "valid_responses": 1006, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.27145858932141254, "spearman": 0.2714585893214125, "kendall": 0.2714585893214124}, "p_value": {"pearson": 1.010273018765039e-18, "spearman": 1.010273018764999e-18, "kendall": 4.1741700500026454e-18}, "kappa_score": 0.19858147727671727, "total_responses": 1043, "valid_responses": 1022, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.07312379861161775, "spearman": 0.0731237986116177, "kendall": 0.07312379861161772}, "p_value": {"pearson": 0.019449686352750174, "spearman": 0.019449686352750368, "kendall": 0.019523220952184648}, "kappa_score": 0.020243960951484508, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.6903405421422498, "spearman": 0.6903405421422498, "kendall": 0.6903405421422499}, "p_value": {"pearson": 1.9392694174394319e-143, "spearman": 1.9392694174390802e-143, "kendall": 2.843719254269518e-106}, "kappa_score": 0.6852638628909, "total_responses": 1043, "valid_responses": 1007, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.2857676671066785, "spearman": 0.2857676671066784, "kendall": 0.28576766710667834}, "p_value": {"pearson": 7.600224143796321e-21, "spearman": 7.600224143796023e-21, "kendall": 4.483670522978827e-20}, "kappa_score": 0.17554927723071012, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.16224431618012833, "spearman": 0.16224431618012825, "kendall": 0.16224431618012825}, "p_value": {"pearson": 5.551562902568506e-07, "spearman": 5.551562902568533e-07, "kendall": 6.459007900127622e-07}, "kappa_score": 0.1591152543354274, "total_responses": 1043, "valid_responses": 942, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.275929759860289, "spearman": 0.27592975986028895, "kendall": 0.2759297598602889}, "p_value": {"pearson": 3.699788809923718e-19, "spearman": 3.699788809923948e-19, "kendall": 1.6661002137148726e-18}, "kappa_score": 0.22088448454370646, "total_responses": 1043, "valid_responses": 1013, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.5451213081665416, "spearman": 0.545121308166541, "kendall": 0.5451213081665413}, "p_value": {"pearson": 5.122414148034582e-79, "spearman": 5.1224141480371146e-79, "kendall": 5.606229951921899e-67}, "kappa_score": 0.5374762651110154, "total_responses": 1043, "valid_responses": 1007, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.42185872783686, "spearman": 0.4218587278368602, "kendall": 0.4218587278368601}, "p_value": {"pearson": 2.995842526694322e-44, "spearman": 2.995842526693785e-44, "kendall": 2.1091286418190675e-40}, "kappa_score": 0.4216987392169874, "total_responses": 1043, "valid_responses": 996, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.3344106241392558, "spearman": 0.33441062413925576, "kendall": 0.3344106241392559}, "p_value": {"pearson": 4.649855565778262e-27, "spearman": 4.649855565778606e-27, "kendall": 1.2027275581036692e-25}, "kappa_score": 0.3157405254591955, "total_responses": 1043, "valid_responses": 981, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.5806244967588189, "spearman": 0.5806244967588189, "kendall": 0.5806244967588188}, "p_value": {"pearson": 3.4038673445242185e-91, "spearman": 3.4038673445238833e-91, "kendall": 3.194964729592492e-75}, "kappa_score": 0.562157935887412, "total_responses": 1043, "valid_responses": 1000, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.13596034241350502, "spearman": 0.13596034241350496, "kendall": 0.135960342413505}, "p_value": {"pearson": 2.5646318314936595e-05, "spearman": 2.5646318314936145e-05, "kendall": 2.755515671693994e-05}, "kappa_score": 0.06911402789171472, "total_responses": 1043, "valid_responses": 952, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.3352544801153253, "spearman": 0.33525448011532527, "kendall": 0.33525448011532527}, "p_value": {"pearson": 4.872107863945474e-27, "spearman": 4.8721078639452964e-27, "kendall": 1.2781580026179022e-25}, "kappa_score": 0.2671138638451632, "total_responses": 1043, "valid_responses": 975, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.08702286483875998, "spearman": 0.08702286483875998, "kendall": 0.08702286483876001}, "p_value": {"pearson": 0.006069385750772347, "spearman": 0.006069385750772599, "kendall": 0.006127583431138492}, "kappa_score": 0.0366726010895172, "total_responses": 1043, "valid_responses": 993, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": 0.08856468267121832, "spearman": 0.08856468267121831, "kendall": 0.08856468267121832}, "p_value": {"pearson": 0.00536360550607019, "spearman": 0.005363605506070047, "kendall": 0.0054193832835484155}, "kappa_score": 0.028726189864968776, "total_responses": 1043, "valid_responses": 987, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.08299738377311124, "spearman": 0.08299738377311125, "kendall": 0.08299738377311125}, "p_value": {"pearson": 0.013359016670481874, "spearman": 0.01335901667048189, "kendall": 0.01344071289922173}, "kappa_score": 0.07764460656591965, "total_responses": 1043, "valid_responses": 888, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": -0.021271786426907635, "spearman": -0.021271786426907607, "kendall": -0.021271786426907607}, "p_value": {"pearson": 0.5340183408649536, "spearman": 0.5340183408649526, "kendall": 0.5337059542708718}, "kappa_score": -0.0038380783278535446, "total_responses": 1043, "valid_responses": 857, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.08760001797174682, "spearman": 0.08760001797174684, "kendall": 0.08760001797174684}, "p_value": {"pearson": 0.005270376314566696, "spearman": 0.0052703763145666264, "kendall": 0.005324328522963925}, "kappa_score": 0.05455072090628221, "total_responses": 1043, "valid_responses": 1013, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.021828915455900957, "spearman": 0.021828915455900988, "kendall": 0.021828915455900988}, "p_value": {"pearson": 0.5260453484719303, "spearman": 0.5260453484719301, "kendall": 0.5257270324362537}, "kappa_score": 0.007532446850863961, "total_responses": 1043, "valid_responses": 846, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.08024653339617141, "spearman": 0.08024653339617147, "kendall": 0.08024653339617145}, "p_value": {"pearson": 0.014907604282109209, "spearman": 0.014907604282109237, "kendall": 0.014987759943086626}, "kappa_score": 0.03812312536958262, "total_responses": 1043, "valid_responses": 920, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.014774879208241158, "spearman": 0.01477487920824117, "kendall": 0.014774879208241172}, "p_value": {"pearson": 0.6542951858509991, "spearman": 0.6542951858509991, "kendall": 0.6540490764937656}, "kappa_score": 0.003120534018343224, "total_responses": 1043, "valid_responses": 921, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": -0.029216154827443906, "spearman": -0.029216154827443892, "kendall": -0.029216154827443892}, "p_value": {"pearson": 0.3623850859602439, "spearman": 0.36238508596024477, "kendall": 0.36211731231468836}, "kappa_score": -0.00773078807131089, "total_responses": 1043, "valid_responses": 974, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.06315270977062573, "spearman": 0.0631527097706257, "kendall": 0.0631527097706257}, "p_value": {"pearson": 0.05254082084560761, "spearman": 0.05254082084560749, "kendall": 0.0525885666461219}, "kappa_score": 0.019636941957377085, "total_responses": 1043, "valid_responses": 943, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.09674703688742238, "spearman": 0.0967470368874224, "kendall": 0.09674703688742238}, "p_value": {"pearson": 0.002442628462744989, "spearman": 0.0024426284627449744, "kendall": 0.00248165555138776}, "kappa_score": 0.034218281753201296, "total_responses": 1043, "valid_responses": 979, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": -0.023900335087238253, "spearman": -0.02390033508723826, "kendall": -0.02390033508723826}, "p_value": {"pearson": 0.4700050309879843, "spearman": 0.47000503098798285, "kendall": 0.4697041856748513}, "kappa_score": -0.00790455929374878, "total_responses": 1043, "valid_responses": 916, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.1218898218820016, "spearman": 0.12188982188200159, "kendall": 0.12188982188200159}, "p_value": {"pearson": 0.00020730997663957098, "spearman": 0.00020730997663957328, "kendall": 0.00021635673900056285}, "kappa_score": 0.05651537031073073, "total_responses": 1043, "valid_responses": 922, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.035783828719141195, "spearman": 0.03578382871914118, "kendall": 0.03578382871914119}, "p_value": {"pearson": 0.306980702398927, "spearman": 0.30698070239892805, "kendall": 0.3066906956811858}, "kappa_score": 0.013620071684587787, "total_responses": 1043, "valid_responses": 817, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.16475086843343048, "spearman": 0.16475086843343043, "kendall": 0.1647508684334304}, "p_value": {"pearson": 2.4719030277630794e-07, "spearman": 2.4719030277630836e-07, "kendall": 2.9207379756880163e-07}, "kappa_score": 0.09313233538627308, "total_responses": 1043, "valid_responses": 970, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.05425316190798637, "spearman": 0.054253161907986396, "kendall": 0.05425316190798639}, "p_value": {"pearson": 0.11700600395734445, "spearman": 0.11700600395734478, "kendall": 0.11694666640772615}, "kappa_score": 0.021765023356224322, "total_responses": 1043, "valid_responses": 836, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.04635529214642464, "spearman": 0.046355292146424615, "kendall": 0.04635529214642462}, "p_value": {"pearson": 0.20938120434372265, "spearman": 0.2093812043437218, "kendall": 0.20916031118030376}, "kappa_score": 0.037317870948557874, "total_responses": 1043, "valid_responses": 735, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.06958042246805039, "spearman": 0.06958042246805037, "kendall": 0.06958042246805038}, "p_value": {"pearson": 0.03625943911713347, "spearman": 0.036259439117133085, "kendall": 0.0363310360334507}, "kappa_score": 0.04403073730432039, "total_responses": 1043, "valid_responses": 906, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": -0.014745581768102334, "spearman": -0.014745581768102322, "kendall": -0.01474558176810232}, "p_value": {"pearson": 0.6434156589177513, "spearman": 0.6434156589177487, "kendall": 0.6431813121888837}, "kappa_score": -0.014734347224965472, "total_responses": 1043, "valid_responses": 988, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.12931499161668647, "spearman": 0.1293149916166865, "kendall": 0.1293149916166865}, "p_value": {"pearson": 4.4482495693821844e-05, "spearman": 4.448249569381967e-05, "kendall": 4.725564022242973e-05}, "kappa_score": 0.06614481877557876, "total_responses": 1043, "valid_responses": 991, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.05884017108505174, "spearman": 0.05884017108505174, "kendall": 0.05884017108505174}, "p_value": {"pearson": 0.07445128685448663, "spearman": 0.0744512868544862, "kendall": 0.07446583562734609}, "kappa_score": 0.011743286299499278, "total_responses": 1043, "valid_responses": 920, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.009906246467605562, "spearman": 0.00990624646760562, "kendall": 0.00990624646760562}, "p_value": {"pearson": 0.7773870727429243, "spearman": 0.777387072742922, "kendall": 0.7771929344734482}, "kappa_score": 0.0011357486922188853, "total_responses": 1043, "valid_responses": 817, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.030469540388343836, "spearman": 0.030469540388343798, "kendall": 0.030469540388343798}, "p_value": {"pearson": 0.39181341432287303, "spearman": 0.3918134143228752, "kendall": 0.3914739774077961}, "kappa_score": 0.006907545164718254, "total_responses": 1043, "valid_responses": 792, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.2897142610095561, "spearman": 0.28971426100955594, "kendall": 0.28971426100955594}, "p_value": {"pearson": 9.910848450685272e-20, "spearman": 9.910848450685887e-20, "kendall": 5.51715560386557e-19}, "kappa_score": 0.251012739975342, "total_responses": 1043, "valid_responses": 945, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.18462669736503656, "spearman": 0.18462669736503665, "kendall": 0.18462669736503667}, "p_value": {"pearson": 2.2504893213803058e-08, "spearman": 2.250489321380212e-08, "kendall": 2.889152737162226e-08}, "kappa_score": 0.08840776570368414, "total_responses": 1043, "valid_responses": 904, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.22847279170075668, "spearman": 0.2284727917007567, "kendall": 0.2284727917007567}, "p_value": {"pearson": 1.4528073566704667e-11, "spearman": 1.452807356670603e-11, "kendall": 2.577256081953807e-11}, "kappa_score": 0.120600476410065, "total_responses": 1043, "valid_responses": 853, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": -0.03391739907031517, "spearman": -0.03391739907031519, "kendall": -0.0339173990703152}, "p_value": {"pearson": 0.2868468017512296, "spearman": 0.2868468017512389, "kendall": 0.2866190289395587}, "kappa_score": -0.005517672042921085, "total_responses": 1043, "valid_responses": 988, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.04249170584047094, "spearman": 0.04249170584047093, "kendall": 0.04249170584047093}, "p_value": {"pearson": 0.18381385095637928, "spearman": 0.18381385095637978, "kendall": 0.18367582860617793}, "kappa_score": 0.022233613122316864, "total_responses": 1043, "valid_responses": 980, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.05637487400257703, "spearman": 0.05637487400257704, "kendall": 0.056374874002577055}, "p_value": {"pearson": 0.08474291563516147, "spearman": 0.08474291563516213, "kendall": 0.08474071956641457}, "kappa_score": 0.006336115860404279, "total_responses": 1043, "valid_responses": 936, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.08495982211720392, "spearman": 0.08495982211720393, "kendall": 0.08495982211720395}, "p_value": {"pearson": 0.00751082133899732, "spearman": 0.0075108213389976745, "kendall": 0.007573908678652779}, "kappa_score": 0.016409144789234165, "total_responses": 1043, "valid_responses": 989, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.047711720995778445, "spearman": 0.04771172099577845, "kendall": 0.04771172099577845}, "p_value": {"pearson": 0.175451336478139, "spearman": 0.1754513364781397, "kendall": 0.17529574656449864}, "kappa_score": 0.008199702430153666, "total_responses": 1043, "valid_responses": 808, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.06716779053063689, "spearman": 0.06716779053063687, "kendall": 0.06716779053063687}, "p_value": {"pearson": 0.04279549662743475, "spearman": 0.042795496627434926, "kendall": 0.04285875784974277}, "kappa_score": 0.013258811291147365, "total_responses": 1043, "valid_responses": 910, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": -0.010991950558392926, "spearman": -0.010991950558392957, "kendall": -0.010991950558392955}, "p_value": {"pearson": 0.7650000090391484, "spearman": 0.7650000090391478, "kendall": 0.7647757374757828}, "kappa_score": -0.0022942545311526175, "total_responses": 1043, "valid_responses": 742, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.16521660615920652, "spearman": 0.16521660615920644, "kendall": 0.16521660615920644}, "p_value": {"pearson": 3.078163179200295e-06, "spearman": 3.0781631792003605e-06, "kendall": 3.5205017770789e-06}, "kappa_score": 0.06367060523192836, "total_responses": 1043, "valid_responses": 789, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.29894971688387967, "spearman": 0.29894971688387967, "kendall": 0.29894971688387967}, "p_value": {"pearson": 1.7559249878986557e-19, "spearman": 1.7559249878987544e-19, "kendall": 1.0667904351353144e-18}, "kappa_score": 0.22538870772698172, "total_responses": 1043, "valid_responses": 873, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.2094927604827237, "spearman": 0.20949276048272375, "kendall": 0.20949276048272375}, "p_value": {"pearson": 2.9893628313000485e-11, "spearman": 2.989362831300112e-11, "kendall": 4.761578843864127e-11}, "kappa_score": 0.18161755079393782, "total_responses": 1043, "valid_responses": 987, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.16293957527898634, "spearman": 0.1629395752789863, "kendall": 0.1629395752789863}, "p_value": {"pearson": 6.930342419409105e-07, "spearman": 6.930342419409012e-07, "kendall": 8.050571321865901e-07}, "kappa_score": 0.14519735367318665, "total_responses": 1043, "valid_responses": 918, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.10423376636286712, "spearman": 0.10423376636286717, "kendall": 0.10423376636286717}, "p_value": {"pearson": 0.0024154151690987218, "spearman": 0.0024154151690987126, "kendall": 0.002460430326863672}, "kappa_score": 0.048402203242423725, "total_responses": 1043, "valid_responses": 845, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.008295098443560099, "spearman": 0.008295098443560066, "kendall": 0.00829509844356007}, "p_value": {"pearson": 0.7962880580548377, "spearman": 0.7962880580548394, "kendall": 0.7961372851656089}, "kappa_score": 0.0017190686662420518, "total_responses": 1043, "valid_responses": 971, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": -0.027455368241847564, "spearman": -0.027455368241847522, "kendall": -0.02745536824184752}, "p_value": {"pearson": 0.40323545485221585, "spearman": 0.4032354548522139, "kendall": 0.40294373594325017}, "kappa_score": -0.002708562733171327, "total_responses": 1043, "valid_responses": 929, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": -0.015618184056183627, "spearman": -0.015618184056183591, "kendall": -0.01561818405618359}, "p_value": {"pearson": 0.6181539878596404, "spearman": 0.6181539878596047, "kendall": 0.6179169070114713}, "kappa_score": -0.0035673304232457514, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.011145983470443543, "spearman": 0.011145983470443563, "kendall": 0.011145983470443563}, "p_value": {"pearson": 0.7559520609434494, "spearman": 0.7559520609434504, "kendall": 0.7557316190353827}, "kappa_score": 0.0021287252692212544, "total_responses": 1043, "valid_responses": 780, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.03739266262486459, "spearman": 0.03739266262486457, "kendall": 0.03739266262486456}, "p_value": {"pearson": 0.2890053351305321, "spearman": 0.28900533513053356, "kendall": 0.28872437771443527}, "kappa_score": 0.015126388935513102, "total_responses": 1043, "valid_responses": 806, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.03184867441201063, "spearman": 0.03184867441201065, "kendall": 0.031848674412010655}, "p_value": {"pearson": 0.457675759837831, "spearman": 0.45767575983783126, "kendall": 0.45717007028559087}, "kappa_score": 0.015176016917527124, "total_responses": 1043, "valid_responses": 546, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.025803209825720107, "spearman": 0.02580320982572012, "kendall": 0.02580320982572012}, "p_value": {"pearson": 0.46361576240198893, "spearman": 0.4636157624019903, "kendall": 0.4632748470579098}, "kappa_score": 0.004098701841581676, "total_responses": 1043, "valid_responses": 809, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": -0.007872223913640664, "spearman": -0.007872223913640708, "kendall": -0.007872223913640708}, "p_value": {"pearson": 0.8351825549539115, "spearman": 0.835182554953909, "kendall": 0.8350107627355472}, "kappa_score": -0.0005594787596312489, "total_responses": 1043, "valid_responses": 701, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.07683572141486185, "spearman": 0.07683572141486184, "kendall": 0.07683572141486184}, "p_value": {"pearson": 0.02876887745111073, "spearman": 0.028768877451110744, "kendall": 0.02885713654201013}, "kappa_score": 0.03585183144868154, "total_responses": 1043, "valid_responses": 810, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.04750593492438597, "spearman": 0.04750593492438607, "kendall": 0.04750593492438606}, "p_value": {"pearson": 0.22718163439500738, "spearman": 0.22718163439500696, "kendall": 0.22690489342024756}, "kappa_score": 0.015915805022156615, "total_responses": 1043, "valid_responses": 648, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.010130358016228738, "spearman": 0.010130358016228743, "kendall": 0.010130358016228743}, "p_value": {"pearson": 0.7806639904555305, "spearman": 0.7806639904555271, "kendall": 0.7804574467563414}, "kappa_score": 0.0008800088766112157, "total_responses": 1043, "valid_responses": 758, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.056705923243040246, "spearman": 0.05670592324304026, "kendall": 0.05670592324304027}, "p_value": {"pearson": 0.13007916776472572, "spearman": 0.13007916776472625, "kendall": 0.12998400735733517}, "kappa_score": 0.006410510070832265, "total_responses": 1043, "valid_responses": 714, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": -0.043339878620334685, "spearman": -0.04333987862033461, "kendall": -0.0433398786203346}, "p_value": {"pearson": 0.16683739119231394, "spearman": 0.16683739119231522, "kendall": 0.16672404196486978}, "kappa_score": -0.025945707301840093, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.05754066409516237, "spearman": 0.057540664095162404, "kendall": 0.057540664095162404}, "p_value": {"pearson": 0.08730230895599425, "spearman": 0.08730230895599442, "kendall": 0.08729564683888458}, "kappa_score": 0.028066528066528207, "total_responses": 1043, "valid_responses": 884, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.04469421446301197, "spearman": 0.04469421446301192, "kendall": 0.044694214463011916}, "p_value": {"pearson": 0.20524464822330926, "spearman": 0.205244648223311, "kendall": 0.20504814680731964}, "kappa_score": 0.012458920451987598, "total_responses": 1043, "valid_responses": 805, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.20486597837416154, "spearman": 0.20486597837416157, "kendall": 0.20486597837416157}, "p_value": {"pearson": 4.064167271611324e-10, "spearman": 4.0641672716113257e-10, "kendall": 6.008493726952543e-10}, "kappa_score": 0.1768848892532746, "total_responses": 1043, "valid_responses": 914, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.04027139064245921, "spearman": 0.0402713906424592, "kendall": 0.0402713906424592}, "p_value": {"pearson": 0.24964974575869284, "spearman": 0.2496497457586938, "kendall": 0.2494074053141483}, "kappa_score": 0.0072398090016800865, "total_responses": 1043, "valid_responses": 819, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": -0.0028391489623270406, "spearman": -0.002839148962327057, "kendall": -0.0028391489623270567}, "p_value": {"pearson": 0.9359759758682745, "spearman": 0.935975975868272, "kendall": 0.9359162830549761}, "kappa_score": -0.0014143841345641839, "total_responses": 1043, "valid_responses": 803, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.03342549074441862, "spearman": 0.03342549074441871, "kendall": 0.03342549074441871}, "p_value": {"pearson": 0.4196946584614763, "spearman": 0.4196946584614759, "kendall": 0.41922675069907667}, "kappa_score": 0.010920886194847768, "total_responses": 1043, "valid_responses": 585, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.10952998863551491, "spearman": 0.10952998863551495, "kendall": 0.10952998863551495}, "p_value": {"pearson": 0.0016610269286087191, "spearman": 0.001661026928608726, "kendall": 0.001698882760727303}, "kappa_score": 0.09829899991452262, "total_responses": 1043, "valid_responses": 822, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.08044324250038444, "spearman": 0.08044324250038444, "kendall": 0.08044324250038444}, "p_value": {"pearson": 0.020007905889706103, "spearman": 0.020007905889706305, "kendall": 0.020097778915571043}, "kappa_score": 0.0384471910671208, "total_responses": 1043, "valid_responses": 836, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.019937194761706075, "spearman": 0.019937194761706047, "kendall": 0.019937194761706054}, "p_value": {"pearson": 0.5809272193848702, "spearman": 0.580927219384868, "kendall": 0.5805950475650944}, "kappa_score": 0.011183876080260946, "total_responses": 1043, "valid_responses": 769, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.042339436840119295, "spearman": 0.042339436840119295, "kendall": 0.042339436840119295}, "p_value": {"pearson": 0.20852750780385498, "spearman": 0.20852750780385595, "kendall": 0.20834483885727484}, "kappa_score": 0.00889340810271444, "total_responses": 1043, "valid_responses": 884, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.04066411543137467, "spearman": 0.04066411543137467, "kendall": 0.040664115431374666}, "p_value": {"pearson": 0.20905123306651355, "spearman": 0.20905123306651466, "kendall": 0.2088817848283787}, "kappa_score": 0.02381386528572993, "total_responses": 1043, "valid_responses": 956, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.005295326664756128, "spearman": 0.005295326664756152, "kendall": 0.005295326664756152}, "p_value": {"pearson": 0.87613051759174, "spearman": 0.8761305175917405, "kendall": 0.8760250872585511}, "kappa_score": 0.003369912727901214, "total_responses": 1043, "valid_responses": 869, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.05538446630308834, "spearman": 0.05538446630308838, "kendall": 0.05538446630308838}, "p_value": {"pearson": 0.08916628342192284, "spearman": 0.08916628342192162, "kendall": 0.08915706206875917}, "kappa_score": 0.05029306343556672, "total_responses": 1043, "valid_responses": 943, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": 0.08895260990866474, "spearman": 0.08895260990866474, "kendall": 0.08895260990866473}, "p_value": {"pearson": 0.004352132255255965, "spearman": 0.004352132255256101, "kendall": 0.004401247568810525}, "kappa_score": 0.05141528287489561, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.29540420777776855, "spearman": 0.29540420777776855, "kendall": 0.29540420777776855}, "p_value": {"pearson": 3.4564217791087734e-22, "spearman": 3.456421779108601e-22, "kendall": 2.6425562747306625e-21}, "kappa_score": 0.2818064792962883, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.0817619261074812, "spearman": 0.08176192610748133, "kendall": 0.08176192610748133}, "p_value": {"pearson": 0.008789605311217811, "spearman": 0.008789605311217514, "kendall": 0.008853526856905287}, "kappa_score": 0.07992377536150652, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.13797905272782932, "spearman": 0.1379790527278295, "kendall": 0.1379790527278295}, "p_value": {"pearson": 9.660521548842478e-06, "spearman": 9.660521548841414e-06, "kendall": 1.0495857883688125e-05}, "kappa_score": 0.10047826816579963, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.04423903100138145, "spearman": 0.0442390310013815, "kendall": 0.04423903100138149}, "p_value": {"pearson": 0.1549656648039406, "spearman": 0.15496566480394425, "kendall": 0.15486822912063997}, "kappa_score": 0.03327998857747971, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.32652963432250237, "spearman": 0.32652963432250237, "kendall": 0.32652963432250237}, "p_value": {"pearson": 5.4370238361428315e-27, "spearman": 5.4370238361428445e-27, "kendall": 1.194774703734759e-25}, "kappa_score": 0.2700391265267277, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.20442794088764565, "spearman": 0.20442794088764565, "kendall": 0.20442794088764565}, "p_value": {"pearson": 3.0895916943778524e-11, "spearman": 3.089591694377871e-11, "kendall": 4.808864950145632e-11}, "kappa_score": 0.1371610015095518, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.5173443681100965, "spearman": 0.5173443681100962, "kendall": 0.5173443681100964}, "p_value": {"pearson": 7.522906252999168e-72, "spearman": 7.522906253001653e-72, "kendall": 4.397743604663461e-62}, "kappa_score": 0.46778928639511985, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.414329161393015, "spearman": 0.41432916139301507, "kendall": 0.41432916139301507}, "p_value": {"pearson": 3.067237290476973e-44, "spearman": 3.0672372904765756e-44, "kendall": 1.5582275860025084e-40}, "kappa_score": 0.37364553260095235, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.22410092617331165, "spearman": 0.2241009261733116, "kendall": 0.22410092617331162}, "p_value": {"pearson": 3.0912269859867213e-13, "spearman": 3.0912269859869707e-13, "kendall": 5.904263794338006e-13}, "kappa_score": 0.1805419276926561, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.288173539220548, "spearman": 0.288173539220548, "kendall": 0.288173539220548}, "p_value": {"pearson": 2.555589808693497e-21, "spearman": 2.5555898086934153e-21, "kendall": 1.6265560442042354e-20}, "kappa_score": 0.25873694487209054, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.26943451846428423, "spearman": 0.2694345184642843, "kendall": 0.26943451846428434}, "p_value": {"pearson": 1.0487165984802286e-18, "spearman": 1.0487165984802251e-18, "kendall": 4.235658987782333e-18}, "kappa_score": 0.2685843320794331, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.275793553663244, "spearman": 0.275793553663244, "kendall": 0.27579355366324393}, "p_value": {"pearson": 2.0326078604152697e-19, "spearman": 2.0326078604150422e-19, "kendall": 9.350480519623278e-19}, "kappa_score": 0.18617646406634591, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.6334723180825809, "spearman": 0.6334723180825806, "kendall": 0.6334723180825806}, "p_value": {"pearson": 3.355978622680943e-117, "spearman": 3.3559786226825054e-117, "kendall": 3.096011137083961e-92}, "kappa_score": 0.6281514574026055, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.4140984318873502, "spearman": 0.4140984318873503, "kendall": 0.41409843188735024}, "p_value": {"pearson": 4.591566251129719e-44, "spearman": 4.591566251129442e-44, "kendall": 2.2292562093935727e-40}, "kappa_score": 0.334599255208508, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.32269357433732093, "spearman": 0.32269357433732093, "kendall": 0.3226935743373208}, "p_value": {"pearson": 1.8402589147248895e-26, "spearman": 1.8402589147249446e-26, "kendall": 3.523634549396332e-25}, "kappa_score": 0.3144470080570232, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.08364748342103696, "spearman": 0.08364748342103699, "kendall": 0.08364748342103698}, "p_value": {"pearson": 0.007288141969389756, "spearman": 0.007288141969389684, "kendall": 0.007348205190907187}, "kappa_score": 0.04908022012567259, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.098423360692911, "spearman": 0.09842336069291106, "kendall": 0.09842336069291108}, "p_value": {"pearson": 0.0015068462615368163, "spearman": 0.0015068462615368547, "kendall": 0.0015351888629460905}, "kappa_score": 0.07344483252848821, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.4891024173443136, "spearman": 0.4891024173443137, "kendall": 0.48910241734431376}, "p_value": {"pearson": 8.133127054210254e-63, "spearman": 8.133127054210498e-63, "kendall": 2.8876951811402137e-55}, "kappa_score": 0.44779332615715817, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.2839044148524046, "spearman": 0.2839044148524045, "kendall": 0.28390441485240453}, "p_value": {"pearson": 1.0298937318319534e-20, "spearman": 1.0298937318320169e-20, "kendall": 5.862621547310797e-20}, "kappa_score": 0.24803099323087396, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.3668409626999961, "spearman": 0.366840962699996, "kendall": 0.366840962699996}, "p_value": {"pearson": 2.05390066318606e-34, "spearman": 2.053900663186034e-34, "kendall": 3.336558103709155e-32}, "kappa_score": 0.3532710280373832, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.13747158627392358, "spearman": 0.1374715862739236, "kendall": 0.1374715862739236}, "p_value": {"pearson": 8.621755784945664e-06, "spearman": 8.621755784945933e-06, "kendall": 9.371293437605092e-06}, "kappa_score": 0.13694917318878097, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.2008848225798016, "spearman": 0.20088482257980156, "kendall": 0.20088482257980153}, "p_value": {"pearson": 1.2290876349568582e-10, "spearman": 1.2290876349568641e-10, "kendall": 1.8328440309068037e-10}, "kappa_score": 0.20048425139326642, "total_responses": 1043, "valid_responses": 1008, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.4441242786391829, "spearman": 0.44412427863918297, "kendall": 0.4441242786391829}, "p_value": {"pearson": 3.2378126680743574e-51, "spearman": 3.237812668073982e-51, "kendall": 3.1647082808648207e-46}, "kappa_score": 0.3898138948716069, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.34494245909418497, "spearman": 0.34494245909418497, "kendall": 0.34494245909418497}, "p_value": {"pearson": 3.318424945497898e-30, "spearman": 3.31842494549793e-30, "kendall": 1.6436388361410916e-28}, "kappa_score": 0.27409453652547566, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.4503617551175716, "spearman": 0.4503617551175718, "kendall": 0.4503617551175718}, "p_value": {"pearson": 5.5407108376687325e-53, "spearman": 5.540710837668238e-53, "kendall": 1.1636230474048052e-47}, "kappa_score": 0.38813309547816643, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.1997208264402797, "spearman": 0.19972082644027966, "kendall": 0.19972082644027966}, "p_value": {"pearson": 1.6451593488978984e-10, "spearman": 1.645159348897943e-10, "kendall": 2.427943526468292e-10}, "kappa_score": 0.09253125484502944, "total_responses": 1043, "valid_responses": 1006, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.23459775787283849, "spearman": 0.2345977578728387, "kendall": 0.23459775787283868}, "p_value": {"pearson": 2.2104624922978533e-14, "spearman": 2.2104624922978675e-14, "kendall": 4.8313824441121026e-14}, "kappa_score": 0.13103659236034104, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.2882446642808779, "spearman": 0.28824466428087814, "kendall": 0.2882446642808781}, "p_value": {"pearson": 2.9749643280799358e-21, "spearman": 2.9749643280799934e-21, "kendall": 1.8832589045245056e-20}, "kappa_score": 0.21424491781778177, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.05396038979417572, "spearman": 0.053960389794175626, "kendall": 0.05396038979417562}, "p_value": {"pearson": 0.0828634214108341, "spearman": 0.08286342141083153, "kendall": 0.08286414876394245}, "kappa_score": 0.03487198411061787, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.25690111030074936, "spearman": 0.25690111030074936, "kendall": 0.25690111030074936}, "p_value": {"pearson": 4.6117865680573655e-17, "spearman": 4.61178656805758e-17, "kendall": 1.4460385206152305e-16}, "kappa_score": 0.15758630162073073, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.12079072614624067, "spearman": 0.12079072614624063, "kendall": 0.12079072614624063}, "p_value": {"pearson": 0.00010672211647307253, "spearman": 0.00010672211647306916, "kendall": 0.00011181261898649492}, "kappa_score": 0.03588920306233612, "total_responses": 1043, "valid_responses": 1024, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.10954946328288588, "spearman": 0.10954946328288577, "kendall": 0.10954946328288576}, "p_value": {"pearson": 0.00043079879122634045, "spearman": 0.0004307987912263318, "kendall": 0.0004440406634179242}, "kappa_score": 0.10368976690707632, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.4453146819637565, "spearman": 0.4453146819637566, "kendall": 0.4453146819637566}, "p_value": {"pearson": 1.0483809282761527e-51, "spearman": 1.0483809282760337e-51, "kendall": 1.2263224316376553e-46}, "kappa_score": 0.3615128621674053, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8013433788966999, "spearman": 0.8013433788967002, "kendall": 0.8013433788967}, "p_value": {"pearson": 3.3871264205270107e-233, "spearman": 3.387126420525497e-233, "kendall": 1.0679190664141922e-146}, "kappa_score": 0.8006519980456078, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.37927878100644263, "spearman": 0.37927878100644263, "kendall": 0.3792787810064426}, "p_value": {"pearson": 2.8172644950763277e-36, "spearman": 2.817264495076318e-36, "kendall": 8.992428649697388e-34}, "kappa_score": 0.3438905719269255, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.20414704435653136, "spearman": 0.2041470443565313, "kendall": 0.2041470443565313}, "p_value": {"pearson": 3.220468282600048e-11, "spearman": 3.220468282600113e-11, "kendall": 5.002161447028719e-11}, "kappa_score": 0.1637234410230246, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.3133241358721811, "spearman": 0.3133241358721811, "kendall": 0.3133241358721811}, "p_value": {"pearson": 6.755218998478475e-25, "spearman": 6.755218998478419e-25, "kendall": 9.110521557943559e-24}, "kappa_score": 0.2502268676594439, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.11375354722313438, "spearman": 0.11375354722313447, "kendall": 0.11375354722313445}, "p_value": {"pearson": 0.00024193506646361663, "spearman": 0.000241935066463615, "kendall": 0.0002508601805401977}, "kappa_score": 0.07710988762350102, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.23346317892455032, "spearman": 0.23346317892455032, "kendall": 0.23346317892455026}, "p_value": {"pearson": 2.6473058477476054e-14, "spearman": 2.647305847747506e-14, "kendall": 5.714257354409804e-14}, "kappa_score": 0.11414337043775391, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.23878817286284457, "spearman": 0.23878817286284446, "kendall": 0.23878817286284448}, "p_value": {"pearson": 6.929007336994764e-15, "spearman": 6.929007336995363e-15, "kendall": 1.6103562137331966e-14}, "kappa_score": 0.15866268851923004, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.06808637080328564, "spearman": 0.06808637080328563, "kendall": 0.06808637080328561}, "p_value": {"pearson": 0.03132765104489079, "spearman": 0.03132765104489089, "kendall": 0.031397095698704656}, "kappa_score": 0.025609143731618045, "total_responses": 1043, "valid_responses": 1000, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.06760156411748401, "spearman": 0.06760156411748398, "kendall": 0.06760156411748398}, "p_value": {"pearson": 0.030050352740396573, "spearman": 0.030050352740398075, "kendall": 0.030118765164995325}, "kappa_score": 0.02426025209153726, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.0624614900664735, "spearman": 0.06246149006647346, "kendall": 0.06246149006647345}, "p_value": {"pearson": 0.045055291374412346, "spearman": 0.04505529137441187, "kendall": 0.04510847228912063}, "kappa_score": 0.025939850860659752, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.06711476253761538, "spearman": 0.06711476253761538, "kendall": 0.06711476253761538}, "p_value": {"pearson": 0.030768977096430183, "spearman": 0.030768977096430884, "kendall": 0.030836442550055045}, "kappa_score": 0.021414743112434964, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.308386685334258, "spearman": 0.30838668533425795, "kendall": 0.30838668533425795}, "p_value": {"pearson": 2.49908452663511e-24, "spearman": 2.4990845266352215e-24, "kendall": 2.914030408701551e-23}, "kappa_score": 0.22490893769081644, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.14470582427692674, "spearman": 0.1447058242769267, "kendall": 0.14470582427692666}, "p_value": {"pearson": 3.3655881252852435e-06, "spearman": 3.3655881252854798e-06, "kendall": 3.7268358139479724e-06}, "kappa_score": 0.0944668102237618, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": -0.0018869725994407399, "spearman": -0.0018869725994407312, "kendall": -0.001886972599440731}, "p_value": {"pearson": 0.9516278925189227, "spearman": 0.9516278925189238, "kendall": 0.9515928910601873}, "kappa_score": -0.0015836770771950892, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.13692460769712145, "spearman": 0.13692460769712128, "kendall": 0.13692460769712128}, "p_value": {"pearson": 9.461585924009945e-06, "spearman": 9.461585924010458e-06, "kendall": 1.0268634848660768e-05}, "kappa_score": 0.13674795953276964, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.1851672983816618, "spearman": 0.18516729838166174, "kendall": 0.18516729838166174}, "p_value": {"pearson": 1.848568183506289e-09, "spearman": 1.848568183506335e-09, "kendall": 2.478804559596219e-09}, "kappa_score": 0.08821684025599208, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.36459246492614217, "spearman": 0.3645924649261424, "kendall": 0.3645924649261424}, "p_value": {"pearson": 5.142112311983186e-34, "spearman": 5.142112311982214e-34, "kendall": 7.365464781037083e-32}, "kappa_score": 0.24920211164415185, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.07194440249723454, "spearman": 0.07194440249723462, "kendall": 0.07194440249723463}, "p_value": {"pearson": 0.022155257118108514, "spearman": 0.022155257118108396, "kendall": 0.022229180419634516}, "kappa_score": 0.013268164474518507, "total_responses": 1043, "valid_responses": 1011, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.4955762784242733, "spearman": 0.4955762784242735, "kendall": 0.4955762784242735}, "p_value": {"pearson": 2.9069161443231825e-64, "spearman": 2.9069161443227345e-64, "kendall": 2.57529282371108e-56}, "kappa_score": 0.4740497798279325, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.2737468894596276, "spearman": 0.27374688945962766, "kendall": 0.2737468894596276}, "p_value": {"pearson": 2.4785615756021854e-19, "spearman": 2.478561575602214e-19, "kendall": 1.1061342378383765e-18}, "kappa_score": 0.15316782453526456, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.40200176334108956, "spearman": 0.4020017633410896, "kendall": 0.40200176334108956}, "p_value": {"pearson": 5.621399843372333e-41, "spearman": 5.621399843372065e-41, "kendall": 9.151656331700644e-38}, "kappa_score": 0.3428331936295055, "total_responses": 1043, "valid_responses": 1022, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.22794427311013488, "spearman": 0.2279442731101348, "kendall": 0.22794427311013474}, "p_value": {"pearson": 1.0045433960871172e-13, "spearman": 1.004543396087231e-13, "kendall": 2.0202843361743113e-13}, "kappa_score": 0.1131395628152776, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.3320604392396457, "spearman": 0.3320604392396457, "kendall": 0.3320604392396457}, "p_value": {"pearson": 3.051910642408223e-28, "spearman": 3.0519106424084683e-28, "kendall": 8.771112008818643e-27}, "kappa_score": 0.2946775964439139, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.3618701021641251, "spearman": 0.3618701021641253, "kendall": 0.36187010216412524}, "p_value": {"pearson": 1.688028510777196e-33, "spearman": 1.68802851077717e-33, "kendall": 2.070996308179195e-31}, "kappa_score": 0.3351147546654214, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.31381894340454486, "spearman": 0.313818943404545, "kendall": 0.31381894340454497}, "p_value": {"pearson": 7.340858909037475e-25, "spearman": 7.340858909037144e-25, "kendall": 9.942514338010037e-24}, "kappa_score": 0.23126656753087227, "total_responses": 1043, "valid_responses": 1025, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.4586731882032578, "spearman": 0.45867318820325814, "kendall": 0.4586731882032581}, "p_value": {"pearson": 3.093017659739061e-55, "spearman": 3.0930176597380796e-55, "kendall": 1.840038962212422e-49}, "kappa_score": 0.41962877593109305, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.1525295359341678, "spearman": 0.1525295359341678, "kendall": 0.1525295359341678}, "p_value": {"pearson": 8.424901332563191e-07, "spearman": 8.424901332563199e-07, "kendall": 9.584921774089563e-07}, "kappa_score": 0.05818989169065558, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.3191553211958389, "spearman": 0.31915532119583884, "kendall": 0.31915532119583884}, "p_value": {"pearson": 5.524025619776136e-26, "spearman": 5.52402561977657e-26, "kendall": 9.360969892314456e-25}, "kappa_score": 0.19680851063829785, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.24782708257326597, "spearman": 0.247827082573266, "kendall": 0.247827082573266}, "p_value": {"pearson": 5.0868001778537e-16, "spearman": 5.086800177853424e-16, "kendall": 1.367678797853239e-15}, "kappa_score": 0.12221405829047272, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": 0.2904329165570003, "spearman": 0.29043291655700026, "kendall": 0.29043291655700026}, "p_value": {"pearson": 1.0128501049448158e-21, "spearman": 1.0128501049447775e-21, "kendall": 6.905669375571427e-21}, "kappa_score": 0.18547618123061138, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.37754794919332185, "spearman": 0.37754794919332174, "kendall": 0.37754794919332174}, "p_value": {"pearson": 1.3123233284039845e-36, "spearman": 1.3123233284041404e-36, "kendall": 4.195279570297498e-34}, "kappa_score": 0.3774967490452792, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.16782441039553783, "spearman": 0.1678244103955378, "kendall": 0.1678244103955378}, "p_value": {"pearson": 5.1241759661683956e-08, "spearman": 5.124175966168261e-08, "kendall": 6.226392848809098e-08}, "kappa_score": 0.1052053612573659, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.1696526855516648, "spearman": 0.1696526855516647, "kendall": 0.16965268555166474}, "p_value": {"pearson": 3.702094289712192e-08, "spearman": 3.7020942897123835e-08, "kendall": 4.538505203277166e-08}, "kappa_score": 0.07582938388625604, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.2354831260017986, "spearman": 0.2354831260017986, "kendall": 0.2354831260017986}, "p_value": {"pearson": 5.599099150241197e-14, "spearman": 5.599099150241345e-14, "kendall": 1.1999845080869722e-13}, "kappa_score": 0.10507779933459549, "total_responses": 1043, "valid_responses": 993, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.4245335746846848, "spearman": 0.4245335746846846, "kendall": 0.42453357468468456}, "p_value": {"pearson": 2.80174925906262e-46, "spearman": 2.8017492590626843e-46, "kendall": 3.417654496869423e-42}, "kappa_score": 0.33973934172741327, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.27011699787983, "spearman": 0.27011699787983007, "kendall": 0.27011699787983007}, "p_value": {"pearson": 1.635001696689324e-18, "spearman": 1.6350016966893452e-18, "kendall": 6.544206296701268e-18}, "kappa_score": 0.1516481273599346, "total_responses": 1043, "valid_responses": 1020, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.5068829871705453, "spearman": 0.506882987170545, "kendall": 0.506882987170545}, "p_value": {"pearson": 1.024997342681024e-68, "spearman": 1.024997342681328e-68, "kendall": 8.780404775278854e-60}, "kappa_score": 0.4146950669534448, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.49731768449686997, "spearman": 0.49731768449687, "kendall": 0.49731768449686997}, "p_value": {"pearson": 2.947500186566741e-66, "spearman": 2.9475001865668806e-66, "kendall": 5.4092811423645134e-58}, "kappa_score": 0.4227489223833204, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.24342161663753956, "spearman": 0.24342161663753964, "kendall": 0.2434216166375396}, "p_value": {"pearson": 1.9364130788957526e-15, "spearman": 1.9364130788959257e-15, "kendall": 4.831658057103966e-15}, "kappa_score": 0.14429328621908122, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.40818951975410966, "spearman": 0.40818951975410955, "kendall": 0.40818951975410955}, "p_value": {"pearson": 5.476553052497452e-43, "spearman": 5.4765530524972744e-43, "kendall": 1.6782099301171788e-39}, "kappa_score": 0.3360223020783166, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.5505649818519198, "spearman": 0.5505649818519198, "kendall": 0.5505649818519199}, "p_value": {"pearson": 2.690683782512288e-82, "spearman": 2.690683782512182e-82, "kendall": 1.7897878605136383e-69}, "kappa_score": 0.5070573386451505, "total_responses": 1043, "valid_responses": 1025, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.4055752570851039, "spearman": 0.405575257085104, "kendall": 0.405575257085104}, "p_value": {"pearson": 3.8903481735456737e-42, "spearman": 3.8903481735455105e-42, "kendall": 9.09079390053473e-39}, "kappa_score": 0.29006351288655663, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.9412578920611684, "spearman": 0.9412578920611686, "kendall": 0.9412578920611686}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 8.984377545405729e-203}, "kappa_score": 0.9395357311447714, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.8240445318315637, "spearman": 0.8240445318315637, "kendall": 0.8240445318315637}, "p_value": {"pearson": 3.681350553762857e-258, "spearman": 3.681350553762624e-258, "kendall": 2.6322943955885167e-155}, "kappa_score": 0.8207273937317443, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.5719308528869191, "spearman": 0.5719308528869192, "kendall": 0.5719308528869191}, "p_value": {"pearson": 1.5348781932704135e-88, "spearman": 1.5348781932703295e-88, "kendall": 1.5341981351790033e-73}, "kappa_score": 0.5478922575190239, "total_responses": 1043, "valid_responses": 1007, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.14085983596057286, "spearman": 0.1408598359605729, "kendall": 0.1408598359605729}, "p_value": {"pearson": 5.11820797336452e-06, "spearman": 5.118207973364694e-06, "kendall": 5.614527397197247e-06}, "kappa_score": 0.05534596587498919, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.2534150014043367, "spearman": 0.25341500140433676, "kendall": 0.2534150014043367}, "p_value": {"pearson": 9.866624626476911e-17, "spearman": 9.866624626477503e-17, "kendall": 2.9265308733148715e-16}, "kappa_score": 0.1848358160898722, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.7903815933788862, "spearman": 0.7903815933788867, "kendall": 0.7903815933788866}, "p_value": {"pearson": 3.947159735429047e-223, "spearman": 3.947159735425349e-223, "kendall": 3.565603336214813e-143}, "kappa_score": 0.7891155116817345, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.37178442752992985, "spearman": 0.37178442752992985, "kendall": 0.3717844275299298}, "p_value": {"pearson": 1.6812849691017238e-35, "spearman": 1.6812849691018173e-35, "kendall": 3.753696317097959e-33}, "kappa_score": 0.24287609780754393, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.6973849691679619, "spearman": 0.6973849691679618, "kendall": 0.6973849691679617}, "p_value": {"pearson": 3.5236003331798776e-151, "spearman": 3.5236003331802236e-151, "kendall": 4.660801874920514e-111}, "kappa_score": 0.6957895943533727, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.28090312855550376, "spearman": 0.28090312855550376, "kendall": 0.28090312855550376}, "p_value": {"pearson": 2.5944657520069657e-20, "spearman": 2.5944657520069753e-20, "kendall": 1.3719810997811822e-19}, "kappa_score": 0.2185520228658986, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.7305238933436335, "spearman": 0.7305238933436332, "kendall": 0.7305238933436333}, "p_value": {"pearson": 1.219975573410992e-174, "spearman": 1.219975573411825e-174, "kendall": 5.991739775175198e-123}, "kappa_score": 0.7174462705436158, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.8095919106916141, "spearman": 0.8095919106916135, "kendall": 0.8095919106916135}, "p_value": {"pearson": 6.158556111220267e-242, "spearman": 6.158556111228661e-242, "kendall": 7.803204681449087e-150}, "kappa_score": 0.801758959521013, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.6672979258912775, "spearman": 0.6672979258912776, "kendall": 0.6672979258912776}, "p_value": {"pearson": 2.406782394574519e-134, "spearman": 2.4067823945743804e-134, "kendall": 3.882657022334257e-102}, "kappa_score": 0.6672337803260681, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.6496941564320385, "spearman": 0.6496941564320389, "kendall": 0.649694156432039}, "p_value": {"pearson": 5.5267095779593274e-126, "spearman": 5.526709577957795e-126, "kendall": 1.4559157305501316e-97}, "kappa_score": 0.608050585176791, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.20247381557046745, "spearman": 0.20247381557046748, "kendall": 0.20247381557046748}, "p_value": {"pearson": 4.302145487022043e-11, "spearman": 4.30214548702204e-11, "kendall": 6.595245918652131e-11}, "kappa_score": 0.1712416162277116, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.42815215887340535, "spearman": 0.42815215887340524, "kendall": 0.4281521588734052}, "p_value": {"pearson": 1.3086555931881746e-47, "spearman": 1.3086555931883278e-47, "kendall": 2.5185674551561838e-43}, "kappa_score": 0.32556743124774823, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.42839541661551367, "spearman": 0.42839541661551356, "kendall": 0.42839541661551356}, "p_value": {"pearson": 8.440394208927699e-48, "spearman": 8.440394208928418e-48, "kendall": 1.7128750373262039e-43}, "kappa_score": 0.36847498282507196, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.2835937961048867, "spearman": 0.28359379610488666, "kendall": 0.2835937961048866}, "p_value": {"pearson": 1.1387459198352295e-20, "spearman": 1.1387459198351121e-20, "kendall": 6.431152979970121e-20}, "kappa_score": 0.19945387190029162, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.2622692986473936, "spearman": 0.2622692986473937, "kendall": 0.26226929864739373}, "p_value": {"pearson": 7.499582099477518e-18, "spearman": 7.499582099477903e-18, "kendall": 2.6283936509048047e-17}, "kappa_score": 0.14170812067963046, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.23885196269160772, "spearman": 0.23885196269160763, "kendall": 0.2388519626916077}, "p_value": {"pearson": 7.67627942221491e-15, "spearman": 7.676279422215933e-15, "kendall": 1.7796595381994993e-14}, "kappa_score": 0.11606153727590629, "total_responses": 1043, "valid_responses": 1031, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.35577690528512707, "spearman": 0.35577690528512707, "kendall": 0.35577690528512707}, "p_value": {"pearson": 2.654811700087423e-32, "spearman": 2.6548117000869247e-32, "kendall": 2.3144525101125172e-30}, "kappa_score": 0.34169983153062966, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.7430367150219093, "spearman": 0.7430367150219094, "kendall": 0.7430367150219094}, "p_value": {"pearson": 6.804695309279254e-183, "spearman": 6.8046953092785805e-183, "kendall": 1.580058262383018e-126}, "kappa_score": 0.7114261884904087, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.9423321316177578, "spearman": 0.9423321316177575, "kendall": 0.9423321316177578}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 2.886177584370973e-202}, "kappa_score": 0.9415093580197222, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.5087761942183671, "spearman": 0.5087761942183671, "kendall": 0.5087761942183671}, "p_value": {"pearson": 8.900240044780062e-69, "spearman": 8.900240044780245e-69, "kendall": 9.143191181842055e-60}, "kappa_score": 0.4158589069663905, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.2268995394965479, "spearman": 0.2268995394965479, "kendall": 0.2268995394965479}, "p_value": {"pearson": 1.2739868161448594e-13, "spearman": 1.2739868161448652e-13, "kendall": 2.5302812666243493e-13}, "kappa_score": 0.10307207768392013, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.3716204497658789, "spearman": 0.3716204497658789, "kendall": 0.37162044976587894}, "p_value": {"pearson": 3.0558064990762315e-35, "spearman": 3.05580649907638e-35, "kendall": 6.509810325502972e-33}, "kappa_score": 0.28247965604962877, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.18961407516996953, "spearman": 0.1896140751699696, "kendall": 0.18961407516996956}, "p_value": {"pearson": 7.814834163494985e-10, "spearman": 7.814834163495262e-10, "kendall": 1.0793864019018146e-09}, "kappa_score": 0.08018169250518425, "total_responses": 1043, "valid_responses": 1035, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.34552762602095344, "spearman": 0.34552762602095327, "kendall": 0.3455276260209534}, "p_value": {"pearson": 1.7812276069695906e-30, "spearman": 1.7812276069697048e-30, "kendall": 9.286133787026413e-29}, "kappa_score": 0.22126531283400463, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.28974190113193987, "spearman": 0.28974190113193987, "kendall": 0.2897419011319398}, "p_value": {"pearson": 3.233663216147543e-21, "spearman": 3.2336632161475582e-21, "kendall": 2.0800630689063417e-20}, "kappa_score": 0.1839348969172876, "total_responses": 1043, "valid_responses": 1022, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.10480293685542474, "spearman": 0.10480293685542469, "kendall": 0.10480293685542467}, "p_value": {"pearson": 0.0011125195189878028, "spearman": 0.0011125195189878158, "kendall": 0.0011380902421233357}, "kappa_score": 0.053602801376621434, "total_responses": 1043, "valid_responses": 965, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.13507815781523752, "spearman": 0.13507815781523755, "kendall": 0.13507815781523752}, "p_value": {"pearson": 0.00011746236134324453, "spearman": 0.00011746236134324227, "kendall": 0.0001244117300170379}, "kappa_score": 0.04707770237611886, "total_responses": 1043, "valid_responses": 808, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.23648551067652135, "spearman": 0.23648551067652138, "kendall": 0.2364855106765214}, "p_value": {"pearson": 1.6089288543576846e-14, "spearman": 1.608928854357619e-14, "kendall": 3.5934095093927667e-14}, "kappa_score": 0.13964475258459375, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.20469567602256752, "spearman": 0.2046956760225677, "kendall": 0.2046956760225677}, "p_value": {"pearson": 1.3455544735063185e-10, "spearman": 1.3455544735062892e-10, "kendall": 2.033909915306777e-10}, "kappa_score": 0.08590154790126892, "total_responses": 1043, "valid_responses": 966, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.3551242573956973, "spearman": 0.3551242573956975, "kendall": 0.3551242573956975}, "p_value": {"pearson": 5.2608394091482e-32, "spearman": 5.260839409148144e-32, "kendall": 4.3168184301131694e-30}, "kappa_score": 0.24218389429240517, "total_responses": 1043, "valid_responses": 1031, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.4373511899325742, "spearman": 0.4373511899325742, "kendall": 0.43735118993257427}, "p_value": {"pearson": 4.5639019933665897e-48, "spearman": 4.563901993366875e-48, "kendall": 1.5207186250734727e-43}, "kappa_score": 0.3675003005891547, "total_responses": 1043, "valid_responses": 1002, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.19982656892288037, "spearman": 0.19982656892288048, "kendall": 0.19982656892288048}, "p_value": {"pearson": 1.1764742678639097e-10, "spearman": 1.176474267863877e-10, "kendall": 1.748484000896229e-10}, "kappa_score": 0.09562492148822888, "total_responses": 1043, "valid_responses": 1021, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.4006137287899353, "spearman": 0.4006137287899351, "kendall": 0.4006137287899351}, "p_value": {"pearson": 4.952752297631981e-40, "spearman": 4.952752297632588e-40, "kendall": 6.39787484209021e-37}, "kappa_score": 0.2765920803359697, "total_responses": 1043, "valid_responses": 1005, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.19675289429743242, "spearman": 0.19675289429743234, "kendall": 0.19675289429743237}, "p_value": {"pearson": 1.5842441496739332e-10, "spearman": 1.584244149673863e-10, "kendall": 2.3128194816363966e-10}, "kappa_score": 0.09472908803599223, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.3181117944519, "spearman": 0.3181117944518999, "kendall": 0.31811179445189985}, "p_value": {"pearson": 6.210603432946178e-26, "spearman": 6.210603432946183e-26, "kendall": 1.0266496358754467e-24}, "kappa_score": 0.19016179807035594, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.11036367384878065, "spearman": 0.11036367384878062, "kendall": 0.1103636738487806}, "p_value": {"pearson": 0.00038996149238333585, "spearman": 0.00038996149238334105, "kendall": 0.0004023637373593662}, "kappa_score": 0.04025892670703701, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.8182963239464189, "spearman": 0.8182963239464185, "kendall": 0.8182963239464185}, "p_value": {"pearson": 2.37114245038387e-252, "spearman": 2.371142450386426e-252, "kendall": 1.3014015621011935e-153}, "kappa_score": 0.8057407559546756, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.27099228433802847, "spearman": 0.2709922843380283, "kendall": 0.2709922843380283}, "p_value": {"pearson": 5.373704068564669e-19, "spearman": 5.37370406856431e-19, "kendall": 2.2611974120214937e-18}, "kappa_score": 0.14585977200559896, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.6113313482195116, "spearman": 0.6113313482195115, "kendall": 0.6113313482195115}, "p_value": {"pearson": 3.425924825456539e-107, "spearman": 3.425924825457107e-107, "kendall": 4.1032597567190974e-86}, "kappa_score": 0.5795869973322794, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.3285245833780286, "spearman": 0.32852458337802876, "kendall": 0.32852458337802865}, "p_value": {"pearson": 3.6005208746492096e-27, "spearman": 3.600520874649104e-27, "kendall": 8.410860726589216e-26}, "kappa_score": 0.20178044174107346, "total_responses": 1043, "valid_responses": 1023, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.6702996325786332, "spearman": 0.6702996325786332, "kendall": 0.6702996325786332}, "p_value": {"pearson": 1.2624911418189377e-136, "spearman": 1.2624911418189335e-136, "kendall": 1.5733168522143025e-103}, "kappa_score": 0.647705657034161, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.6335579912174736, "spearman": 0.6335579912174744, "kendall": 0.6335579912174745}, "p_value": {"pearson": 5.053768726341427e-118, "spearman": 5.053768726337105e-118, "kendall": 7.1577946451382046e-93}, "kappa_score": 0.5867218485945853, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.5807780488178598, "spearman": 0.5807780488178593, "kendall": 0.5807780488178593}, "p_value": {"pearson": 3.29769128242221e-94, "spearman": 3.2976912824238125e-94, "kendall": 1.1004803444329616e-77}, "kappa_score": 0.5413716555672392, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.6866596645268646, "spearman": 0.6866596645268643, "kendall": 0.6866596645268644}, "p_value": {"pearson": 3.4583457117086456e-146, "spearman": 3.4583457117099406e-146, "kendall": 9.387477168221595e-109}, "kappa_score": 0.6865096875125356, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.23923897189092816, "spearman": 0.23923897189092813, "kendall": 0.23923897189092813}, "p_value": {"pearson": 5.135712174743708e-15, "spearman": 5.135712174743456e-15, "kendall": 1.2076897142900865e-14}, "kappa_score": 0.15009510782448865, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.417540492618639, "spearman": 0.4175404926186388, "kendall": 0.4175404926186388}, "p_value": {"pearson": 4.726342940687492e-45, "spearman": 4.726342940687902e-45, "kendall": 3.25680994833447e-41}, "kappa_score": 0.3378307258025932, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.3000906525515517, "spearman": 0.30009065255155176, "kendall": 0.30009065255155176}, "p_value": {"pearson": 7.052697042809307e-23, "spearman": 7.052697042809223e-23, "kendall": 6.190876097713222e-22}, "kappa_score": 0.1726717767476017, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gemini-1.5-flash-latest (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": -0.14410717997209888, "spearman": -0.14410717997209893, "kendall": -0.1441071799720989}, "p_value": {"pearson": 0.14443351312068164, "spearman": 0.14443351312068134, "kendall": 0.14359653800723202}, "kappa_score": -0.09578544061302674, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": -0.1539981007018036, "spearman": -0.1539981007018036, "kendall": -0.1539981007018036}, "p_value": {"pearson": 0.1185653634996437, "spearman": 0.11856536349964396, "kendall": 0.11807375928554856}, "kappa_score": -0.15189873417721533, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.056417501472938, "spearman": 0.05641750147293804, "kendall": 0.056417501472938045}, "p_value": {"pearson": 0.5694596568058289, "spearman": 0.569459656805829, "kendall": 0.5669324198951806}, "kappa_score": 0.03459915611814357, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.09276626358267055, "spearman": 0.09276626358267051, "kendall": 0.09276626358267052}, "p_value": {"pearson": 0.3489532060064505, "spearman": 0.3489532060064494, "kendall": 0.34646162295487637}, "kappa_score": 0.06621773288439947, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": -0.04264445100899951, "spearman": -0.04264445100899954, "kendall": -0.04264445100899954}, "p_value": {"pearson": 0.6673198712572945, "spearman": 0.6673198712572941, "kendall": 0.6651644986592545}, "kappa_score": -0.040000000000000036, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": -0.3181738014061412, "spearman": -0.31817380140614127, "kendall": -0.31817380140614115}, "p_value": {"pearson": 0.0009965173708343946, "spearman": 0.0009965173708343916, "kendall": 0.001241755098183989}, "kappa_score": -0.25109361329833746, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": -0.03951405741979084, "spearman": -0.03951405741979083, "kendall": -0.03951405741979083}, "p_value": {"pearson": 0.6904450544324954, "spearman": 0.6904450544324949, "kendall": 0.6884025394730037}, "kappa_score": -0.025261860751694343, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.12638326787979082, "spearman": 0.1263832678797909, "kendall": 0.12638326787979087}, "p_value": {"pearson": 0.2011024276453468, "spearman": 0.2011024276453466, "kendall": 0.19961469597325643}, "kappa_score": 0.09800520381613165, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": -0.1132008308132945, "spearman": -0.1132008308132945, "kendall": -0.1132008308132945}, "p_value": {"pearson": 0.2525589771952859, "spearman": 0.25255897719528597, "kendall": 0.25061249427674215}, "kappa_score": -0.09473684210526323, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": -0.18868471280902044, "spearman": -0.18868471280902038, "kendall": -0.18868471280902036}, "p_value": {"pearson": 0.055082442207506375, "spearman": 0.05508244220750656, "kendall": 0.05550006780602206}, "kappa_score": -0.09425690486628668, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": -0.17075131106430497, "spearman": -0.17075131106430494, "kendall": -0.17075131106430494}, "p_value": {"pearson": 0.08308964447626398, "spearman": 0.08308964447626446, "kendall": 0.08310694866201224}, "kappa_score": -0.16473988439306364, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": -0.21708037259683646, "spearman": -0.21708037259683646, "kendall": -0.2170803725968365}, "p_value": {"pearson": 0.026862912806503783, "spearman": 0.026862912806503655, "kendall": 0.027585928143777173}, "kappa_score": -0.21350546176762664, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.061670393760732536, "spearman": 0.06167039376073258, "kendall": 0.06167039376073258}, "p_value": {"pearson": 0.5340022134034946, "spearman": 0.5340022134034944, "kendall": 0.5313896266968501}, "kappa_score": 0.03873239436619724, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": -0.08761918840023444, "spearman": -0.08761918840023439, "kendall": -0.08761918840023442}, "p_value": {"pearson": 0.376454997056514, "spearman": 0.376454997056514, "kendall": 0.37387537667731574}, "kappa_score": -0.08599508599508598, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": -0.08070466898086173, "spearman": -0.08070466898086172, "kendall": -0.08070466898086172}, "p_value": {"pearson": 0.41540915155119473, "spearman": 0.4154091515511943, "kendall": 0.4127505079813296}, "kappa_score": -0.07772020725388606, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": -0.21041647661119495, "spearman": -0.21041647661119492, "kendall": -0.21041647661119486}, "p_value": {"pearson": 0.032035705347967396, "spearman": 0.03203570534796718, "kendall": 0.03272067939179003}, "kappa_score": -0.20147874306839197, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.13092405451329003, "spearman": 0.1309240545132901, "kendall": 0.1309240545132901}, "p_value": {"pearson": 0.1852568996085906, "spearman": 0.1852568996085907, "kendall": 0.18393573278353892}, "kappa_score": 0.06215316315205344, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": -0.09582065893301983, "spearman": -0.09582065893301986, "kendall": -0.09582065893301983}, "p_value": {"pearson": 0.33324363683766933, "spearman": 0.3332436368376692, "kendall": 0.3308150534174823}, "kappa_score": -0.05892547660311953, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": -0.12998877418150553, "spearman": -0.12998877418150556, "kendall": -0.12998877418150553}, "p_value": {"pearson": 0.18844386649887568, "spearman": 0.18844386649887576, "kendall": 0.18708822990977514}, "kappa_score": -0.12941176470588234, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": -0.042014581590156766, "spearman": -0.04201458159015677, "kendall": -0.042014581590156766}, "p_value": {"pearson": 0.6719488220847287, "spearman": 0.6719488220847284, "kendall": 0.6698153575994166}, "kappa_score": -0.018433179723502224, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": -0.05050505050505047, "spearman": -0.05050505050505051, "kendall": -0.050505050505050504}, "p_value": {"pearson": 0.6106452915935101, "spearman": 0.610645291593509, "kendall": 0.6082519463104721}, "kappa_score": -0.050505050505050386, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": -0.016979054399120327, "spearman": -0.01697905439912036, "kendall": -0.016979054399120355}, "p_value": {"pearson": 0.8641666711562671, "spearman": 0.8641666711562671, "kendall": 0.8631870765561221}, "kappa_score": -0.009708737864077666, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": -0.044946657497549475, "spearman": -0.04494665749754947, "kendall": -0.044946657497549475}, "p_value": {"pearson": 0.6505077599100942, "spearman": 0.6505077599100939, "kendall": 0.648275823467581}, "kappa_score": -0.044642857142857206, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": -0.04309971159206156, "spearman": -0.04309971159206156, "kendall": -0.04309971159206156}, "p_value": {"pearson": 0.663981868133811, "spearman": 0.663981868133811, "kendall": 0.6618109156957125}, "kappa_score": -0.03833865814696469, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.03239597537401377, "spearman": 0.03239597537401377, "kendall": 0.03239597537401377}, "p_value": {"pearson": 0.744070189243995, "spearman": 0.7440701892439952, "kendall": 0.7423195310802435}, "kappa_score": 0.03143189755529685, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": -0.11028432237559468, "spearman": -0.11028432237559463, "kendall": -0.11028432237559466}, "p_value": {"pearson": 0.2650672365427003, "spearman": 0.2650672365427013, "kendall": 0.2630276873223302}, "kappa_score": -0.10105871029836377, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": -0.04355582277466924, "spearman": -0.04355582277466924, "kendall": -0.04355582277466924}, "p_value": {"pearson": 0.660644202201699, "spearman": 0.6606442022016987, "kendall": 0.6584578568079666}, "kappa_score": -0.018498367791077497, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": -0.1263812574008592, "spearman": -0.12638125740085918, "kendall": -0.12638125740085918}, "p_value": {"pearson": 0.20110965264023525, "spearman": 0.20110965264023484, "kendall": 0.19962184776972625}, "kappa_score": -0.11616161616161613, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": -0.04264445100899953, "spearman": -0.04264445100899954, "kendall": -0.04264445100899954}, "p_value": {"pearson": 0.6673198712572945, "spearman": 0.6673198712572941, "kendall": 0.6651644986592545}, "kappa_score": -0.040000000000000036, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.18490982138073722, "spearman": 0.1849098213807372, "kendall": 0.18490982138073722}, "p_value": {"pearson": 0.06022189020236744, "spearman": 0.060221890202367276, "kendall": 0.06056886020265741}, "kappa_score": 0.06612244897959174, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": -0.04268601559033573, "spearman": -0.04268601559033574, "kendall": -0.042686015590335746}, "p_value": {"pearson": 0.667014846344442, "spearman": 0.6670148463444412, "kendall": 0.6648580424290286}, "kappa_score": -0.03146374829001375, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": -0.055607067440108765, "spearman": -0.05560706744010878, "kendall": -0.05560706744010878}, "p_value": {"pearson": 0.5750271310156168, "spearman": 0.5750271310156161, "kendall": 0.5725158931911976}, "kappa_score": -0.05535055350553497, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": -0.02998126755983445, "spearman": -0.029981267559834452, "kendall": -0.029981267559834462}, "p_value": {"pearson": 0.7625585286467138, "spearman": 0.7625585286467155, "kendall": 0.7609171455129757}, "kappa_score": -0.028776978417266008, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": -0.02197616439259177, "spearman": -0.021976164392591792, "kendall": -0.02197616439259179}, "p_value": {"pearson": 0.8247562142915498, "spearman": 0.8247562142915507, "kendall": 0.8235092708783607}, "kappa_score": -0.02183406113537112, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": -0.25298221281347044, "spearman": -0.25298221281347033, "kendall": -0.25298221281347033}, "p_value": {"pearson": 0.009568822705439588, "spearman": 0.0095688227054396, "kendall": 0.010243802596871576}, "kappa_score": -0.2175226586102721, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": -0.07348836679370008, "spearman": -0.07348836679370006, "kendall": -0.07348836679370006}, "p_value": {"pearson": 0.45846146578108604, "spearman": 0.45846146578108593, "kendall": 0.4557728543943549}, "kappa_score": -0.051063829787234116, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.20842196696139487, "spearman": 0.20842196696139476, "kendall": 0.20842196696139478}, "p_value": {"pearson": 0.033738624596155925, "spearman": 0.033738624596155904, "kendall": 0.034408480022234955}, "kappa_score": 0.18324607329842935, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.1512816851570249, "spearman": 0.15128168515702486, "kendall": 0.15128168515702486}, "p_value": {"pearson": 0.12528387760199655, "spearman": 0.12528387760199616, "kendall": 0.1246999852957182}, "kappa_score": 0.12897822445561136, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": -0.045078391868073615, "spearman": -0.04507839186807362, "kendall": -0.045078391868073615}, "p_value": {"pearson": 0.6495509330383165, "spearman": 0.6495509330383167, "kendall": 0.6473147843885203}, "kappa_score": -0.01855670103092777, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": -0.055607067440108765, "spearman": -0.05560706744010878, "kendall": -0.05560706744010878}, "p_value": {"pearson": 0.5750271310156168, "spearman": 0.5750271310156161, "kendall": 0.5725158931911976}, "kappa_score": -0.05535055350553497, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.15475212458872706, "spearman": 0.1547521245887271, "kendall": 0.1547521245887271}, "p_value": {"pearson": 0.1167506926969953, "spearman": 0.11675069269699523, "kendall": 0.11628429878808527}, "kappa_score": 0.04677623261694053, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": -0.035010032878776194, "spearman": -0.0350100328787762, "kendall": -0.035010032878776194}, "p_value": {"pearson": 0.7242183731479342, "spearman": 0.7242183731479335, "kendall": 0.7223550969462649}, "kappa_score": -0.010704225352112573, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.2040698785434192, "spearman": 0.2040698785434192, "kendall": 0.20406987854341918}, "p_value": {"pearson": 0.037720474092232385, "spearman": 0.0377204740922322, "kendall": 0.03835103379099759}, "kappa_score": 0.07995916978564144, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": -0.031468954668723376, "spearman": -0.031468954668723376, "kendall": -0.03146895466872337}, "p_value": {"pearson": 0.7511514458706597, "spearman": 0.7511514458706604, "kendall": 0.7494421595417922}, "kappa_score": -0.02824858757062132, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": -0.14974023397346525, "spearman": -0.14974023397346523, "kendall": -0.1497402339734652}, "p_value": {"pearson": 0.12922425755369912, "spearman": 0.12922425755369907, "kendall": 0.12858704598927911}, "kappa_score": -0.09350356740518206, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.03117398431942749, "spearman": 0.031173984319427483, "kendall": 0.031173984319427486}, "p_value": {"pearson": 0.7534090125604745, "spearman": 0.7534090125604738, "kendall": 0.7517130433374133}, "kappa_score": 0.02857142857142858, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": -0.0612244897959184, "spearman": -0.06122448979591837, "kendall": -0.06122448979591837}, "p_value": {"pearson": 0.5369688984850216, "spearman": 0.536968898485022, "kendall": 0.5343623184517253}, "kappa_score": -0.06122448979591821, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.04962160002151726, "spearman": 0.04962160002151724, "kendall": 0.049621600021517255}, "p_value": {"pearson": 0.6169094703041342, "spearman": 0.6169094703041349, "kendall": 0.61453951393257}, "kappa_score": 0.020489094514210215, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": -0.04355582277466923, "spearman": -0.04355582277466924, "kendall": -0.04355582277466924}, "p_value": {"pearson": 0.660644202201699, "spearman": 0.6606442022016987, "kendall": 0.6584578568079666}, "kappa_score": -0.018498367791077497, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": -0.1018853416216987, "spearman": -0.10188534162169867, "kendall": -0.10188534162169866}, "p_value": {"pearson": 0.30340743383001884, "spearman": 0.30340743383001934, "kendall": 0.3011252781512592}, "kappa_score": -0.037815126050420256, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": -0.13625641413319153, "spearman": -0.13625641413319148, "kendall": -0.13625641413319145}, "p_value": {"pearson": 0.16783450801308405, "spearman": 0.1678345080130838, "kendall": 0.16671038199645205}, "kappa_score": -0.13043478260869557, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.035759012451554203, "spearman": 0.035759012451554203, "kendall": 0.035759012451554203}, "p_value": {"pearson": 0.7185632830323891, "spearman": 0.7185632830323887, "kendall": 0.7166688743699917}, "kappa_score": 0.02499999999999991, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": -0.01677978716107606, "spearman": -0.01677978716107607, "kendall": -0.016779787161076067}, "p_value": {"pearson": 0.8657458227384246, "spearman": 0.8657458227384232, "kendall": 0.864777167816573}, "kappa_score": -0.013864818024263315, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": -0.04658528162129117, "spearman": -0.04658528162129117, "kendall": -0.046585281621291164}, "p_value": {"pearson": 0.6386467550026456, "spearman": 0.6386467550026462, "kendall": 0.636363742882765}, "kappa_score": -0.0186092066601371, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.007946514953505714, "spearman": 0.007946514953505703, "kendall": 0.0079465149535057}, "p_value": {"pearson": 0.9361890027502016, "spearman": 0.9361890027502009, "kendall": 0.9357216386525409}, "kappa_score": 0.007633587786259555, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": -0.026469427034047404, "spearman": -0.026469427034047407, "kendall": -0.026469427034047407}, "p_value": {"pearson": 0.7896843904502631, "spearman": 0.7896843904502614, "kendall": 0.7882103105502956}, "kappa_score": -0.017114914425427896, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.022205825081290216, "spearman": 0.02220582508129023, "kendall": 0.022205825081290227}, "p_value": {"pearson": 0.8229545965269168, "spearman": 0.8229545965269164, "kendall": 0.8216957177413307}, "kappa_score": 0.017941454202077378, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": -0.024133196686197615, "spearman": -0.024133196686197622, "kendall": -0.024133196686197622}, "p_value": {"pearson": 0.8078720512277495, "spearman": 0.807872051227749, "kendall": 0.8065143519428498}, "kappa_score": -0.023622047244094446, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": -0.06831725428356214, "spearman": -0.06831725428356222, "kendall": -0.06831725428356222}, "p_value": {"pearson": 0.4907683731275882, "spearman": 0.4907683731275879, "kendall": 0.4880934419985651}, "kappa_score": -0.03351519875292297, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": -0.03799494353024639, "spearman": -0.03799494353024632, "kendall": -0.03799494353024633}, "p_value": {"pearson": 0.7017723016858621, "spearman": 0.7017723016858632, "kendall": 0.6997880727056446}, "kappa_score": -0.02796528447444535, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.13285783231567527, "spearman": 0.13285783231567522, "kendall": 0.13285783231567522}, "p_value": {"pearson": 0.17879245897033935, "spearman": 0.17879245897034024, "kendall": 0.17754270832266106}, "kappa_score": 0.05485789821546594, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gpt-4o (SP: None, AP: 9)": {"Simple": {"corr_coeff": {"pearson": -0.1581138830084189, "spearman": -0.15811388300841897, "kendall": -0.15811388300841897}, "p_value": {"pearson": 0.10892044192962073, "spearman": 0.10892044192962083, "kendall": 0.10856410165335996}, "kappa_score": -0.1304347826086958, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": -0.026347273384468593, "spearman": -0.026347273384468566, "kendall": -0.026347273384468562}, "p_value": {"pearson": 0.7906326625793936, "spearman": 0.7906326625793931, "kendall": 0.7891645709669761}, "kappa_score": -0.026315789473684292, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": -0.02970297029702968, "spearman": -0.029702970297029698, "kendall": -0.0297029702970297}, "p_value": {"pearson": 0.7646981543959686, "spearman": 0.7646981543959688, "kendall": 0.7630696756592528}, "kappa_score": -0.02970297029702973, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": -0.03873177009899627, "spearman": -0.038731770098996254, "kendall": -0.03873177009899625}, "p_value": {"pearson": 0.6962698273072033, "spearman": 0.696269827307203, "kendall": 0.6942570460428634}, "kappa_score": -0.03740648379052369, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": -0.046298091973689434, "spearman": -0.04629809197368942, "kendall": -0.04629809197368943}, "p_value": {"pearson": 0.640719084579547, "spearman": 0.6407190845795476, "kendall": 0.6384448158673675}, "kappa_score": -0.04208416833667328, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": -0.24525119397904704, "spearman": -0.24525119397904704, "kendall": -0.245251193979047}, "p_value": {"pearson": 0.012097057403721776, "spearman": 0.012097057403721825, "kendall": 0.012809295864413123}, "kappa_score": -0.22185792349726774, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": -0.08116412559294567, "spearman": -0.08116412559294567, "kendall": -0.08116412559294565}, "p_value": {"pearson": 0.41275018692907456, "spearman": 0.4127501869290744, "kendall": 0.41009531408488165}, "kappa_score": -0.07281553398058249, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": -0.05560706744010878, "spearman": -0.05560706744010878, "kendall": -0.05560706744010878}, "p_value": {"pearson": 0.5750271310156161, "spearman": 0.5750271310156161, "kendall": 0.5725158931911976}, "kappa_score": -0.05535055350553497, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": -0.09759000729485331, "spearman": -0.09759000729485331, "kendall": -0.09759000729485331}, "p_value": {"pearson": 0.3243524709477994, "spearman": 0.32435247094779895, "kendall": 0.32196379171227585}, "kappa_score": -0.08786610878661105, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": -0.09226097313475809, "spearman": -0.0922609731347581, "kendall": -0.09226097313475812}, "p_value": {"pearson": 0.35159601342360736, "spearman": 0.35159601342360747, "kendall": 0.34909475625926545}, "kappa_score": -0.07772020725388606, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": -0.10669117182157792, "spearman": -0.10669117182157789, "kendall": -0.10669117182157792}, "p_value": {"pearson": 0.28104683095051997, "spearman": 0.2810468309505203, "kendall": 0.2788984780583561}, "kappa_score": -0.10109289617486339, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": -0.07099094899376698, "spearman": -0.07099094899376693, "kendall": -0.07099094899376693}, "p_value": {"pearson": 0.47391560864989424, "spearman": 0.4739156086498949, "kendall": 0.4712298519793092}, "kappa_score": -0.07074973600844792, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": -0.03446909937728555, "spearman": -0.03446909937728555, "kendall": -0.03446909937728556}, "p_value": {"pearson": 0.7283118954492508, "spearman": 0.728311895449251, "kendall": 0.726471422820596}, "kappa_score": -0.03409090909090917, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": -0.07216494845360828, "spearman": -0.07216494845360824, "kendall": -0.07216494845360825}, "p_value": {"pearson": 0.4666159404405649, "spearman": 0.46661594044056476, "kendall": 0.46392797549443365}, "kappa_score": -0.07216494845360821, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": -0.05560706744010881, "spearman": -0.055607067440108786, "kendall": -0.05560706744010878}, "p_value": {"pearson": 0.5750271310156161, "spearman": 0.5750271310156161, "kendall": 0.5725158931911976}, "kappa_score": -0.05535055350553497, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": -0.145629560785166, "spearman": -0.14562956078516595, "kendall": -0.14562956078516595}, "p_value": {"pearson": 0.14019581404951872, "spearman": 0.14019581404951906, "kendall": 0.13941350064001307}, "kappa_score": -0.14178168130489333, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": -0.01532008661797191, "spearman": -0.015320086617971922, "kendall": -0.015320086617971925}, "p_value": {"pearson": 0.8773293622309285, "spearman": 0.8773293622309284, "kendall": 0.8764414238126652}, "kappa_score": -0.015113350125944613, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": -0.06487491201346023, "spearman": -0.06487491201346025, "kendall": -0.06487491201346025}, "p_value": {"pearson": 0.5129247021432154, "spearman": 0.5129247021432151, "kendall": 0.5102757088150994}, "kappa_score": -0.06289308176100628, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": -0.12998877418150553, "spearman": -0.12998877418150556, "kendall": -0.12998877418150553}, "p_value": {"pearson": 0.18844386649887568, "spearman": 0.18844386649887576, "kendall": 0.18708822990977514}, "kappa_score": -0.12941176470588234, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": -0.019706585563285858, "spearman": -0.01970658556328586, "kendall": -0.019706585563285865}, "p_value": {"pearson": 0.8426078469317946, "spearman": 0.8426078469317946, "kendall": 0.8414805811217939}, "kappa_score": -0.015625, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": -0.03873177009899624, "spearman": -0.03873177009899625, "kendall": -0.03873177009899625}, "p_value": {"pearson": 0.6962698273072033, "spearman": 0.696269827307203, "kendall": 0.6942570460428634}, "kappa_score": -0.03740648379052369, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": -0.019706585563285858, "spearman": -0.01970658556328586, "kendall": -0.019706585563285865}, "p_value": {"pearson": 0.8426078469317946, "spearman": 0.8426078469317946, "kendall": 0.8414805811217939}, "kappa_score": -0.015625, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": -0.04000000000000001, "spearman": -0.039999999999999994, "kendall": -0.04}, "p_value": {"pearson": 0.6868358589880845, "spearman": 0.6868358589880847, "kendall": 0.6847751781174618}, "kappa_score": -0.040000000000000036, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": -0.08333333333333331, "spearman": -0.08333333333333334, "kendall": -0.08333333333333334}, "p_value": {"pearson": 0.40033143464701276, "spearman": 0.4003314346470124, "kendall": 0.39769726575853726}, "kappa_score": -0.08333333333333326, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": -0.05372706895173353, "spearman": -0.053727068951733535, "kendall": -0.053727068951733535}, "p_value": {"pearson": 0.5880389294032584, "spearman": 0.5880389294032583, "kendall": 0.585567698540374}, "kappa_score": -0.05147058823529416, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": -0.07216494845360825, "spearman": -0.07216494845360824, "kendall": -0.07216494845360825}, "p_value": {"pearson": 0.4666159404405649, "spearman": 0.46661594044056476, "kendall": 0.46392797549443365}, "kappa_score": -0.07216494845360821, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": -0.013797369644231543, "spearman": -0.013797369644231549, "kendall": -0.013797369644231547}, "p_value": {"pearson": 0.8894405776918959, "spearman": 0.8894405776918957, "kendall": 0.8886378608950078}, "kappa_score": -0.01298701298701288, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": -0.04741523949866493, "spearman": -0.04741523949866491, "kendall": -0.04741523949866492}, "p_value": {"pearson": 0.6326735231395876, "spearman": 0.6326735231395875, "kendall": 0.6303657447629001}, "kappa_score": -0.04404145077720201, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": -0.02970297029702968, "spearman": -0.029702970297029698, "kendall": -0.0297029702970297}, "p_value": {"pearson": 0.7646981543959686, "spearman": 0.7646981543959688, "kendall": 0.7630696756592528}, "kappa_score": -0.02970297029702973, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.2606936229533506, "spearman": 0.2606936229533505, "kendall": 0.2606936229533505}, "p_value": {"pearson": 0.007521755587980665, "spearman": 0.007521755587980654, "kendall": 0.008150971593502691}, "kappa_score": 0.12727272727272732, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.031173984319427486, "spearman": 0.031173984319427483, "kendall": 0.031173984319427486}, "p_value": {"pearson": 0.7534090125604743, "spearman": 0.7534090125604738, "kendall": 0.7517130433374133}, "kappa_score": 0.02857142857142858, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": -0.03146895466872339, "spearman": -0.031468954668723376, "kendall": -0.031468954668723376}, "p_value": {"pearson": 0.7511514458706597, "spearman": 0.7511514458706604, "kendall": 0.7494421595417922}, "kappa_score": -0.02824858757062132, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.029216163036280034, "spearman": 0.029216163036280014, "kendall": 0.029216163036280014}, "p_value": {"pearson": 0.768445111463403, "spearman": 0.7684451114634026, "kendall": 0.7668393556324486}, "kappa_score": 0.02904564315352698, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": -0.012012499502607446, "spearman": -0.012012499502607455, "kendall": -0.012012499502607452}, "p_value": {"pearson": 0.9036691084328355, "spearman": 0.9036691084328352, "kendall": 0.9029674804668391}, "kappa_score": -0.011976047904191489, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": -0.17863711103108795, "spearman": -0.17863711103108793, "kendall": -0.1786371110310879}, "p_value": {"pearson": 0.06962331161321593, "spearman": 0.06962331161321615, "kendall": 0.06983665374917752}, "kappa_score": -0.16955017301038056, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": -0.01698170640419704, "spearman": -0.016981706404197033, "kendall": -0.016981706404197036}, "p_value": {"pearson": 0.8641456581549873, "spearman": 0.8641456581549875, "kendall": 0.8631659180932314}, "kappa_score": -0.014634146341463428, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": -0.006118563994697596, "spearman": -0.006118563994697589, "kendall": -0.006118563994697588}, "p_value": {"pearson": 0.9508465153633012, "spearman": 0.950846515363302, "kendall": 0.9504858707242864}, "kappa_score": -0.006109979633401208, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.20374571037633116, "spearman": 0.2037457103763311, "kendall": 0.2037457103763311}, "p_value": {"pearson": 0.038032202677624395, "spearman": 0.03803220267762448, "kendall": 0.038659480788728114}, "kappa_score": 0.191111111111111, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": -0.009708737864077674, "spearman": -0.00970873786407767, "kendall": -0.00970873786407767}, "p_value": {"pearson": 0.9220786212973373, "spearman": 0.9220786212973373, "kendall": 0.9215091265495959}, "kappa_score": -0.009708737864077666, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": -0.0505050505050505, "spearman": -0.05050505050505051, "kendall": -0.050505050505050504}, "p_value": {"pearson": 0.6106452915935081, "spearman": 0.610645291593509, "kendall": 0.6082519463104722}, "kappa_score": -0.050505050505050386, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.12638326787979084, "spearman": 0.1263832678797909, "kendall": 0.12638326787979087}, "p_value": {"pearson": 0.20110242764534644, "spearman": 0.20110242764534664, "kendall": 0.19961469597325643}, "kappa_score": 0.09800520381613165, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": -0.06487491201346021, "spearman": -0.06487491201346025, "kendall": -0.06487491201346025}, "p_value": {"pearson": 0.5129247021432154, "spearman": 0.5129247021432151, "kendall": 0.5102757088150994}, "kappa_score": -0.06289308176100628, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": -0.019607843137254905, "spearman": -0.019607843137254905, "kendall": -0.019607843137254898}, "p_value": {"pearson": 0.8433863981178318, "spearman": 0.8433863981178312, "kendall": 0.8422644077753896}, "kappa_score": -0.019607843137255054, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": -0.025027809091526132, "spearman": -0.025027809091526108, "kendall": -0.0250278090915261}, "p_value": {"pearson": 0.8008947858076592, "spearman": 0.8008947858076594, "kendall": 0.7994920656939639}, "kappa_score": -0.023066485753052923, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": -0.07142857142857141, "spearman": -0.07142857142857142, "kendall": -0.07142857142857144}, "p_value": {"pearson": 0.4711873639420059, "spearman": 0.4711873639420059, "kendall": 0.4685006036198155}, "kappa_score": -0.07058823529411762, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": -0.042644451008999495, "spearman": -0.04264445100899953, "kendall": -0.04264445100899953}, "p_value": {"pearson": 0.6673198712572935, "spearman": 0.6673198712572941, "kendall": 0.6651644986592545}, "kappa_score": -0.040000000000000036, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": -0.10158117067285229, "spearman": -0.10158117067285224, "kendall": -0.10158117067285227}, "p_value": {"pearson": 0.3048608248241446, "spearman": 0.3048608248241446, "kendall": 0.30257069898034017}, "kappa_score": -0.08982035928143706, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": -0.009708737864077676, "spearman": -0.00970873786407767, "kendall": -0.00970873786407767}, "p_value": {"pearson": 0.9220786212973373, "spearman": 0.9220786212973373, "kendall": 0.9215091265495959}, "kappa_score": -0.009708737864077666, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": -0.04567210044745518, "spearman": -0.045672100447455184, "kendall": -0.045672100447455184}, "p_value": {"pearson": 0.6452457292272202, "spearman": 0.6452457292272202, "kendall": 0.6429908261365962}, "kappa_score": -0.0331125827814569, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": -0.14170127713626784, "spearman": -0.14170127713626782, "kendall": -0.1417012771362678}, "p_value": {"pearson": 0.1513267714519386, "spearman": 0.15132677145193837, "kendall": 0.15040259145487528}, "kappa_score": -0.14138153647514518, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.05382149791824944, "spearman": 0.053821497918249424, "kendall": 0.053821497918249424}, "p_value": {"pearson": 0.5873821824202422, "spearman": 0.5873821824202422, "kendall": 0.5849088459642058}, "kappa_score": 0.03967168262653886, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": -0.09919663684480977, "spearman": -0.0991966368448098, "kendall": -0.0991966368448098}, "p_value": {"pearson": 0.3164120879843381, "spearman": 0.31641208798433845, "kendall": 0.3140617000853634}, "kappa_score": -0.0991253644314869, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": -0.024380576742367474, "spearman": -0.024380576742367467, "kendall": -0.024380576742367474}, "p_value": {"pearson": 0.8059411517400316, "spearman": 0.8059411517400318, "kendall": 0.8045709480174332}, "kappa_score": -0.016759776536312776, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.07151402775784323, "spearman": 0.07151402775784324, "kendall": 0.07151402775784324}, "p_value": {"pearson": 0.47065560637623943, "spearman": 0.47065560637623927, "kendall": 0.46796867513671214}, "kappa_score": 0.0714285714285714, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": -0.013797369644231545, "spearman": -0.013797369644231549, "kendall": -0.013797369644231547}, "p_value": {"pearson": 0.8894405776918959, "spearman": 0.8894405776918957, "kendall": 0.8886378608950078}, "kappa_score": -0.01298701298701288, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": -0.044946657497549454, "spearman": -0.04494665749754947, "kendall": -0.044946657497549475}, "p_value": {"pearson": 0.6505077599100941, "spearman": 0.6505077599100939, "kendall": 0.648275823467581}, "kappa_score": -0.044642857142857206, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": -0.024133196686197615, "spearman": -0.024133196686197622, "kendall": -0.024133196686197622}, "p_value": {"pearson": 0.8078720512277499, "spearman": 0.807872051227749, "kendall": 0.8065143519428498}, "kappa_score": -0.023622047244094446, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": -0.0041926233634553695, "spearman": -0.004192623363455352, "kendall": -0.004192623363455351}, "p_value": {"pearson": 0.9663074138856058, "spearman": 0.9663074138856051, "kendall": 0.9660598710298038}, "kappa_score": -0.0035087719298247944, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": -0.02465568363607695, "spearman": -0.024655683636076897, "kendall": -0.024655683636076897}, "p_value": {"pearson": 0.8037952018570041, "spearman": 0.8037952018570047, "kendall": 0.802411141503359}, "kappa_score": -0.024390243902439046, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": -0.011595810494742684, "spearman": -0.01159581049474271, "kendall": -0.011595810494742712}, "p_value": {"pearson": 0.9069954094804478, "spearman": 0.9069954094804474, "kendall": 0.9063175509193407}, "kappa_score": -0.006951340615690249, "total_responses": 104, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}}