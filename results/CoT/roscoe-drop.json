{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.38513110818813207, "spearman": 0.384165667533821, "kendall": 0.33425799172719783}, "p_value": {"pearson": 7.835198593301378e-09, "spearman": 8.599014924982381e-09, "kendall": 1.1038112843079858e-08}, "kappa_score": 0.17871453758615152, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.44288279514667506, "spearman": 0.4893090160574349, "kendall": 0.4398151815567955}, "p_value": {"pearson": 2.105283957877108e-11, "spearman": 6.40069216551433e-14, "kendall": 3.222113441875039e-12}, "kappa_score": 0.21068165846802522, "total_responses": 210, "valid_responses": 208, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.036815497579446466, "spearman": -0.036815497579446466, "kendall": -0.03681549757944646}, "p_value": {"pearson": 0.6065987251834649, "spearman": 0.6065987251834645, "kendall": 0.6053445583879132}, "kappa_score": -0.015974440894568565, "total_responses": 210, "valid_responses": 198, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.21476628916142532, "spearman": -0.2147662891614253, "kendall": -0.2147662891614253}, "p_value": {"pearson": 0.0019858016605241095, "spearman": 0.001985801660524092, "kendall": 0.0021587467527422587}, "kappa_score": -0.08554657033783508, "total_responses": 210, "valid_responses": 205, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4165715904183822, "spearman": 0.3897305099581545, "kendall": 0.3378778019340166}, "p_value": {"pearson": 3.3385740192095517e-09, "spearman": 3.833500787605507e-08, "kendall": 7.815515682616003e-08}, "kappa_score": 0.18159682173522995, "total_responses": 210, "valid_responses": 186, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.19632826388297858, "spearman": 0.19359238792299077, "kendall": 0.17545922101431957}, "p_value": {"pearson": 0.007562039219249013, "spearman": 0.008461532255897342, "kendall": 0.008806529550624902}, "kappa_score": 0.07576857903655287, "total_responses": 210, "valid_responses": 184, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.23706501552921716, "spearman": -0.23706501552921716, "kendall": -0.23706501552921716}, "p_value": {"pearson": 0.0009304902766277328, "spearman": 0.0009304902766277316, "kendall": 0.0010517539800276375}, "kappa_score": -0.21875, "total_responses": 210, "valid_responses": 192, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.04236466795155182, "spearman": -0.0423646679515518, "kendall": -0.0423646679515518}, "p_value": {"pearson": 0.5637636643002606, "spearman": 0.5637636643002617, "kendall": 0.5623677942048317}, "kappa_score": -0.00797360461919161, "total_responses": 210, "valid_responses": 188, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.30170102143108873, "spearman": 0.27737799664490165, "kendall": 0.24481551846529595}, "p_value": {"pearson": 8.582913763234232e-06, "spearman": 4.584408136703595e-05, "kendall": 6.66703865067542e-05}, "kappa_score": 0.08931943764426109, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.12019866653359645, "spearman": 0.06160597945445573, "kendall": 0.054224039883580065}, "p_value": {"pearson": 0.08225428539860515, "spearman": 0.3743950479279554, "kendall": 0.3972515909718024}, "kappa_score": 0.025114897172833217, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.06911739145392246, "spearman": -0.06911739145392247, "kendall": -0.06911739145392247}, "p_value": {"pearson": 0.3188516649418669, "spearman": 0.318851664941867, "kendall": 0.3176888380139936}, "kappa_score": -0.03221276222241731, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.06438637210528617, "spearman": -0.06438637210528621, "kendall": -0.06438637210528622}, "p_value": {"pearson": 0.35668204716108237, "spearman": 0.35668204716108254, "kendall": 0.3554247321288164}, "kappa_score": -0.027716617018520795, "total_responses": 210, "valid_responses": 207, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.3094481173243899, "spearman": 0.3048539056800094, "kendall": 0.26515647969825634}, "p_value": {"pearson": 5.411623362825166e-06, "spearman": 7.56264007907217e-06, "kendall": 1.165102372220626e-05}, "kappa_score": 0.12321895140219463, "total_responses": 210, "valid_responses": 208, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.24257736891373588, "spearman": 0.26050252347287073, "kendall": 0.2370913629299106}, "p_value": {"pearson": 0.00047270106814875423, "spearman": 0.00016786229078078447, "kendall": 0.00020776674906100738}, "kappa_score": 0.14072570413600605, "total_responses": 210, "valid_responses": 204, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.14146895587545702, "spearman": -0.141468955875457, "kendall": -0.14146895587545702}, "p_value": {"pearson": 0.04054473765088944, "spearman": 0.04054473765088951, "kendall": 0.04083583729524579}, "kappa_score": -0.14036688874691983, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.0290543601573988, "spearman": -0.029054360157398817, "kendall": -0.029054360157398828}, "p_value": {"pearson": 0.6777203721607494, "spearman": 0.6777203721607485, "kendall": 0.67667217745879}, "kappa_score": -0.007160561828697176, "total_responses": 210, "valid_responses": 207, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5221298331774165, "spearman": 0.4601863140098989, "kendall": 0.4167063673434356}, "p_value": {"pearson": 4.389971213392163e-16, "spearman": 2.108102661750109e-12, "kendall": 2.8319359856472555e-11}, "kappa_score": 0.09383456447012362, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.1802013949749633, "spearman": 0.12392914866273888, "kendall": 0.11750646838489832}, "p_value": {"pearson": 0.010090402151565966, "spearman": 0.07813483418938755, "kendall": 0.07883147419271432}, "kappa_score": 0.06409875074360505, "total_responses": 210, "valid_responses": 203, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.2440011055006973, "spearman": -0.2440011055006973, "kendall": -0.2440011055006973}, "p_value": {"pearson": 0.0004088012941317915, "spearman": 0.00040880129413179214, "kendall": 0.0004766184258876243}, "kappa_score": -0.23076187744957477, "total_responses": 210, "valid_responses": 206, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.16430790089689282, "spearman": -0.16430790089689284, "kendall": -0.16430790089689284}, "p_value": {"pearson": 0.01743963662571896, "spearman": 0.017439636625719065, "kendall": 0.017803378499628614}, "kappa_score": -0.0575393956917738, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5471427189835385, "spearman": 0.49466353135226454, "kendall": 0.44017408367606975}, "p_value": {"pearson": 1.3317977740319764e-15, "spearman": 1.269047136168063e-12, "kendall": 2.5093029496826646e-11}, "kappa_score": 0.14723839273037065, "total_responses": 210, "valid_responses": 182, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3801535966978416, "spearman": 0.28743890493361574, "kendall": 0.25721335010959057}, "p_value": {"pearson": 1.7983067990624539e-07, "spearman": 0.00010479289372594016, "kendall": 0.00018017148020417413}, "kappa_score": 0.12462908011869445, "total_responses": 210, "valid_responses": 177, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.1207626456227566, "spearman": -0.12076264562275658, "kendall": -0.1207626456227566}, "p_value": {"pearson": 0.08155134942459462, "spearman": 0.0815513494245947, "kendall": 0.08156731771462081}, "kappa_score": -0.11588281721528393, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.12395288351066894, "spearman": -0.12395288351066894, "kendall": -0.12395288351066897}, "p_value": {"pearson": 0.07306165243511832, "spearman": 0.07306165243511809, "kendall": 0.07313840457114493}, "kappa_score": -0.02559784439205126, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.711317171774977, "spearman": 0.6823619934801347, "kendall": 0.6060697321474651}, "p_value": {"pearson": 1.0926431965641428e-33, "spearman": 4.005235045972119e-30, "kendall": 4.734577355717304e-25}, "kappa_score": 0.3153868500048417, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3782036523255585, "spearman": 0.40953970363988257, "kendall": 0.3765608412214471}, "p_value": {"pearson": 1.5172096914694395e-08, "spearman": 6.733515722156691e-10, "kendall": 2.101490923658405e-09}, "kappa_score": 0.18080748976009364, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.2912368212244151, "spearman": 0.2912368212244151, "kendall": 0.2912368212244151}, "p_value": {"pearson": 2.3776762152903513e-05, "spearman": 2.377676215290346e-05, "kendall": 3.332227008229151e-05}, "kappa_score": 0.2361408286325618, "total_responses": 210, "valid_responses": 204, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.03903853274282888, "spearman": 0.03903853274282886, "kendall": 0.03903853274282886}, "p_value": {"pearson": 0.5774513689276799, "spearman": 0.5774513689276797, "kendall": 0.5761980785450496}, "kappa_score": 0.01813084112149521, "total_responses": 210, "valid_responses": 206, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": -0.029174039698517354, "spearman": -0.050775394000336496, "kendall": -0.04409511166773249}, "p_value": {"pearson": 0.7848850932437935, "spearman": 0.6345937919255797, "kendall": 0.6376134276602523}, "kappa_score": 0.005960729312763036, "total_responses": 210, "valid_responses": 90, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": -0.046379985315171346, "spearman": -0.029355443349237925, "kendall": -0.026348801123887423}, "p_value": {"pearson": 0.6771481789477736, "spearman": 0.7922101791251246, "kendall": 0.7968638865351998}, "kappa_score": -0.023755139333028863, "total_responses": 210, "valid_responses": 83, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.11948429397398497, "spearman": -0.11948429397398494, "kendall": -0.11948429397398498}, "p_value": {"pearson": 0.12519871419435316, "spearman": 0.12519871419435408, "kendall": 0.12483209162120194}, "kappa_score": -0.10155799192152348, "total_responses": 210, "valid_responses": 166, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.18126444803093084, "spearman": -0.1812644480309308, "kendall": -0.18126444803093078}, "p_value": {"pearson": 0.03272008597818285, "spearman": 0.03272008597818295, "kendall": 0.033223236928875514}, "kappa_score": -0.04400132934529766, "total_responses": 210, "valid_responses": 139, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5690398367300532, "spearman": 0.5239600800792433, "kendall": 0.46487353851814983}, "p_value": {"pearson": 2.0437159786768242e-19, "spearman": 3.326197323261457e-16, "kendall": 1.842379253181128e-14}, "kappa_score": 0.22768537538930478, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.410572724875894, "spearman": 0.3514952535754311, "kendall": 0.32775773119283474}, "p_value": {"pearson": 6.042324335793493e-10, "spearman": 1.6847549163725842e-07, "kendall": 3.025471423432336e-07}, "kappa_score": 0.2001284934147124, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.1542950674932565, "spearman": -0.1542950674932565, "kendall": -0.1542950674932565}, "p_value": {"pearson": 0.025351165320510675, "spearman": 0.025351165320510852, "kendall": 0.025706449109275418}, "kappa_score": -0.12934631432545185, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.112992857486784, "spearman": -0.11299285748678399, "kendall": -0.112992857486784}, "p_value": {"pearson": 0.1033251146610253, "spearman": 0.10332511466102533, "kendall": 0.10318476044266829}, "kappa_score": -0.034930406852248685, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 9)": {"Overall Quality": {"corr_coeff": {"pearson": 0.7293015017329769, "spearman": 0.6616131186757845, "kendall": 0.5902696331397315}, "p_value": {"pearson": 3.93333016415945e-36, "spearman": 8.189957006194244e-28, "kendall": 3.876105603882313e-23}, "kappa_score": 0.30686137227445487, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.4312040680926754, "spearman": 0.427531073691256, "kendall": 0.39410868628899315}, "p_value": {"pearson": 6.419646173583467e-11, "spearman": 9.676404731834749e-11, "kendall": 6.118134918421053e-10}, "kappa_score": 0.19891008174386915, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.05890078303763706, "spearman": -0.05890078303763708, "kendall": -0.05890078303763708}, "p_value": {"pearson": 0.39577204133363864, "spearman": 0.39577204133363897, "kendall": 0.3944812564796262}, "kappa_score": -0.054547129825854634, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.21889586523635782, "spearman": -0.21889586523635782, "kendall": -0.21889586523635782}, "p_value": {"pearson": 0.0014130643768013624, "spearman": 0.0014130643768013498, "kendall": 0.0015532787536372769}, "kappa_score": -0.04016982364467658, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}