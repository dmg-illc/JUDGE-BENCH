{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": 0.04764178316642266, "spearman": 0.04764178316642266, "kendall": 0.04764178316642267}, "p_value": {"pearson": 0.41812993588254654, "spearman": 0.41812993588254554, "kendall": 0.4171874777477169}, "kappa_score": 0.04402102496714844, "total_responses": 300, "valid_responses": 291, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": 0.13813377827742757, "spearman": 0.13813377827742754, "kendall": 0.13813377827742757}, "p_value": {"pearson": 0.017221452749854257, "spearman": 0.01722145274985432, "kendall": 0.017475706283602264}, "kappa_score": 0.12957746478873244, "total_responses": 300, "valid_responses": 297, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": 0.40147321760611676, "spearman": 0.40147321760611676, "kendall": 0.40147321760611676}, "p_value": {"pearson": 1.533476058934609e-12, "spearman": 1.5334760589346173e-12, "kendall": 1.1250085562394548e-11}, "kappa_score": 0.3980754204877247, "total_responses": 300, "valid_responses": 287, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": 0.11643543432050885, "spearman": 0.11643543432050887, "kendall": 0.11643543432050887}, "p_value": {"pearson": 0.04460337362101657, "spearman": 0.04460337362101664, "kendall": 0.04479099895141482}, "kappa_score": 0.11584625758597444, "total_responses": 300, "valid_responses": 298, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": 0.011561757565517333, "spearman": 0.011561757565517368, "kendall": 0.011561757565517364}, "p_value": {"pearson": 0.8451089736275323, "spearman": 0.8451089736275313, "kendall": 0.8447130190773612}, "kappa_score": 0.009995240361732494, "total_responses": 300, "valid_responses": 288, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": -0.0037385419869990708, "spearman": -0.0037385419869990695, "kendall": -0.003738541986999069}, "p_value": {"pearson": 0.9496315629600172, "spearman": 0.949631562960016, "kendall": 0.9494998112247128}, "kappa_score": -0.0020311442112390665, "total_responses": 300, "valid_responses": 288, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": -0.020071066902935863, "spearman": -0.020071066902935822, "kendall": -0.020071066902935825}, "p_value": {"pearson": 0.7300500689985471, "spearman": 0.7300500689985494, "kendall": 0.7294189932541342}, "kappa_score": -0.011903023221849107, "total_responses": 300, "valid_responses": 298, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": 0.04516733362865101, "spearman": 0.045167333628651024, "kendall": 0.04516733362865103}, "p_value": {"pearson": 0.5191491106371154, "spearman": 0.519149110637116, "kendall": 0.5178275467108068}, "kappa_score": 0.020121826021490596, "total_responses": 300, "valid_responses": 206, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": 0.2645265352192987, "spearman": 0.26452653521929864, "kendall": 0.2645265352192987}, "p_value": {"pearson": 3.390529628425692e-06, "spearman": 3.390529628425717e-06, "kendall": 4.782910434973557e-06}, "kappa_score": 0.25316307403936267, "total_responses": 300, "valid_responses": 300, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 9)": {"Sound Reasoning": {"corr_coeff": {"pearson": 0.5252606643429443, "spearman": 0.525260664342944, "kendall": 0.525260664342944}, "p_value": {"pearson": 1.1232239549002932e-22, "spearman": 1.123223954900407e-22, "kendall": 1.0600581873183718e-19}, "kappa_score": 0.47371177209886894, "total_responses": 300, "valid_responses": 300, "krippendorff_alpha": 1, "type": "categorical", "expert": "true", "task": "Reasoning"}}}