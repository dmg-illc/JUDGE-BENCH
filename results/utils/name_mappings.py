dataset_names = [
    "cola",
    "inferential-strategies",
    "switchboard-acceptability",
    "qags",
    "persona-chat",
    "newsroom",
    "roscoe-cosmos",
    "roscoe-drop",
    "dailydialog-acceptability",
    "roscoe-esnli",
    "roscoe-gsm8k",
    "topical-chat",
    "summeval",
    "medical-safety",
    "wmt-human-en-de",
    "wmt-human-zh-en",
    "cola-grammar",
    "llmbar-natural",
    "dices-990",
    "dices-350-expert",
    "dices-350-crowdsourced",
    "llmbar-adversarial",
    "wmt-23-en-de",
    "wmt-23-zh-en",
    "toxic-chat",
    "recipe-crowd-sourcing-data",
]

candidate_models = [
    "gpt-4o",
    "gemini-1.5-flash-latest",
    "Meta-Llama-3-70B-Instruct",
    "Mixtral-8x7B-Instruct-v0.1",
    "Mixtral-8x22B-Instruct-v0.1",
    "Meta-Llama-3-8B-Instruct",
    "c4ai-command-r-plus",
]
all_models = {
    "Meta-Llama-3-8B-Instruct": "Open",
    "Mistral-7B-Instruct-v0.2": "Open",
    "Starling-LM-7B-alpha": "Open",
    "Meta-Llama-3-70B-Instruct": "Open",
    "c4ai-command-r-v01": "Open",
    "OLMo-7B-Instruct": "Open",
    "gpt-3.5-turbo-0125": "Closed",
    "gpt-4o": "Closed",
    "gemini-1.5-flash-latest": "Closed",
    "Mixtral-8x7B-Instruct-v0.1": "Open",
    "Mixtral-8x22B-Instruct-v0.1": "Open",
    "c4ai-command-r-plus": "Open",
}
# Name mapping
models_short_names = {
    "Meta-Llama-3-8B-Instruct": "Llama-3-8B",
    "Meta-Llama-3-70B-Instruct": "Llama-3-70B",
    "Mixtral-8x7B-Instruct-v0.1": "Mixtral-8x7B",
    "Mixtral-8x22B-Instruct-v0.1": "Mixtral-8x22B",
    "gpt-4o": "GPT-4o",
    "gemini-1.5-flash-latest": "Gemini-1.5",
    "c4ai-command-r-v01": "Comm-R4",
    "c4ai-command-r-plus": "Comm-R+",
    "OLMo-7B-Instruct": "OLMo-7B",
    "Starling-LM-7B-alpha": "Starling-7B",
    "gpt-3.5-turbo-0125": "GPT-3.5",
    "Mistral-7B-Instruct-v0.2": "Mistral-7B",
}

task_cabapility_mappings = {
    "Acceptability": "B",
    "Reasoning": "B",
    "Summarisation": "D",
    "Dialogue": "D",
    "Toxicity \ Safety": "B",
    "Translation": "D",
    "Instruction Following": "D",
    "Planning": "B",
}
tasks_dataset_names = {
    "cola": "Acceptability",
    "cola-grammar": "Acceptability",
    "dailydialog-acceptability": "Acceptability",
    "newsroom": "Summarisation",
    "persona-chat": "Dialogue",
    "persona_chat": "Dialogue",
    "qags": "Summarisation",
    "roscoe-cosmos": "Reasoning",
    "roscoe-drop": "Reasoning",
    "roscoe-esnli": "Reasoning",
    "roscoe-gsm8k": "Reasoning",
    "summeval": "Summarisation",
    "switchboard-acceptability": "Acceptability",
    "topical_chat": "Dialogue",
    "topical-chat": "Dialogue",
    "wmt-human_en_de": "Translation",
    "wmt-human_zh_en": "Translation",
    "wmt-human-en-de": "Translation",
    "wmt-human-zh-en": "Translation",
    "wmt-23_en_de": "Translation",
    "wmt-23_zh_en": "Translation",
    "wmt-23-en-de": "Translation",
    "wmt-23-zh-en": "Translation",
    "inferential-strategies": "Reasoning",
    "medical-safety": "Toxicity \ Safety",
    "toxic_chat": "Toxicity \ Safety",
    "toxic-chat": "Toxicity \ Safety",
    "dices-990": "Toxicity \ Safety",
    "dices_990": "Toxicity \ Safety",
    "dices_350_expert": "Toxicity \ Safety",
    "dices-350-expert": "Toxicity \ Safety",
    "dices_350_crowdsourced": "Toxicity \ Safety",
    "dices-350-crowdsourced": "Toxicity \ Safety",
    "recipe_crowd_sourcing_data": "Planning",
    "recipe-crowd-sourcing-data": "Planning",
    "llmbar-natural": "Instruction Following",
    "llmbar-adversarial": "Instruction Following",
}
dataset_human_vs_machines = {
    "cola": "human",
    "inferential-strategies": "model-generated",
    "switchboard-acceptability": "human",
    "qags": "model-generated",
    "persona-chat": "model-generated",
    "newsroom": "model-generated",
    "roscoe-cosmos": "model-generated",
    "roscoe-drop": "model-generated",
    "dailydialog-acceptability": "human",
    "roscoe-esnli": "model-generated",
    "roscoe-gsm8k": "model-generated",
    "topical-chat": "model-generated",
    "summeval": "model-generated",
    "medical-safety": "model-generated",
    "wmt-human-en-de": "model-generated",
    "wmt-human-zh-en": "model-generated",
    "cola-grammar": "human",
    "llmbar-natural": "human",
    "dices-990": "model-generated",
    "dices-350-expert": "model-generated",
    "dices-350-crowdsourced": "model-generated",
    "llmbar-adversarial": "human",
    "wmt-23-en-de": "model-generated",
    "wmt-23-zh-en": "model-generated",
    "toxic-chat": "human",
    "recipe-crowd-sourcing-data": "model-generated",
}
subtask_to_cat = {
    "acceptability": "acceptability",
    "add arg": "grammaticality",
    "aux": "grammaticality",
    "binding:other": "grammaticality",
    "binding:refl": "grammaticality",
    "by-phrase": "grammaticality",
    "coherence": "coherence",
    "coherency": "coherence",
    "comparative": "grammaticality",
    "complex qp": "grammaticality",
    "compx np": "grammaticality",
    "consistency": "consistency",
    "contradiction": "correct reasoning",
    "control": "grammaticality",
    "coord": "grammaticality",
    "copula": "grammaticality",
    "cp arg np/ap": "grammaticality",
    "cp arg vp": "grammaticality",
    "cp subj": "grammaticality",
    "deep embed": "grammaticality",
    "deverbal": "grammaticality",
    "dislocation": "grammaticality",
    "drop arg": "grammaticality",
    "ellipsis/anaphor": "grammaticality",
    "emb q": "grammaticality",
    "engaging": "engaging",
    "expletive": "grammaticality",
    "extra/mising expr": "grammaticality",
    "factual consistency": "consistency",
    "fluency": "fluency",
    "frag/paren": "grammaticality",
    "grammar": "grammaticality",
    "grammaticality": "grammaticality",
    "high arity": "grammaticality",
    "imperative": "grammaticality",
    "infl/agr violation": "grammaticality",
    "info struc": "grammaticality",
    "informativeness": "informativeness",
    "island": "grammaticality",
    "jailbreaking": "remove",
    "locative": "grammaticality",
    "maintains context": "remove",
    "matrix q": "grammaticality",
    "misc": "grammaticality",
    "missing steps": "correct reasoning",
    "modal": "grammaticality",
    "natural": "remove",
    "neg": "grammaticality",
    "nncompd": "grammaticality",
    "no c-izer": "grammaticality",
    "non-finite cp": "grammaticality",
    "non-finite vp misc": "grammaticality",
    "np adjunct": "grammaticality",
    "npi/fci": "grammaticality",
    "oblique": "grammaticality",
    "overall": "remove",
    "overall quality": "remove",
    "particle": "grammaticality",
    "partitive": "grammaticality",
    "passive": "grammaticality",
    "pp arg-vp": "grammaticality",
    "pparg-np/ap": "grammaticality",
    "pred/sc": "grammaticality",
    "psuedo-aux": "grammaticality",
    "quality": "remove",
    "quality_single_turn": "remove",
    "quantifier": "grammaticality",
    "query risk level": "remove",
    "raising": "grammaticality",
    "rc": "grammaticality",
    "rel adj": "grammaticality",
    "rel np": "grammaticality",
    "relevance": "relevance",
    "response type": "remove",
    "result/depictive": "grammaticality",
    "s-adjunct": "grammaticality",
    "safety": "safety",
    "sem  violation": "grammaticality",
    "simple": "grammaticality",
    "sound reasoning": "correct reasoning",
    "structure": "remove",
    "subordinate/cond": "grammaticality",
    "success": "remove",
    "temporal": "grammaticality",
    "toxicity": "toxicity",
    "trans adj": "grammaticality",
    "trans np": "grammaticality",
    "understandable": "remove",
    "uses knowledge": "remove",
    "verbosity": "verbosity",
    "vp adjunct": "grammaticality",
    "vp arg-np/ap": "grammaticality",
    "vp+extract": "grammaticality",
}