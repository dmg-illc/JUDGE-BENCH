{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.07992813704912077, "spearman": 0.07992813704912081, "kendall": 0.07992813704912081}, "p_value": {"pearson": 0.009812800387848267, "spearman": 0.009812800387848424, "kendall": 0.009877678723069586}, "kappa_score": 0.0643521151173646, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.23615110640664289, "spearman": 0.23615110640664286, "kendall": 0.23615110640664286}, "p_value": {"pearson": 1.100938299293363e-14, "spearman": 1.1009382992933872e-14, "kendall": 2.4791687042997107e-14}, "kappa_score": 0.1565791225671519, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.020892519947234935, "spearman": 0.020892519947234928, "kendall": 0.020892519947234924}, "p_value": {"pearson": 0.5003119048776572, "spearman": 0.5003119048776579, "kendall": 0.5000500120616964}, "kappa_score": 0.0008726138858079491, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.12280887707828553, "spearman": 0.1228088770782855, "kendall": 0.1228088770782855}, "p_value": {"pearson": 6.994273994464225e-05, "spearman": 6.994273994464213e-05, "kendall": 7.361977971618033e-05}, "kappa_score": 0.02971586529516501, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.08060457794480803, "spearman": 0.08060457794480803, "kendall": 0.08060457794480803}, "p_value": {"pearson": 0.009206672233244421, "spearman": 0.009206672233244458, "kendall": 0.009270407627640255}, "kappa_score": 0.012910316380769449, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.2985355416297645, "spearman": 0.2985355416297645, "kendall": 0.2985355416297644}, "p_value": {"pearson": 6.495822063539827e-23, "spearman": 6.495822063539485e-23, "kendall": 5.593907914933918e-22}, "kappa_score": 0.18935745830408535, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.11295330630750205, "spearman": 0.11295330630750207, "kendall": 0.11295330630750208}, "p_value": {"pearson": 0.0002569677873596596, "spearman": 0.0002569677873596779, "kendall": 0.0002662136117560314}, "kappa_score": 0.02519544401388496, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.313722025358678, "spearman": 0.31372202535867794, "kendall": 0.31372202535867794}, "p_value": {"pearson": 2.9660257446503184e-25, "spearman": 2.966025744650479e-25, "kendall": 4.195112188665433e-24}, "kappa_score": 0.2019792378391485, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.36057756568116306, "spearman": 0.360577565681163, "kendall": 0.360577565681163}, "p_value": {"pearson": 2.233240185597875e-33, "spearman": 2.2332401855977417e-33, "kendall": 2.596763935815836e-31}, "kappa_score": 0.2380194921269838, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.09690792210951744, "spearman": 0.0969079221095174, "kendall": 0.09690792210951737}, "p_value": {"pearson": 0.0017284376947217784, "spearman": 0.0017284376947217595, "kendall": 0.001758863652299364}, "kappa_score": 0.02248396716290746, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.14589484718780188, "spearman": 0.14589484718780188, "kendall": 0.14589484718780188}, "p_value": {"pearson": 2.2293683691925676e-06, "spearman": 2.2293683691925654e-06, "kendall": 2.483382708666848e-06}, "kappa_score": 0.041683369577171, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.2563493227913445, "spearman": 0.2563493227913445, "kendall": 0.2563493227913445}, "p_value": {"pearson": 4.102689095650869e-17, "spearman": 4.102689095650775e-17, "kendall": 1.2849606102771025e-16}, "kappa_score": 0.13481401841218432, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.13694849323109082, "spearman": 0.1369484932310908, "kendall": 0.1369484932310908}, "p_value": {"pearson": 9.061101071203697e-06, "spearman": 9.061101071203937e-06, "kendall": 9.838133656099265e-06}, "kappa_score": 0.036819238829822964, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.20606312794561732, "spearman": 0.20606312794561724, "kendall": 0.2060631279456172}, "p_value": {"pearson": 1.8276129751936708e-11, "spearman": 1.8276129751937435e-11, "kendall": 2.8968176017176378e-11}, "kappa_score": 0.08146486333599035, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.03975216859489431, "spearman": 0.03975216859489429, "kendall": 0.0397521685948943}, "p_value": {"pearson": 0.19956770189571763, "spearman": 0.19956770189571188, "kendall": 0.19942167014218326}, "kappa_score": 0.0031554834109562835, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.05781743728553917, "spearman": 0.05781743728553915, "kendall": 0.05781743728553915}, "p_value": {"pearson": 0.06196219755857521, "spearman": 0.06196219755857471, "kendall": 0.06199265014554824}, "kappa_score": 0.008623315125555142, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.02152069996461734, "spearman": 0.021520699964617338, "kendall": 0.02152069996461734}, "p_value": {"pearson": 0.4875135433025898, "spearman": 0.4875135433026049, "kendall": 0.487250393465395}, "kappa_score": 0.0009258522542331393, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.06095252860785708, "spearman": 0.06095252860785714, "kendall": 0.060952528607857145}, "p_value": {"pearson": 0.04907234854260267, "spearman": 0.04907234854260281, "kendall": 0.04911993727233802}, "kappa_score": 0.020441155338410844, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.20169462944831673, "spearman": 0.20169462944831668, "kendall": 0.20169462944831668}, "p_value": {"pearson": 4.90826495885406e-11, "spearman": 4.9082649588542345e-11, "kendall": 7.479759835081426e-11}, "kappa_score": 0.09402426902885974, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.3720987798344009, "spearman": 0.37209877983440076, "kendall": 0.3720987798344007}, "p_value": {"pearson": 1.3533922528865316e-35, "spearman": 1.3533922528865795e-35, "kendall": 3.0971749347107415e-33}, "kappa_score": 0.2605368668100919, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.2477429185096977, "spearman": 0.24774291850969776, "kendall": 0.24774291850969776}, "p_value": {"pearson": 4.728592740095764e-16, "spearman": 4.728592740096053e-16, "kendall": 1.2733461603087684e-15}, "kappa_score": 0.11903600462371566, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.18489614134439206, "spearman": 0.18489614134439208, "kendall": 0.1848961413443921}, "p_value": {"pearson": 1.7867052066255271e-09, "spearman": 1.7867052066255453e-09, "kendall": 2.3951504796932798e-09}, "kappa_score": 0.07161027473231008, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.17184548009467338, "spearman": 0.17184548009467324, "kendall": 0.17184548009467324}, "p_value": {"pearson": 2.339995115708966e-08, "spearman": 2.339995115709068e-08, "kendall": 2.9031987559620332e-08}, "kappa_score": 0.1661744131820302, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.2613615687560185, "spearman": 0.2613615687560186, "kendall": 0.26136156875601857}, "p_value": {"pearson": 9.46622663980221e-18, "spearman": 9.466226639802532e-18, "kendall": 3.2626124438850834e-17}, "kappa_score": 0.13071121102581462, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.3440927882456383, "spearman": 0.3440927882456383, "kendall": 0.3440927882456383}, "p_value": {"pearson": 2.3296205992669364e-30, "spearman": 2.329620599267e-30, "kendall": 1.1557145710560175e-28}, "kappa_score": 0.21878282540875027, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.3098965573298245, "spearman": 0.30989655732982435, "kendall": 0.3098965573298244}, "p_value": {"pearson": 1.1878336892277631e-24, "spearman": 1.187833689227747e-24, "kendall": 1.471507610730913e-23}, "kappa_score": 0.19223335406055186, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.14414055479325413, "spearman": 0.14414055479325413, "kendall": 0.14414055479325413}, "p_value": {"pearson": 2.954778392081008e-06, "spearman": 2.954778392080909e-06, "kendall": 3.273614375485345e-06}, "kappa_score": 0.04070724501504319, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.06639578304251922, "spearman": 0.06639578304251928, "kendall": 0.06639578304251927}, "p_value": {"pearson": 0.032026424036141116, "spearman": 0.0320264240361417, "kendall": 0.03209242567357609}, "kappa_score": 0.008778102623999584, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.19583401916941257, "spearman": 0.1958340191694125, "kendall": 0.19583401916941254}, "p_value": {"pearson": 1.7843691420901802e-10, "spearman": 1.784369142090216e-10, "kendall": 2.58991125759563e-10}, "kappa_score": 0.07386897961913919, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.07006107744155371, "spearman": 0.07006107744155372, "kendall": 0.07006107744155371}, "p_value": {"pearson": 0.023652589029790276, "spearman": 0.0236525890297898, "kendall": 0.023723778191477887}, "kappa_score": 0.009769156705727644, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.0763459789218105, "spearman": 0.0763459789218105, "kendall": 0.07634597892181053}, "p_value": {"pearson": 0.013652609973160644, "spearman": 0.013652609973161109, "kendall": 0.01372236726065024}, "kappa_score": 0.013770027181998379, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.041434840752961444, "spearman": 0.04143484075296144, "kendall": 0.04143484075296144}, "p_value": {"pearson": 0.1811805465724217, "spearman": 0.18118054657242275, "kendall": 0.18105371304321272}, "kappa_score": 0.003427807039545261, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.12562264030445092, "spearman": 0.125622640304451, "kendall": 0.12562264030445103}, "p_value": {"pearson": 4.7355610809785255e-05, "spearman": 4.735561080978499e-05, "kendall": 5.011244292452319e-05}, "kappa_score": 0.03922608460588828, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.4279481580186644, "spearman": 0.4279481580186646, "kendall": 0.4279481580186646}, "p_value": {"pearson": 1.0785154371982731e-47, "spearman": 1.0785154371981309e-47, "kendall": 2.093325279500568e-43}, "kappa_score": 0.30958243969603105, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8551537130214091, "spearman": 0.8551537130214087, "kendall": 0.8551537130214087}, "p_value": {"pearson": 2.5405965853841867e-299, "spearman": 2.54059658538718e-299, "kendall": 9.857571809577374e-168}, "kappa_score": 0.8533349999218787, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.4294047209955961, "spearman": 0.4294047209955961, "kendall": 0.42940472099559607}, "p_value": {"pearson": 4.8475619110791656e-48, "spearman": 4.847561911079099e-48, "kendall": 1.088468688495102e-43}, "kappa_score": 0.3503785606125539, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.09473319676596931, "spearman": 0.09473319676596927, "kendall": 0.09473319676596927}, "p_value": {"pearson": 0.002193657414578944, "spearman": 0.00219365741457887, "kendall": 0.0022282705686924166}, "kappa_score": 0.0177891109231606, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.12404644315907358, "spearman": 0.1240464431590735, "kendall": 0.12404644315907351}, "p_value": {"pearson": 5.897801372764858e-05, "spearman": 5.897801372764574e-05, "kendall": 6.222184503459837e-05}, "kappa_score": 0.030308664931201212, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.0647012478153255, "spearman": 0.0647012478153255, "kendall": 0.0647012478153255}, "p_value": {"pearson": 0.03668580435175034, "spearman": 0.03668580435174928, "kendall": 0.03674753979545368}, "kappa_score": 0.008337599648943206, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.09052561664615932, "spearman": 0.0905256166461593, "kendall": 0.09052561664615928}, "p_value": {"pearson": 0.003432683285241246, "spearman": 0.0034326832852412913, "kendall": 0.0034760270641785497}, "kappa_score": 0.01862456388076783, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.019501031033470322, "spearman": 0.01950103103347032, "kendall": 0.019501031033470322}, "p_value": {"pearson": 0.5292833487366779, "spearman": 0.5292833487366617, "kendall": 0.5290258493271016}, "kappa_score": 0.0007602912914008719, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.03899870388465929, "spearman": 0.038998703884659286, "kendall": 0.03899870388465928}, "p_value": {"pearson": 0.20822851091679914, "spearman": 0.20822851091679412, "kendall": 0.20807399382747094}, "kappa_score": 0.007828733542003419, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.01901907888740571, "spearman": 0.019019078887405713, "kendall": 0.019019078887405713}, "p_value": {"pearson": 0.5395128544181669, "spearman": 0.5395128544181671, "kendall": 0.5392573966025913}, "kappa_score": 0.000723189127601831, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.03318471034524196, "spearman": 0.033184710345241945, "kendall": 0.03318471034524196}, "p_value": {"pearson": 0.2842922289643027, "spearman": 0.28429222896431383, "kendall": 0.2840780405575747}, "kappa_score": 0.0022000272763561535, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.011782931197481836, "spearman": 0.011782931197481843, "kendall": 0.011782931197481843}, "p_value": {"pearson": 0.7038766326360996, "spearman": 0.7038766326360973, "kendall": 0.7036831672114928}, "kappa_score": 0.0002776363888760125, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.23870659999964333, "spearman": 0.23870659999964322, "kendall": 0.23870659999964325}, "p_value": {"pearson": 5.578752963489104e-15, "spearman": 5.57875296348932e-15, "kendall": 1.3037795121669622e-14}, "kappa_score": 0.13457989616184418, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.10177755587865603, "spearman": 0.10177755587865604, "kendall": 0.10177755587865606}, "p_value": {"pearson": 0.0009963077730037566, "spearman": 0.0009963077730037234, "kendall": 0.0010184418188236262}, "kappa_score": 0.025015432831568596, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.05819374380544266, "spearman": 0.05819374380544266, "kendall": 0.05819374380544266}, "p_value": {"pearson": 0.060280642431289715, "spearman": 0.06028064243129043, "kendall": 0.06031341314563588}, "kappa_score": 0.006750164125601477, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.019391673324565435, "spearman": 0.019391673324565428, "kendall": 0.019391673324565425}, "p_value": {"pearson": 0.5315958138008868, "spearman": 0.5315958138008707, "kendall": 0.5313387541361829}, "kappa_score": 0.0007517912873171717, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.058723743385871725, "spearman": 0.058723743385871746, "kendall": 0.05872374338587175}, "p_value": {"pearson": 0.05797652773204186, "spearman": 0.057976527732044196, "kendall": 0.058012442264140526}, "kappa_score": 0.009966777408637939, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.07723389359647798, "spearman": 0.07723389359647796, "kendall": 0.07723389359647796}, "p_value": {"pearson": 0.012594129762063169, "spearman": 0.01259412976206397, "kendall": 0.01266288964748618}, "kappa_score": 0.01185940639957872, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.03643143172072954, "spearman": 0.036431431720729573, "kendall": 0.03643143172072957}, "p_value": {"pearson": 0.23977431719687836, "spearman": 0.239774317196872, "kendall": 0.2395918715108406}, "kappa_score": 0.00265097992341623, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.44704804866888626, "spearman": 0.4470480486688863, "kendall": 0.4470480486688862}, "p_value": {"pearson": 2.194170354144678e-52, "spearman": 2.1941703541447644e-52, "kendall": 3.3159126363764036e-47}, "kappa_score": 0.3485269168617747, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.2060014833749859, "spearman": 0.20600148337498594, "kendall": 0.20600148337498592}, "p_value": {"pearson": 1.8535547957197165e-11, "spearman": 1.8535547957196803e-11, "kendall": 2.9362520310210084e-11}, "kappa_score": 0.08141811348273631, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.22217535190958565, "spearman": 0.22217535190958562, "kendall": 0.22217535190958562}, "p_value": {"pearson": 3.941469219544169e-13, "spearman": 3.9414692195439705e-13, "kendall": 7.40040370435856e-13}, "kappa_score": 0.154667600689113, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.12178535131537327, "spearman": 0.12178535131537326, "kendall": 0.12178535131537328}, "p_value": {"pearson": 8.04386643870434e-05, "spearman": 8.043866438704002e-05, "kendall": 8.451091016909289e-05}, "kappa_score": 0.03972756395875776, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.3486121361816529, "spearman": 0.3486121361816531, "kendall": 0.3486121361816531}, "p_value": {"pearson": 3.6105179975020033e-31, "spearman": 3.610517997501429e-31, "kendall": 2.2331806740242223e-29}, "kappa_score": 0.3485999791818466, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.2721712757257413, "spearman": 0.27217127572574135, "kendall": 0.27217127572574135}, "p_value": {"pearson": 3.592376983700341e-19, "spearman": 3.592376983700362e-19, "kendall": 1.5539999137253991e-18}, "kappa_score": 0.18564963829312597, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.2335441664441405, "spearman": 0.23354416644414056, "kendall": 0.23354416644414053}, "p_value": {"pearson": 2.1846278599275476e-14, "spearman": 2.184627859927526e-14, "kendall": 4.742740031970897e-14}, "kappa_score": 0.12380255545167529, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.49321638557579583, "spearman": 0.4932163855757952, "kendall": 0.49321638557579517}, "p_value": {"pearson": 4.895778577878785e-65, "spearman": 4.895778577880777e-65, "kendall": 4.528083303983473e-57}, "kappa_score": 0.41243850227212986, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.060712284241625517, "spearman": 0.06071228424162551, "kendall": 0.060712284241625517}, "p_value": {"pearson": 0.0499734183245937, "spearman": 0.049973418324593614, "kendall": 0.05001986815423529}, "kappa_score": 0.009192646778764968, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.1575049101968477, "spearman": 0.15750491019684773, "kendall": 0.15750491019684773}, "p_value": {"pearson": 3.178477346327054e-07, "spearman": 3.178477346327026e-07, "kendall": 3.6905742572987275e-07}, "kappa_score": 0.04841453551607766, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.10003064514683555, "spearman": 0.10003064514683548, "kendall": 0.10003064514683548}, "p_value": {"pearson": 0.0012173511403448358, "spearman": 0.0012173511403448761, "kendall": 0.001242274982642996}, "kappa_score": 0.021927493730164782, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.30214037992173737, "spearman": 0.30214037992173737, "kendall": 0.3021403799217374}, "p_value": {"pearson": 1.8600293694923066e-23, "spearman": 1.8600293694924024e-23, "kendall": 1.7892137387345017e-22}, "kappa_score": 0.2800861345666613, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.553254371809657, "spearman": 0.5532543718096569, "kendall": 0.5532543718096569}, "p_value": {"pearson": 1.1153314830771832e-84, "spearman": 1.1153314830773e-84, "kendall": 2.4572173566533078e-71}, "kappa_score": 0.5527838681916184, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.1313912104904226, "spearman": 0.1313912104904226, "kendall": 0.1313912104904226}, "p_value": {"pearson": 2.0744380747570784e-05, "spearman": 2.0744380747571753e-05, "kendall": 2.2221744400693674e-05}, "kappa_score": 0.04563917157650421, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.17688498817416598, "spearman": 0.1768849881741659, "kendall": 0.17688498817416587}, "p_value": {"pearson": 8.863949030309922e-09, "spearman": 8.863949030309853e-09, "kendall": 1.1307459178206051e-08}, "kappa_score": 0.08601280754971341, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.11024536619399675, "spearman": 0.11024536619399679, "kendall": 0.11024536619399679}, "p_value": {"pearson": 0.00036103775934195746, "spearman": 0.00036103775934195464, "kendall": 0.00037266208856521306}, "kappa_score": 0.028854276549172497, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.3940878384930948, "spearman": 0.394087838493095, "kendall": 0.3940878384930949}, "p_value": {"pearson": 4.390676923733803e-40, "spearman": 4.390676923733424e-40, "kendall": 4.510830437495701e-37}, "kappa_score": 0.29132850332219684, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.17270301596191998, "spearman": 0.17270301596192, "kendall": 0.17270301596192}, "p_value": {"pearson": 1.987662472038135e-08, "spearman": 1.987662472038164e-08, "kendall": 2.4773237394810778e-08}, "kappa_score": 0.05792497395645324, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.4058653303192531, "spearman": 0.4058653303192532, "kendall": 0.40586533031925315}, "p_value": {"pearson": 1.2429024594873861e-42, "spearman": 1.2429024594873354e-42, "kendall": 3.234828478149164e-39}, "kappa_score": 0.30450066270961795, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.446040807097508, "spearman": 0.44604080709750793, "kendall": 0.44604080709750793}, "p_value": {"pearson": 3.946681698348462e-52, "spearman": 3.9466816983485635e-52, "kendall": 5.310235114576597e-47}, "kappa_score": 0.3660811429343218, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.22487203456158636, "spearman": 0.2248720345615863, "kendall": 0.22487203456158633}, "p_value": {"pearson": 2.0126002372756696e-13, "spearman": 2.0126002372757933e-13, "kendall": 3.903234001071264e-13}, "kappa_score": 0.12092037866394922, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.46084361308573774, "spearman": 0.4608436130857378, "kendall": 0.4608436130857378}, "p_value": {"pearson": 5.778233848823743e-56, "spearman": 5.778233848824219e-56, "kendall": 4.715763948509019e-50}, "kappa_score": 0.3768533678732846, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.47158266140334093, "spearman": 0.47158266140334115, "kendall": 0.47158266140334104}, "p_value": {"pearson": 7.237435231518503e-59, "spearman": 7.2374352315182435e-59, "kendall": 2.4999691232038677e-52}, "kappa_score": 0.3942174114905277, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.27776704128328894, "spearman": 0.27776704128328905, "kendall": 0.27776704128328894}, "p_value": {"pearson": 6.22617059181945e-20, "spearman": 6.226170591819632e-20, "kendall": 3.065669419637909e-19}, "kappa_score": 0.14640390806345882, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.7535268778351669, "spearman": 0.7535268778351668, "kendall": 0.7535268778351668}, "p_value": {"pearson": 7.729883189097305e-192, "spearman": 7.72988318909931e-192, "kendall": 1.0962485414127692e-130}, "kappa_score": 0.7243293246993525, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.6551197549586083, "spearman": 0.6551197549586084, "kendall": 0.6551197549586084}, "p_value": {"pearson": 6.812581244419948e-129, "spearman": 6.812581244419511e-129, "kendall": 2.923060864107201e-99}, "kappa_score": 0.6210414638045547, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.373215018631585, "spearman": 0.37321501863158496, "kendall": 0.37321501863158496}, "p_value": {"pearson": 8.161114057334867e-36, "spearman": 8.161114057334943e-36, "kendall": 2.001886661589051e-33}, "kappa_score": 0.26238325537144225, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.10720605282191908, "spearman": 0.10720605282191904, "kendall": 0.10720605282191903}, "p_value": {"pearson": 0.00052410965828635, "spearman": 0.0005241096582863512, "kendall": 0.000538944901205231}, "kappa_score": 0.03664640529200136, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.20164704941201295, "spearman": 0.20164704941201297, "kendall": 0.201647049412013}, "p_value": {"pearson": 4.960759250435205e-11, "spearman": 4.9607592504350343e-11, "kendall": 7.556628469796236e-11}, "kappa_score": 0.09939556749496326, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.6833293269676797, "spearman": 0.6833293269676797, "kendall": 0.6833293269676797}, "p_value": {"pearson": 2.2151384223965636e-144, "spearman": 2.2151384223970333e-144, "kendall": 8.024350326099835e-108}, "kappa_score": 0.6812267332040665, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.6448913693723876, "spearman": 0.6448913693723872, "kendall": 0.6448913693723872}, "p_value": {"pearson": 1.11041144091057e-123, "spearman": 1.1104114409109876e-123, "kendall": 3.0291629906562837e-96}, "kappa_score": 0.6380985426786954, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.7691546732572936, "spearman": 0.7691546732572938, "kendall": 0.7691546732572939}, "p_value": {"pearson": 1.1954640725640671e-204, "spearman": 1.195464072563497e-204, "kendall": 4.433313914450276e-136}, "kappa_score": 0.7616862468820808, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.34106991579968327, "spearman": 0.34106991579968343, "kendall": 0.3410699157996835}, "p_value": {"pearson": 7.970730264002507e-30, "spearman": 7.970730264002537e-30, "kendall": 3.429717954453581e-28}, "kappa_score": 0.28611151513077393, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.5737685447289018, "spearman": 0.5737685447289018, "kendall": 0.5737685447289018}, "p_value": {"pearson": 2.353577265058378e-92, "spearman": 2.3535772650584948e-92, "kendall": 1.391348538220613e-76}, "kappa_score": 0.5431096681096681, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.7431103725309445, "spearman": 0.7431103725309443, "kendall": 0.7431103725309443}, "p_value": {"pearson": 8.024408061362973e-184, "spearman": 8.024408061366204e-184, "kendall": 3.744397424750572e-127}, "kappa_score": 0.7248892171344166, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.5813595847468978, "spearman": 0.5813595847468979, "kendall": 0.5813595847468979}, "p_value": {"pearson": 2.4638782954907497e-95, "spearman": 2.4638782954906223e-95, "kendall": 1.4246437482290255e-78}, "kappa_score": 0.5725646563659523, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.5516420939118112, "spearman": 0.5516420939118112, "kendall": 0.5516420939118113}, "p_value": {"pearson": 4.248491022916712e-84, "spearman": 4.248491022916697e-84, "kendall": 6.234132192842099e-71}, "kappa_score": 0.4747732960202351, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.33378247879642975, "spearman": 0.3337824787964294, "kendall": 0.33378247879642947}, "p_value": {"pearson": 1.4631462425869665e-28, "spearman": 1.4631462425872759e-28, "kendall": 4.5421033050954016e-27}, "kappa_score": 0.2699628643089068, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.2584180453389295, "spearman": 0.2584180453389296, "kendall": 0.2584180453389296}, "p_value": {"pearson": 2.24838471984578e-17, "spearman": 2.2483847198459526e-17, "kendall": 7.320470903696621e-17}, "kappa_score": 0.14442383169903705, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.39429348832999, "spearman": 0.39429348832998995, "kendall": 0.39429348832999}, "p_value": {"pearson": 3.971142220332888e-40, "spearman": 3.971142220332763e-40, "kendall": 4.1433135225207524e-37}, "kappa_score": 0.3395671445370746, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.19255795938346787, "spearman": 0.1925579593834678, "kendall": 0.1925579593834678}, "p_value": {"pearson": 3.60890791057012e-10, "spearman": 3.6089079105702746e-10, "kendall": 5.10717144337725e-10}, "kappa_score": 0.08947101581882588, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.2329532317268107, "spearman": 0.23295323172681062, "kendall": 0.2329532317268107}, "p_value": {"pearson": 2.5488386278067418e-14, "spearman": 2.5488386278070614e-14, "kendall": 5.48869193359522e-14}, "kappa_score": 0.11433818199391088, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.19553388160802568, "spearman": 0.19553388160802565, "kendall": 0.19553388160802568}, "p_value": {"pearson": 1.9042806512820643e-10, "spearman": 1.9042806512819146e-10, "kendall": 2.757398194165026e-10}, "kappa_score": 0.08046936562302509, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.2747383858263943, "spearman": 0.2747383858263942, "kendall": 0.27473838582639426}, "p_value": {"pearson": 1.615784359567509e-19, "spearman": 1.6157843595675434e-19, "kendall": 7.409657124266703e-19}, "kappa_score": 0.18315402010788173, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.6598898903468472, "spearman": 0.6598898903468473, "kendall": 0.6598898903468474}, "p_value": {"pearson": 2.1494987915655004e-131, "spearman": 2.1494987915650192e-131, "kendall": 1.1050361463399611e-100}, "kappa_score": 0.6067132279087151, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.934414453639, "spearman": 0.9344144536390003, "kendall": 0.9344144536390003}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 7.261557358076206e-200}, "kappa_score": 0.9336096943849905, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.46454742987179554, "spearman": 0.4645474298717957, "kendall": 0.46454742987179565}, "p_value": {"pearson": 5.922507593116418e-57, "spearman": 5.922507593115932e-57, "kendall": 7.844752415310867e-51}, "kappa_score": 0.3597298956414978, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.20638503466240682, "spearman": 0.20638503466240665, "kendall": 0.20638503466240668}, "p_value": {"pearson": 1.697806875097911e-11, "spearman": 1.6978068750979903e-11, "kendall": 2.69916459347132e-11}, "kappa_score": 0.08636811278702128, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.3135021688089457, "spearman": 0.3135021688089457, "kendall": 0.31350216880894577}, "p_value": {"pearson": 3.21400215036373e-25, "spearman": 3.214002150363736e-25, "kendall": 4.510705769647726e-24}, "kappa_score": 0.2308387533199151, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.16772967487851345, "spearman": 0.16772967487851342, "kendall": 0.16772967487851342}, "p_value": {"pearson": 5.0634654723674654e-08, "spearman": 5.063465472367446e-08, "kendall": 6.152272256673802e-08}, "kappa_score": 0.06405297521428355, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.2766069599326316, "spearman": 0.2766069599326315, "kendall": 0.2766069599326315}, "p_value": {"pearson": 8.984052601795957e-20, "spearman": 8.984052601796382e-20, "kendall": 4.3034522844676603e-19}, "kappa_score": 0.15504350875213113, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.17812878189322554, "spearman": 0.17812878189322548, "kendall": 0.1781287818932255}, "p_value": {"pearson": 6.945183129725543e-09, "spearman": 6.9451831297257825e-09, "kendall": 8.924266042092146e-09}, "kappa_score": 0.06504083767623559, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.126262706096162, "spearman": 0.12626270609616203, "kendall": 0.12626270609616205}, "p_value": {"pearson": 4.3285530500214046e-05, "spearman": 4.3285530500214256e-05, "kendall": 4.586365716001495e-05}, "kappa_score": 0.03645842527376175, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.06892028200701114, "spearman": 0.06892028200701113, "kendall": 0.06892028200701113}, "p_value": {"pearson": 0.026028004848239555, "spearman": 0.026028004848238855, "kendall": 0.026098132372350123}, "kappa_score": 0.009455098774824866, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.1759053542084851, "spearman": 0.17590535420848505, "kendall": 0.17590535420848505}, "p_value": {"pearson": 1.0728573236450358e-08, "spearman": 1.0728573236450891e-08, "kendall": 1.3609628291881189e-08}, "kappa_score": 0.06779937844520578, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.10740181041454351, "spearman": 0.10740181041454352, "kendall": 0.10740181041454351}, "p_value": {"pearson": 0.0005118227147621896, "spearman": 0.00051182271476219, "kendall": 0.0005264328910096676}, "kappa_score": 0.022807213161282425, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.3326743370115177, "spearman": 0.3326743370115177, "kendall": 0.3326743370115177}, "p_value": {"pearson": 2.2620693575169597e-28, "spearman": 2.26206935751682e-28, "kendall": 6.6954885048694e-27}, "kappa_score": 0.24176224866283957, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.25775525517524, "spearman": 0.25775525517524006, "kendall": 0.25775525517524006}, "p_value": {"pearson": 2.7277821793531925e-17, "spearman": 2.7277821793532172e-17, "kendall": 8.770688218480268e-17}, "kappa_score": 0.12459755897920954, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.10270211188410899, "spearman": 0.10270211188410908, "kendall": 0.10270211188410906}, "p_value": {"pearson": 0.0008949438765834333, "spearman": 0.0008949438765834198, "kendall": 0.0009156882598778719}, "kappa_score": 0.03050934256540838, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.15579618115692773, "spearman": 0.15579618115692773, "kendall": 0.15579618115692775}, "p_value": {"pearson": 4.272691972738909e-07, "spearman": 4.272691972739002e-07, "kendall": 4.927755631550843e-07}, "kappa_score": 0.05035220163762255, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.159900626227654, "spearman": 0.1599006262276539, "kendall": 0.15990062622765394}, "p_value": {"pearson": 2.0881206327687802e-07, "spearman": 2.0881206327688988e-07, "kendall": 2.448530366324336e-07}, "kappa_score": 0.052520716173519055, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.19475361999627627, "spearman": 0.19475361999627624, "kendall": 0.19475361999627624}, "p_value": {"pearson": 2.2539927344879458e-10, "spearman": 2.253992734487904e-10, "kendall": 3.243860713983252e-10}, "kappa_score": 0.07308587293836921, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.14546094769835605, "spearman": 0.14546094769835607, "kendall": 0.14546094769835607}, "p_value": {"pearson": 2.390974539922058e-06, "spearman": 2.3909745399221183e-06, "kendall": 2.6597749358718364e-06}, "kappa_score": 0.0414409306295892, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.7171787638426617, "spearman": 0.7171787638426617, "kendall": 0.7171787638426615}, "p_value": {"pearson": 1.8645220629117823e-165, "spearman": 1.8645220629119438e-165, "kendall": 1.4353824214729006e-118}, "kappa_score": 0.6829323215150253, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.27167386274698774, "spearman": 0.2716738627469877, "kendall": 0.2716738627469876}, "p_value": {"pearson": 4.1897642994888248e-19, "spearman": 4.1897642994887193e-19, "kendall": 1.79239984783016e-18}, "kappa_score": 0.137467364555096, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.5762320660922347, "spearman": 0.5762320660922347, "kendall": 0.5762320660922348}, "p_value": {"pearson": 2.589065937482062e-93, "spearman": 2.5890659374820906e-93, "kendall": 3.166348597883432e-77}, "kappa_score": 0.5356188780053428, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.2365344982905204, "spearman": 0.23653449829052034, "kendall": 0.23653449829052037}, "p_value": {"pearson": 9.946987474471796e-15, "spearman": 9.946987474471566e-15, "kendall": 2.2522618632616568e-14}, "kappa_score": 0.10596835969162477, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.5434758387979881, "spearman": 0.5434758387979881, "kendall": 0.5434758387979882}, "p_value": {"pearson": 3.3265773522003046e-81, "spearman": 3.3265773522007264e-81, "kendall": 6.679204421563703e-69}, "kappa_score": 0.5434758387979881, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.5740967421415639, "spearman": 0.5740967421415644, "kendall": 0.5740967421415645}, "p_value": {"pearson": 1.7558699956598652e-92, "spearman": 1.7558699956592034e-92, "kendall": 1.1427417625676888e-76}, "kappa_score": 0.5500607866975176, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.3959158565100884, "spearman": 0.39591585651008815, "kendall": 0.395915856510088}, "p_value": {"pearson": 1.79368349687671e-40, "spearman": 1.7936834968768841e-40, "kendall": 2.115965457815662e-37}, "kappa_score": 0.30441841195847674, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.7231074354030458, "spearman": 0.7231074354030455, "kendall": 0.7231074354030453}, "p_value": {"pearson": 1.8077501608796248e-169, "spearman": 1.807750160880513e-169, "kendall": 1.6646059635216048e-120}, "kappa_score": 0.7199498791730063, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.18449088684263976, "spearman": 0.18449088684263978, "kendall": 0.18449088684263978}, "p_value": {"pearson": 1.940850963170493e-09, "spearman": 1.940850963170487e-09, "kendall": 2.594834602978117e-09}, "kappa_score": 0.07718191719362133, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.290572965930218, "spearman": 0.29057296593021786, "kendall": 0.2905729659302179}, "p_value": {"pearson": 9.666102341499065e-22, "spearman": 9.66610234149933e-22, "kendall": 6.6159109913636106e-21}, "kappa_score": 0.16676700369225006, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.2730656933876416, "spearman": 0.27306569338764153, "kendall": 0.27306569338764153}, "p_value": {"pearson": 2.7220942782995573e-19, "spearman": 2.7220942782995293e-19, "kendall": 1.2014813226785593e-18}, "kappa_score": 0.14909640765154064, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.019324629108148743, "spearman": 0.019324629108148746, "kendall": 0.019324629108148746}, "p_value": {"pearson": 0.5330160470132657, "spearman": 0.5330160470132681, "kendall": 0.5327592637655825}, "kappa_score": 0.006662762806430189, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.06194965362629289, "spearman": 0.061949653626292824, "kendall": 0.06194965362629282}, "p_value": {"pearson": 0.04547672927758363, "spearman": 0.04547672927758399, "kendall": 0.0455287403685249}, "kappa_score": 0.036295947417524954, "total_responses": 1043, "valid_responses": 971, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.01766831438077908, "spearman": 0.017668314380779034, "kendall": 0.01766831438077903}, "p_value": {"pearson": 0.5686997471389089, "spearman": 0.5686997471389093, "kendall": 0.5684514381752999}, "kappa_score": 0.0030051808874931307, "total_responses": 1043, "valid_responses": 855, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.0031180028735749276, "spearman": 0.0031180028735748964, "kendall": 0.003118002873574896}, "p_value": {"pearson": 0.9198862634087398, "spearman": 0.9198862634087422, "kendall": 0.9198289310594794}, "kappa_score": 0.0023555948947833194, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": -0.09845423070488486, "spearman": -0.09845423070488482, "kendall": -0.09845423070488483}, "p_value": {"pearson": 0.0014547890354470244, "spearman": 0.0014547890354469717, "kendall": 0.0014824105162624997}, "kappa_score": -0.026926966617511372, "total_responses": 1043, "valid_responses": 918, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.12379421500932597, "spearman": 0.12379421500932605, "kendall": 0.12379421500932605}, "p_value": {"pearson": 6.10715518608158e-05, "spearman": 6.107155186081244e-05, "kendall": 6.439988971778907e-05}, "kappa_score": 0.06879317332440027, "total_responses": 1043, "valid_responses": 725, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.05241438755075728, "spearman": 0.052414387550757245, "kendall": 0.05241438755075725}, "p_value": {"pearson": 0.09066835602732831, "spearman": 0.09066835602733081, "kendall": 0.09065784729135248}, "kappa_score": 0.012959022140084153, "total_responses": 1043, "valid_responses": 941, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.07897852113215094, "spearman": 0.07897852113215097, "kendall": 0.07897852113215098}, "p_value": {"pearson": 0.010723581771265076, "spearman": 0.010723581771265013, "kendall": 0.010789959687158136}, "kappa_score": 0.031242083931436126, "total_responses": 1043, "valid_responses": 696, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.07990484462757282, "spearman": 0.07990484462757282, "kendall": 0.07990484462757283}, "p_value": {"pearson": 0.00983428984692156, "spearman": 0.009834289846921742, "kendall": 0.009899206480254026}, "kappa_score": 0.03369545904510485, "total_responses": 1043, "valid_responses": 739, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.12398724745074781, "spearman": 0.12398724745074781, "kendall": 0.12398724745074782}, "p_value": {"pearson": 5.94631646708258e-05, "spearman": 5.946316467082413e-05, "kendall": 6.272665960387928e-05}, "kappa_score": 0.040094543115687054, "total_responses": 1043, "valid_responses": 954, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.1376410565240922, "spearman": 0.13764105652409223, "kendall": 0.13764105652409223}, "p_value": {"pearson": 8.153756277492303e-06, "spearman": 8.153756277492049e-06, "kendall": 8.868977484138482e-06}, "kappa_score": 0.06099418481306007, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.08391680066873478, "spearman": 0.08391680066873482, "kendall": 0.08391680066873482}, "p_value": {"pearson": 0.006694515039779708, "spearman": 0.006694515039779833, "kendall": 0.006751962342391334}, "kappa_score": 0.037964098786910094, "total_responses": 1043, "valid_responses": 942, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.01188527185787093, "spearman": 0.011885271857870904, "kendall": 0.011885271857870904}, "p_value": {"pearson": 0.7014275109934953, "spearman": 0.7014275109934999, "kendall": 0.7012327833197367}, "kappa_score": 0.0025719030282302935, "total_responses": 1043, "valid_responses": 977, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.23263809677467123, "spearman": 0.2326380967746712, "kendall": 0.23263809677467118}, "p_value": {"pearson": 2.766804398812528e-14, "spearman": 2.766804398812675e-14, "kendall": 5.932482392495004e-14}, "kappa_score": 0.11246804112495246, "total_responses": 1043, "valid_responses": 1015, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.023334772429564044, "spearman": 0.023334772429564048, "kendall": 0.023334772429564044}, "p_value": {"pearson": 0.45156576828148426, "spearman": 0.451565768281483, "kendall": 0.4513014815113813}, "kappa_score": 0.011022464134571974, "total_responses": 1043, "valid_responses": 929, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.12908079699092176, "spearman": 0.12908079699092173, "kendall": 0.12908079699092173}, "p_value": {"pearson": 2.8993004029192986e-05, "spearman": 2.899300402919232e-05, "kendall": 3.0899831937185296e-05}, "kappa_score": 0.06804631731214361, "total_responses": 1043, "valid_responses": 878, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": -0.0896322765975036, "spearman": -0.08963227659750353, "kendall": -0.08963227659750353}, "p_value": {"pearson": 0.0037665140831799862, "spearman": 0.0037665140831801987, "kendall": 0.0038117801354003622}, "kappa_score": -0.02953073731358824, "total_responses": 1043, "valid_responses": 1014, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": -0.013893264652117966, "spearman": -0.013893264652117935, "kendall": -0.013893264652117937}, "p_value": {"pearson": 0.6540278648884451, "spearman": 0.654027864888447, "kendall": 0.6538104772384108}, "kappa_score": -0.013749866419691559, "total_responses": 1043, "valid_responses": 1017, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.10688644288126686, "spearman": 0.10688644288126689, "kendall": 0.1068864428812669}, "p_value": {"pearson": 0.0005447618175912795, "spearman": 0.0005447618175912559, "kendall": 0.000559970078162301}, "kappa_score": 0.03523626849204475, "total_responses": 1043, "valid_responses": 861, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.12693688983887685, "spearman": 0.12693688983887685, "kendall": 0.12693688983887683}, "p_value": {"pearson": 3.9357963526736244e-05, "spearman": 3.935796352673578e-05, "kendall": 4.175893668106811e-05}, "kappa_score": 0.07934680406040728, "total_responses": 1043, "valid_responses": 990, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.054135611824326545, "spearman": 0.054135611824326496, "kendall": 0.0541356118243265}, "p_value": {"pearson": 0.08054678161336139, "spearman": 0.08054678161336185, "kendall": 0.08055083704964926}, "kappa_score": 0.020593958202484997, "total_responses": 1043, "valid_responses": 681, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.02173877808847429, "spearman": 0.021738778088474315, "kendall": 0.021738778088474322}, "p_value": {"pearson": 0.4831121049420669, "spearman": 0.48311210494205403, "kendall": 0.48284862350741087}, "kappa_score": 0.005308080463607423, "total_responses": 1043, "valid_responses": 866, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.10429871240183688, "spearman": 0.10429871240183687, "kendall": 0.10429871240183688}, "p_value": {"pearson": 0.0007420675219446475, "spearman": 0.0007420675219446625, "kendall": 0.0007605546370850295}, "kappa_score": 0.0768092311551487, "total_responses": 1043, "valid_responses": 659, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.1080886886246826, "spearman": 0.10808868862468254, "kendall": 0.10808868862468254}, "p_value": {"pearson": 0.000470799027787137, "spearman": 0.00047079902778713706, "kendall": 0.0004846397459168622}, "kappa_score": 0.043227340218340626, "total_responses": 1043, "valid_responses": 927, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.1185361783723016, "spearman": 0.11853617837230164, "kendall": 0.11853617837230164}, "p_value": {"pearson": 0.00012447988939780024, "spearman": 0.00012447988939779766, "kendall": 0.00013005692879147616}, "kappa_score": 0.05436365682318689, "total_responses": 1043, "valid_responses": 761, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.16299859669100658, "spearman": 0.16299859669100647, "kendall": 0.1629985966910065}, "p_value": {"pearson": 1.2016262675824048e-07, "spearman": 1.2016262675825006e-07, "kendall": 1.4280816130840138e-07}, "kappa_score": 0.06533202807295668, "total_responses": 1043, "valid_responses": 935, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.015138937725755981, "spearman": 0.015138937725755947, "kendall": 0.015138937725755947}, "p_value": {"pearson": 0.6252938556472135, "spearman": 0.6252938556472174, "kendall": 0.6250645231705443}, "kappa_score": 0.004799399769204737, "total_responses": 1043, "valid_responses": 697, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.018787920974520377, "spearman": 0.018787920974520374, "kendall": 0.018787920974520377}, "p_value": {"pearson": 0.544454057642123, "spearman": 0.5444540576421217, "kendall": 0.5441996741287611}, "kappa_score": 0.003236087001062149, "total_responses": 1043, "valid_responses": 1004, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.10978086285397205, "spearman": 0.10978086285397205, "kendall": 0.10978086285397205}, "p_value": {"pearson": 0.00038243387826608275, "spearman": 0.00038243387826609055, "kendall": 0.00039451057171194226}, "kappa_score": 0.03403242353840341, "total_responses": 1043, "valid_responses": 947, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.0165465667126384, "spearman": 0.01654656671263844, "kendall": 0.016546566712638437}, "p_value": {"pearson": 0.5934968170010214, "spearman": 0.5934968170010015, "kendall": 0.5932560341716765}, "kappa_score": 0.0032440865158614995, "total_responses": 1043, "valid_responses": 995, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": -0.026102123307327245, "spearman": -0.02610212330732727, "kendall": -0.02610212330732727}, "p_value": {"pearson": 0.399724126850819, "spearman": 0.39972412685082936, "kendall": 0.39946495408998606}, "kappa_score": -0.003785371717767383, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.05747494155869176, "spearman": 0.05747494155869179, "kendall": 0.057474941558691775}, "p_value": {"pearson": 0.06352618246862672, "spearman": 0.06352618246862754, "kendall": 0.06355446322851932}, "kappa_score": 0.00833973279298228, "total_responses": 1043, "valid_responses": 991, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.13895913567457263, "spearman": 0.13895913567457263, "kendall": 0.13895913567457263}, "p_value": {"pearson": 6.66095875004018e-06, "spearman": 6.660958750040334e-06, "kendall": 7.2707553589908566e-06}, "kappa_score": 0.07603881147669111, "total_responses": 1043, "valid_responses": 976, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.14644878736972344, "spearman": 0.14644878736972336, "kendall": 0.1464487873697234}, "p_value": {"pearson": 2.0382284907861385e-06, "spearman": 2.038228490786175e-06, "kendall": 2.2744604493384536e-06}, "kappa_score": 0.09549496528217616, "total_responses": 1043, "valid_responses": 998, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.3530173963478801, "spearman": 0.35301739634788, "kendall": 0.35301739634788}, "p_value": {"pearson": 5.694382417286752e-32, "spearman": 5.694382417287219e-32, "kendall": 4.407487602446874e-30}, "kappa_score": 0.35207833453692705, "total_responses": 1043, "valid_responses": 1000, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.023694052216746427, "spearman": 0.023694052216746433, "kendall": 0.023694052216746433}, "p_value": {"pearson": 0.4446281711622493, "spearman": 0.44462817116224806, "kendall": 0.4443640905074744}, "kappa_score": 0.01732952351532946, "total_responses": 1043, "valid_responses": 893, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.06920503377827632, "spearman": 0.06920503377827625, "kendall": 0.06920503377827625}, "p_value": {"pearson": 0.025416570707409984, "spearman": 0.025416570707409762, "kendall": 0.025487007669699975}, "kappa_score": 0.027773008031163227, "total_responses": 1043, "valid_responses": 816, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": -0.007955731714776365, "spearman": -0.007955731714776391, "kendall": -0.007955731714776391}, "p_value": {"pearson": 0.7974641192951184, "spearman": 0.7974641192951165, "kendall": 0.7973245105675326}, "kappa_score": -0.0008395021690561499, "total_responses": 1043, "valid_responses": 1019, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": -0.009204355012708228, "spearman": -0.00920435501270815, "kendall": -0.009204355012708148}, "p_value": {"pearson": 0.7665358462092221, "spearman": 0.7665358462092252, "kendall": 0.7663773326228323}, "kappa_score": -0.0007692449329057549, "total_responses": 1043, "valid_responses": 1007, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.06211837007232564, "spearman": 0.06211837007232562, "kendall": 0.06211837007232562}, "p_value": {"pearson": 0.04489082632682913, "spearman": 0.04489082632682857, "kendall": 0.04494353751474992}, "kappa_score": 0.020887115700539693, "total_responses": 1043, "valid_responses": 1001, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": -0.04120513948193841, "spearman": -0.04120513948193851, "kendall": -0.04120513948193851}, "p_value": {"pearson": 0.1836138290784633, "spearman": 0.18361382907845689, "kendall": 0.18348436238946486}, "kappa_score": -0.0031948818429172743, "total_responses": 1043, "valid_responses": 969, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.017828149556713385, "spearman": 0.017828149556713375, "kendall": 0.017828149556713375}, "p_value": {"pearson": 0.5652071137824789, "spearman": 0.5652071137824812, "kendall": 0.5649578494191706}, "kappa_score": 0.003955628603165451, "total_responses": 1043, "valid_responses": 775, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.0023496576398217006, "spearman": 0.002349657639821718, "kendall": 0.002349657639821718}, "p_value": {"pearson": 0.9395841800698869, "spearman": 0.9395841800698865, "kendall": 0.9395408177505615}, "kappa_score": 0.0007971103274498903, "total_responses": 1043, "valid_responses": 934, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.03598487239119633, "spearman": 0.035984872391196326, "kendall": 0.035984872391196326}, "p_value": {"pearson": 0.2455880919760152, "spearman": 0.24558809197601017, "kendall": 0.245401000501148}, "kappa_score": 0.006875629712463582, "total_responses": 1043, "valid_responses": 981, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.015684009661999846, "spearman": 0.015684009661999867, "kendall": 0.015684009661999867}, "p_value": {"pearson": 0.6128939743157024, "spearman": 0.6128939743157014, "kendall": 0.6126599462978588}, "kappa_score": 0.0017503621438919037, "total_responses": 1043, "valid_responses": 897, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.16875229131879863, "spearman": 0.16875229131879865, "kendall": 0.16875229131879863}, "p_value": {"pearson": 4.187117722764605e-08, "spearman": 4.1871177227644695e-08, "kendall": 5.1132078464482536e-08}, "kappa_score": 0.13300527998275935, "total_responses": 1043, "valid_responses": 1005, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.03801202458378619, "spearman": 0.03801202458378622, "kendall": 0.038012024583786226}, "p_value": {"pearson": 0.2199771164605313, "spearman": 0.2199771164605387, "kendall": 0.21981165542250702}, "kappa_score": 0.01691925790436366, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.011235033795809207, "spearman": 0.011235033795809195, "kendall": 0.011235033795809193}, "p_value": {"pearson": 0.717040065941728, "spearman": 0.7170400659417245, "kendall": 0.7168535273666767}, "kappa_score": 0.00117959795716982, "total_responses": 1043, "valid_responses": 992, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": -0.026999023771097332, "spearman": -0.026999023771097294, "kendall": -0.02699902377109729}, "p_value": {"pearson": 0.38372113854091217, "spearman": 0.3837211385408902, "kendall": 0.38346529318919276}, "kappa_score": -0.0033172241852381656, "total_responses": 1043, "valid_responses": 916, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.04526850124370967, "spearman": 0.045268501243709666, "kendall": 0.04526850124370966}, "p_value": {"pearson": 0.14402497960582392, "spearman": 0.14402497960582022, "kendall": 0.1439418142265913}, "kappa_score": 0.021277453153334625, "total_responses": 1043, "valid_responses": 1032, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.01521421207639929, "spearman": 0.015214212076399232, "kendall": 0.01521421207639923}, "p_value": {"pearson": 0.6235750122677535, "spearman": 0.623575012267759, "kendall": 0.6233450118566429}, "kappa_score": 0.007370778393735122, "total_responses": 1043, "valid_responses": 958, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": -0.01795473928516361, "spearman": -0.017954739285163532, "kendall": -0.017954739285163532}, "p_value": {"pearson": 0.5624482687623739, "spearman": 0.5624482687623729, "kendall": 0.5621982685279465}, "kappa_score": -0.003824091778202643, "total_responses": 1043, "valid_responses": 933, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.32463524064826643, "spearman": 0.3246352406482666, "kendall": 0.3246352406482665}, "p_value": {"pearson": 5.0595348987237795e-27, "spearman": 5.059534898723604e-27, "kendall": 1.076122323739498e-25}, "kappa_score": 0.3049068757191392, "total_responses": 1043, "valid_responses": 968, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.07654570272589716, "spearman": 0.07654570272589709, "kendall": 0.07654570272589707}, "p_value": {"pearson": 0.013407909478212783, "spearman": 0.013407909478213166, "kendall": 0.013477456251293261}, "kappa_score": 0.03426753885854894, "total_responses": 1043, "valid_responses": 975, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.1692871575274018, "spearman": 0.16928715752740175, "kendall": 0.16928715752740178}, "p_value": {"pearson": 3.789201608209241e-08, "spearman": 3.7892016082091864e-08, "kendall": 4.63968412483121e-08}, "kappa_score": 0.11278418393940515, "total_responses": 1043, "valid_responses": 895, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.08943502594486337, "spearman": 0.08943502594486331, "kendall": 0.08943502594486331}, "p_value": {"pearson": 0.003844084696880346, "spearman": 0.0038440846968804438, "kendall": 0.0038897767812592146}, "kappa_score": 0.023979043321572857, "total_responses": 1043, "valid_responses": 548, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.08543720157950377, "spearman": 0.08543720157950374, "kendall": 0.08543720157950375}, "p_value": {"pearson": 0.005762838343950495, "spearman": 0.005762838343950586, "kendall": 0.005817132464931477}, "kappa_score": 0.07984661169468199, "total_responses": 1043, "valid_responses": 818, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.0688190338994531, "spearman": 0.06881903389945311, "kendall": 0.06881903389945311}, "p_value": {"pearson": 0.026248449546417776, "spearman": 0.026248449546416693, "kendall": 0.026318459747535976}, "kappa_score": 0.039666245374844755, "total_responses": 1043, "valid_responses": 830, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.1344611563996267, "spearman": 0.1344611563996267, "kendall": 0.13446115639962666}, "p_value": {"pearson": 1.3180623996183186e-05, "spearman": 1.3180623996182522e-05, "kendall": 1.422174582441329e-05}, "kappa_score": 0.05615870771265241, "total_responses": 1043, "valid_responses": 898, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.139440999776847, "spearman": 0.13944099977684696, "kendall": 0.13944099977684696}, "p_value": {"pearson": 6.183452554585872e-06, "spearman": 6.183452554586105e-06, "kendall": 6.758394667207334e-06}, "kappa_score": 0.07000038164363498, "total_responses": 1043, "valid_responses": 837, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": -0.02270088966919607, "spearman": -0.022700889669196107, "kendall": -0.022700889669196107}, "p_value": {"pearson": 0.463953705758744, "spearman": 0.46395370575873174, "kendall": 0.4636893999421563}, "kappa_score": -0.007033270706781503, "total_responses": 1043, "valid_responses": 908, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.04740275071136957, "spearman": 0.047402750711369596, "kendall": 0.047402750711369596}, "p_value": {"pearson": 0.12603644090799707, "spearman": 0.126036440907996, "kendall": 0.12597664273364997}, "kappa_score": 0.011915060428279278, "total_responses": 1043, "valid_responses": 935, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.07570637537788868, "spearman": 0.07570637537788867, "kendall": 0.07570637537788867}, "p_value": {"pearson": 0.014462958439388695, "spearman": 0.014462958439388647, "kendall": 0.014533332839066174}, "kappa_score": 0.038638644088890284, "total_responses": 1043, "valid_responses": 655, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.1237982848605825, "spearman": 0.12379828486058253, "kendall": 0.12379828486058252}, "p_value": {"pearson": 6.103722057176583e-05, "spearman": 6.103722057176172e-05, "kendall": 6.436417983389376e-05}, "kappa_score": 0.08224098986728601, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.2152590607010919, "spearman": 0.2152590607010919, "kendall": 0.2152590607010919}, "p_value": {"pearson": 2.1240020748961834e-12, "spearman": 2.1240020748962957e-12, "kendall": 3.690131135239003e-12}, "kappa_score": 0.15766183449079163, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.04226532633965695, "spearman": 0.04226532633965695, "kendall": 0.04226532633965694}, "p_value": {"pearson": 0.17258235848625128, "spearman": 0.17258235848624487, "kendall": 0.1724650550893193}, "kappa_score": 0.017160144819719392, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.0731032108035407, "spearman": 0.07310321080354068, "kendall": 0.0731032108035407}, "p_value": {"pearson": 0.018214217438050243, "spearman": 0.018214217438049952, "kendall": 0.018286098154545422}, "kappa_score": 0.014534361635948567, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.004515932656316334, "spearman": 0.004515932656316304, "kendall": 0.004515932656316304}, "p_value": {"pearson": 0.8841817414733939, "spearman": 0.8841817414733902, "kendall": 0.884099471572234}, "kappa_score": 0.002510460251046065, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.12258333045181283, "spearman": 0.12258333045181281, "kendall": 0.12258333045181283}, "p_value": {"pearson": 7.213801030766071e-05, "spearman": 7.213801030765902e-05, "kendall": 7.589917151345746e-05}, "kappa_score": 0.038819246896424575, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.08375745768891311, "spearman": 0.08375745768891311, "kendall": 0.0837574576889131}, "p_value": {"pearson": 0.006799594761429868, "spearman": 0.006799594761429775, "kendall": 0.006857365137116829}, "kappa_score": 0.01393287994109682, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.12684302547151052, "spearman": 0.12684302547151052, "kendall": 0.12684302547151052}, "p_value": {"pearson": 3.9883793350330815e-05, "spearman": 3.988379335033292e-05, "kendall": 4.2308770699111194e-05}, "kappa_score": 0.03857730214624344, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.2848375808923068, "spearman": 0.2848375808923068, "kendall": 0.28483758089230676}, "p_value": {"pearson": 6.4130013923511966e-21, "spearman": 6.413001392350652e-21, "kendall": 3.765177983144525e-20}, "kappa_score": 0.16710797293321555, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.06180132706884707, "spearman": 0.061801327068847056, "kendall": 0.061801327068847056}, "p_value": {"pearson": 0.04599712714224301, "spearman": 0.045997127142241453, "kendall": 0.0460485112858886}, "kappa_score": 0.0076097433704640505, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.10610460457446577, "spearman": 0.10610460457446588, "kendall": 0.10610460457446586}, "p_value": {"pearson": 0.0005985152701970623, "spearman": 0.0005985152701970593, "kendall": 0.0006146653222733919}, "kappa_score": 0.033506888158754355, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.18106074077451245, "spearman": 0.18106074077451245, "kendall": 0.18106074077451245}, "p_value": {"pearson": 3.88123293754995e-09, "spearman": 3.881232937549789e-09, "kendall": 5.076490804195696e-09}, "kappa_score": 0.08295370286583292, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.062305986120666734, "spearman": 0.062305986120666755, "kendall": 0.06230598612066675}, "p_value": {"pearson": 0.04424676836073489, "spearman": 0.044246768360735905, "kendall": 0.044300241834713726}, "kappa_score": 0.010891754280986654, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.37100982243294955, "spearman": 0.37100982243294955, "kendall": 0.37100982243294955}, "p_value": {"pearson": 2.212585190392428e-35, "spearman": 2.2125851903926784e-35, "kendall": 4.735001743793445e-33}, "kappa_score": 0.2736540043043866, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.20260827071797924, "spearman": 0.20260827071797924, "kendall": 0.20260827071797924}, "p_value": {"pearson": 3.999359774623575e-11, "spearman": 3.9993597746237614e-11, "kendall": 6.143661832241257e-11}, "kappa_score": 0.11764417398554061, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.16963434441942998, "spearman": 0.1696343444194299, "kendall": 0.16963434441942993}, "p_value": {"pearson": 3.550781556170522e-08, "spearman": 3.550781556170538e-08, "kendall": 4.3553732174936287e-08}, "kappa_score": 0.09210203076031753, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.02887696483701117, "spearman": 0.028876964837011243, "kendall": 0.028876964837011243}, "p_value": {"pearson": 0.3515059016325235, "spearman": 0.3515059016325002, "kendall": 0.351259455236522}, "kappa_score": 0.005246132315716356, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.07481297773898625, "spearman": 0.0748129777389862, "kendall": 0.0748129777389862}, "p_value": {"pearson": 0.01566564941808424, "spearman": 0.015665649418084012, "kendall": 0.015736731468456264}, "kappa_score": 0.029710435864041096, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.23697438970988116, "spearman": 0.23697438970988113, "kendall": 0.23697438970988122}, "p_value": {"pearson": 8.851762333869369e-15, "spearman": 8.851762333869318e-15, "kendall": 2.0170082665973695e-14}, "kappa_score": 0.1366144561245406, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.13283569913989146, "spearman": 0.1328356991398914, "kendall": 0.1328356991398914}, "p_value": {"pearson": 1.6778807713745718e-05, "spearman": 1.6778807713746555e-05, "kendall": 1.803380628671011e-05}, "kappa_score": 0.13143650242886884, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.4520342311309795, "spearman": 0.45203423113097957, "kendall": 0.45203423113097957}, "p_value": {"pearson": 1.16532035034564e-53, "spearman": 1.1653203503457298e-53, "kendall": 3.173046566648681e-48}, "kappa_score": 0.4251059416209808, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.15895785215363958, "spearman": 0.15895785215363947, "kendall": 0.15895785215363947}, "p_value": {"pearson": 2.465380220221648e-07, "spearman": 2.4653802202218057e-07, "kendall": 2.8795678465823637e-07}, "kappa_score": 0.08289079347074335, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.46855338948470426, "spearman": 0.4685533894847039, "kendall": 0.46855338948470393}, "p_value": {"pearson": 4.8835601309880284e-58, "spearman": 4.883560130989349e-58, "kendall": 1.1094375639550101e-51}, "kappa_score": 0.445791431326629, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.30175399044311924, "spearman": 0.3017539904431191, "kendall": 0.30175399044311907}, "p_value": {"pearson": 2.128639005177273e-23, "spearman": 2.1286390051774613e-23, "kendall": 2.0230365607679727e-22}, "kappa_score": 0.2322503661116233, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.32266129899264, "spearman": 0.32266129899264, "kendall": 0.32266129899264}, "p_value": {"pearson": 1.0698865775519102e-26, "spearman": 1.0698865775520161e-26, "kendall": 2.106549437741912e-25}, "kappa_score": 0.20547482105187231, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.16790722035498146, "spearman": 0.1679072203549814, "kendall": 0.16790722035498143}, "p_value": {"pearson": 4.899531918483083e-08, "spearman": 4.899531918483092e-08, "kendall": 5.9582624010520306e-08}, "kappa_score": 0.05976342159172465, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.04565644837134999, "spearman": 0.04565644837134997, "kendall": 0.045656448371349974}, "p_value": {"pearson": 0.14061663899902926, "spearman": 0.14061663899902946, "kendall": 0.14053779553296702}, "kappa_score": 0.004160350258737289, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": -0.03376433575794567, "spearman": -0.03376433575794564, "kendall": -0.03376433575794565}, "p_value": {"pearson": 0.275960113826809, "spearman": 0.2759601138268102, "kendall": 0.27575120736820957}, "kappa_score": -0.004998253298578392, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.07469952453785977, "spearman": 0.07469952453785977, "kendall": 0.07469952453785976}, "p_value": {"pearson": 0.01582449987608493, "spearman": 0.01582449987608384, "kendall": 0.015895658217787656}, "kappa_score": 0.014544621639419386, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.0250122655211508, "spearman": 0.025012265521150785, "kendall": 0.025012265521150778}, "p_value": {"pearson": 0.4197001934381446, "spearman": 0.41970019343814813, "kendall": 0.4194380534440162}, "kappa_score": 0.0030724551376238862, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.0631584877943336, "spearman": 0.06315848779433357, "kendall": 0.06315848779433358}, "p_value": {"pearson": 0.04141750702246575, "spearman": 0.04141750702246455, "kendall": 0.041474230770379684}, "kappa_score": 0.013046195404286531, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.06443444832574893, "spearman": 0.0644344483257489, "kendall": 0.0644344483257489}, "p_value": {"pearson": 0.03746957655960053, "spearman": 0.037469576559600516, "kendall": 0.037530523860738615}, "kappa_score": 0.014153428083354958, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.08540970856009797, "spearman": 0.08540970856009794, "kendall": 0.08540970856009797}, "p_value": {"pearson": 0.005778592312412043, "spearman": 0.005778592312412109, "kendall": 0.005832944411553781}, "kappa_score": 0.01866945757085614, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.413418515818848, "spearman": 0.41341851581884786, "kendall": 0.41341851581884786}, "p_value": {"pearson": 2.544302882950932e-44, "spearman": 2.5443028829509964e-44, "kendall": 1.2639900476277694e-40}, "kappa_score": 0.3103724274250239, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.6674063773114507, "spearman": 0.667406377311451, "kendall": 0.667406377311451}, "p_value": {"pearson": 1.98141876613175e-135, "spearman": 1.9814187661310863e-135, "kendall": 6.040850239181202e-103}, "kappa_score": 0.6480061556737493, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.23897110722504722, "spearman": 0.2389711072250471, "kendall": 0.2389711072250471}, "p_value": {"pearson": 5.197351598767249e-15, "spearman": 5.197351598767401e-15, "kendall": 1.2194091311167219e-14}, "kappa_score": 0.18460141729503443, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.06754649279078326, "spearman": 0.06754649279078329, "kendall": 0.06754649279078327}, "p_value": {"pearson": 0.02915944264195593, "spearman": 0.02915944264195565, "kendall": 0.02922764186196243}, "kappa_score": 0.05220983064849227, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.1048640473606276, "spearman": 0.10486404736062757, "kendall": 0.1048640473606276}, "p_value": {"pearson": 0.0006940151275684714, "spearman": 0.0006940151275684433, "kendall": 0.0007117461191561583}, "kappa_score": 0.030574622692862596, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.1099623519583345, "spearman": 0.1099623519583345, "kendall": 0.10996235195833447}, "p_value": {"pearson": 0.000373936949727886, "spearman": 0.00037393694972788505, "kendall": 0.0003858352951266757}, "kappa_score": 0.042861650604886115, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.04106043273719521, "spearman": 0.04106043273719518, "kendall": 0.04106043273719518}, "p_value": {"pearson": 0.18515910437480268, "spearman": 0.18515910437480398, "kendall": 0.18502798012928567}, "kappa_score": 0.004893546622007361, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.060796617897226554, "spearman": 0.060796617897226575, "kendall": 0.06079661789722656}, "p_value": {"pearson": 0.049655548125448326, "spearman": 0.04965554812544942, "kendall": 0.0497024010111687}, "kappa_score": 0.0073652339061848204, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.08416297446025367, "spearman": 0.08416297446025363, "kendall": 0.08416297446025363}, "p_value": {"pearson": 0.006535038080460016, "spearman": 0.006535038080459797, "kendall": 0.006591983169236647}, "kappa_score": 0.03035159328156667, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.04620615883269162, "spearman": 0.046206158832691614, "kendall": 0.046206158832691614}, "p_value": {"pearson": 0.13589361064680416, "spearman": 0.1358936106468006, "kendall": 0.13582083940649314}, "kappa_score": 0.004260921122712591, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.08291888806350475, "spearman": 0.08291888806350477, "kendall": 0.08291888806350477}, "p_value": {"pearson": 0.007377367512559254, "spearman": 0.007377367512559665, "kendall": 0.007436809398064496}, "kappa_score": 0.01563477932597379, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.07046810217862784, "spearman": 0.07046810217862785, "kendall": 0.07046810217862784}, "p_value": {"pearson": 0.022851751143479933, "spearman": 0.02285175114347971, "kendall": 0.022923207068839144}, "kappa_score": 0.009882433123189593, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.11321592351100712, "spearman": 0.1132159235110071, "kendall": 0.1132159235110071}, "p_value": {"pearson": 0.0002485327487221437, "spearman": 0.0002485327487221303, "kendall": 0.00025757038622231513}, "kappa_score": 0.0293531310702706, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.1279774923110061, "spearman": 0.12797749231100614, "kendall": 0.12797749231100614}, "p_value": {"pearson": 3.3951981639318525e-05, "spearman": 3.395198163931954e-05, "kendall": 3.610053636486718e-05}, "kappa_score": 0.0424620364640359, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.03820488115650863, "spearman": 0.03820488115650861, "kendall": 0.0382048811565086}, "p_value": {"pearson": 0.21764416325942096, "spearman": 0.2176441632594134, "kendall": 0.2174808237460113}, "kappa_score": 0.007948530924461017, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": -0.009670060105403076, "spearman": -0.00967006010540307, "kendall": -0.00967006010540307}, "p_value": {"pearson": 0.7550919486816535, "spearman": 0.7550919486816547, "kendall": 0.7549266963198809}, "kappa_score": -0.0050267396855476765, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.05904827653465278, "spearman": 0.05904827653465284, "kendall": 0.05904827653465283}, "p_value": {"pearson": 0.056602079518566425, "spearman": 0.05660207951856735, "kendall": 0.05663984916606765}, "kappa_score": 0.012277727334817135, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.09080110667744216, "spearman": 0.0908011066774422, "kendall": 0.09080110667744219}, "p_value": {"pearson": 0.003335299757543791, "spearman": 0.003335299757543867, "kendall": 0.003378053831268976}, "kappa_score": 0.0399275484247722, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.06853791584272448, "spearman": 0.06853791584272438, "kendall": 0.0685379158427244}, "p_value": {"pearson": 0.026868986654400708, "spearman": 0.02686898665440145, "kendall": 0.026938650785298456}, "kappa_score": 0.018178641083165026, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.10371648771450805, "spearman": 0.10371648771450807, "kendall": 0.10371648771450806}, "p_value": {"pearson": 0.0007947665304173981, "spearman": 0.0007947665304173994, "kendall": 0.0008140558984277498}, "kappa_score": 0.03474762253108998, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.10368069765653037, "spearman": 0.10368069765653044, "kendall": 0.10368069765653044}, "p_value": {"pearson": 0.0007981165426683084, "spearman": 0.0007981165426683254, "kendall": 0.0008174560076240444}, "kappa_score": 0.02127072054356649, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.2146959006011226, "spearman": 0.21469590060112254, "kendall": 0.2146959006011226}, "p_value": {"pearson": 2.4301662480743035e-12, "spearman": 2.4301662480745447e-12, "kendall": 4.196849839429044e-12}, "kappa_score": 0.18652861454294722, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.050931473872999004, "spearman": 0.050931473872999046, "kendall": 0.050931473872999046}, "p_value": {"pearson": 0.10018600223533647, "spearman": 0.10018600223533514, "kendall": 0.10016190113945012}, "kappa_score": 0.005174607053276881, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.30069682831600386, "spearman": 0.30069682831600386, "kendall": 0.3006968283160039}, "p_value": {"pearson": 3.0756087580743164e-23, "spearman": 3.0756087580744e-23, "kendall": 2.828813388913009e-22}, "kappa_score": 0.28024399703818614, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.16944508983070622, "spearman": 0.169445089830706, "kendall": 0.16944508983070602}, "p_value": {"pearson": 3.678884456878933e-08, "spearman": 3.678884456879025e-08, "kendall": 4.508190811155582e-08}, "kappa_score": 0.1518026565464896, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.26292023922098795, "spearman": 0.2629202392209881, "kendall": 0.26292023922098806}, "p_value": {"pearson": 5.960838906479459e-18, "spearman": 5.960838906479219e-18, "kendall": 2.1190878133907513e-17}, "kappa_score": 0.1649319455564452, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.30351088575991364, "spearman": 0.3035108857599132, "kendall": 0.3035108857599132}, "p_value": {"pearson": 1.1508453941386008e-23, "spearman": 1.1508453941387496e-23, "kendall": 1.1559070243840965e-22}, "kappa_score": 0.2339598135248595, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.07290242154309731, "spearman": 0.07290242154309728, "kendall": 0.07290242154309728}, "p_value": {"pearson": 0.018536093935658932, "spearman": 0.018536093935658294, "kendall": 0.01860801649485326}, "kappa_score": 0.015907684133799505, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.10928502623952069, "spearman": 0.10928502623952076, "kendall": 0.10928502623952076}, "p_value": {"pearson": 0.00040657543860916055, "spearman": 0.0004065754386091601, "kendall": 0.000419149970339142}, "kappa_score": 0.027781795024798273, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.17020196025546241, "spearman": 0.17020196025546244, "kendall": 0.17020196025546241}, "p_value": {"pearson": 3.1919508998756234e-08, "spearman": 3.191950899875439e-08, "kendall": 3.9265565922228925e-08}, "kappa_score": 0.07774625332892382, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": -0.017182573060834865, "spearman": -0.01718257306083478, "kendall": -0.01718257306083478}, "p_value": {"pearson": 0.5793766507909585, "spearman": 0.579376650790959, "kendall": 0.5791314248216998}, "kappa_score": -0.01302143351002516, "total_responses": 1043, "valid_responses": 787, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.061884812541000214, "spearman": 0.06188481254099955, "kendall": 0.06188481254099954}, "p_value": {"pearson": 0.04570360891491628, "spearman": 0.045703608914918, "kendall": 0.04575534725639806}, "kappa_score": 0.05744196112191857, "total_responses": 1043, "valid_responses": 600, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.030793585750287636, "spearman": 0.0307935857502878, "kendall": 0.030793585750287792}, "p_value": {"pearson": 0.32044800694700587, "spearman": 0.32044800694700304, "kendall": 0.3202142449257843}, "kappa_score": 0.01239333826201916, "total_responses": 1043, "valid_responses": 317, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": -0.016100351683704144, "spearman": -0.016100351683704134, "kendall": -0.016100351683704134}, "p_value": {"pearson": 0.6034963109795523, "spearman": 0.6034963109795513, "kendall": 0.6032589184251322}, "kappa_score": -0.01065891472868219, "total_responses": 1043, "valid_responses": 881, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.04396167604114022, "spearman": 0.04396167604114084, "kendall": 0.043961676041140846}, "p_value": {"pearson": 0.155972435705308, "spearman": 0.15597243570530744, "kendall": 0.1558745303091336}, "kappa_score": 0.02203191416816297, "total_responses": 1043, "valid_responses": 835, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.1984237622079662, "spearman": 0.19842376220796573, "kendall": 0.19842376220796573}, "p_value": {"pearson": 1.0136706502008826e-10, "spearman": 1.0136706502009997e-10, "kendall": 1.5024725679342463e-10}, "kappa_score": 0.13430541055882939, "total_responses": 1043, "valid_responses": 881, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.10734486734310233, "spearman": 0.10734486734310214, "kendall": 0.10734486734310215}, "p_value": {"pearson": 0.000515368870836395, "spearman": 0.0005153688708364184, "kendall": 0.0005300442500541851}, "kappa_score": 0.04865308187284667, "total_responses": 1043, "valid_responses": 690, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.12356397112979452, "spearman": 0.12356397112979575, "kendall": 0.12356397112979575}, "p_value": {"pearson": 6.30437840860857e-05, "spearman": 6.304378408607577e-05, "kendall": 6.645092529313934e-05}, "kappa_score": 0.09085866429997791, "total_responses": 1043, "valid_responses": 921, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.24907742691225687, "spearman": 0.24907742691225276, "kendall": 0.2490774269122527}, "p_value": {"pearson": 3.2563872892152684e-16, "spearman": 3.256387289219009e-16, "kendall": 8.967328562887421e-16}, "kappa_score": 0.1931371757614897, "total_responses": 1043, "valid_responses": 821, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.13172002668862404, "spearman": 0.13172002668862387, "kendall": 0.1317200266886239}, "p_value": {"pearson": 1.9770160924758046e-05, "spearman": 1.9770160924758395e-05, "kendall": 2.1194015665610476e-05}, "kappa_score": 0.07947132714363747, "total_responses": 1043, "valid_responses": 784, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": -0.024740993993802564, "spearman": -0.024740993993802578, "kendall": -0.024740993993802578}, "p_value": {"pearson": 0.4247619344153857, "spearman": 0.4247619344153738, "kendall": 0.4244992451727805}, "kappa_score": -0.013145864142388719, "total_responses": 1043, "valid_responses": 867, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.16043242335358643, "spearman": 0.16043242335358554, "kendall": 0.16043242335358554}, "p_value": {"pearson": 1.900569400567256e-07, "spearman": 1.900569400567743e-07, "kendall": 2.2336249178566045e-07}, "kappa_score": 0.1429477633060794, "total_responses": 1043, "valid_responses": 765, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.07706993939712327, "spearman": 0.0770699393971234, "kendall": 0.07706993939712338}, "p_value": {"pearson": 0.012783936999611282, "spearman": 0.012783936999610352, "kendall": 0.012852892779170528}, "kappa_score": 0.05427565250225397, "total_responses": 1043, "valid_responses": 726, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.3542158995257027, "spearman": 0.3542158995257044, "kendall": 0.3542158995257044}, "p_value": {"pearson": 3.4277413541283126e-32, "spearman": 3.427741354126198e-32, "kendall": 2.8245666529254585e-30}, "kappa_score": 0.2714729916481403, "total_responses": 1043, "valid_responses": 753, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.05958125451013677, "spearman": 0.05958125451013753, "kendall": 0.05958125451013752}, "p_value": {"pearson": 0.054403644991317016, "spearman": 0.05440364499131485, "kendall": 0.0544443461461447}, "kappa_score": 0.0513279212569302, "total_responses": 1043, "valid_responses": 785, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.10199095286908201, "spearman": 0.10199095286908101, "kendall": 0.101990952869081}, "p_value": {"pearson": 0.0009720118517050828, "spearman": 0.0009720118517051568, "kendall": 0.0009938197824229578}, "kappa_score": 0.09455590863390984, "total_responses": 1043, "valid_responses": 784, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": -0.027751541411237236, "spearman": -0.027751541411236976, "kendall": -0.02775154141123698}, "p_value": {"pearson": 0.37060113156222224, "spearman": 0.3706011315622145, "kendall": 0.3703486689190666}, "kappa_score": -0.02510721944245886, "total_responses": 1043, "valid_responses": 915, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.051097304074516924, "spearman": 0.051097304074516334, "kendall": 0.05109730407451634}, "p_value": {"pearson": 0.09908369684126088, "spearman": 0.09908369684126139, "kendall": 0.09906116118556853}, "kappa_score": 0.017007868377001856, "total_responses": 1043, "valid_responses": 823, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.2748384061080525, "spearman": 0.2748384061080501, "kendall": 0.2748384061080501}, "p_value": {"pearson": 1.5659883203713561e-19, "spearman": 1.565988320372553e-19, "kendall": 7.1979058661421735e-19}, "kappa_score": 0.24052357435213845, "total_responses": 1043, "valid_responses": 803, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.053041930995397245, "spearman": 0.05304193099539693, "kendall": 0.05304193099539694}, "p_value": {"pearson": 0.08686580945987918, "spearman": 0.08686580945988409, "kendall": 0.08686076675197563}, "kappa_score": 0.02099081288521909, "total_responses": 1043, "valid_responses": 800, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.10089842722714572, "spearman": 0.10089842722714633, "kendall": 0.10089842722714633}, "p_value": {"pearson": 0.0011024381719072164, "spearman": 0.0011024381719071373, "kendall": 0.0011259495278355622}, "kappa_score": 0.08170901709506218, "total_responses": 1043, "valid_responses": 796, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.017233107644547756, "spearman": 0.01723310764454779, "kendall": 0.017233107644547795}, "p_value": {"pearson": 0.5782615020507025, "spearman": 0.5782615020507016, "kendall": 0.5780159427745171}, "kappa_score": 0.01387216113048706, "total_responses": 1043, "valid_responses": 845, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.03657786978343827, "spearman": 0.03657786978343828, "kendall": 0.036577869783438285}, "p_value": {"pearson": 0.2378891005756451, "spearman": 0.23788910057565213, "kendall": 0.2377081944370727}, "kappa_score": 0.024044440759472763, "total_responses": 1043, "valid_responses": 624, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.23320388890040059, "spearman": 0.23320388890039925, "kendall": 0.23320388890039925}, "p_value": {"pearson": 2.387592644898761e-14, "spearman": 2.387592644899578e-14, "kendall": 5.159155945971957e-14}, "kappa_score": 0.18817286795537413, "total_responses": 1043, "valid_responses": 747, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.03434510639213031, "spearman": 0.03434510639213055, "kendall": 0.03434510639213055}, "p_value": {"pearson": 0.2677799320139978, "spearman": 0.26777993201399286, "kendall": 0.2675765016807442}, "kappa_score": 0.030688643833907903, "total_responses": 1043, "valid_responses": 807, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.24635712410622213, "spearman": 0.2463571241062217, "kendall": 0.2463571241062217}, "p_value": {"pearson": 6.949267180578077e-16, "spearman": 6.949267180578693e-16, "kendall": 1.8291169775761935e-15}, "kappa_score": 0.15720802643498022, "total_responses": 1043, "valid_responses": 793, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.02690189159897958, "spearman": 0.026901891598979426, "kendall": 0.026901891598979422}, "p_value": {"pearson": 0.38543507069530597, "spearman": 0.3854350706953069, "kendall": 0.38517882748091503}, "kappa_score": 0.01001572062763878, "total_responses": 1043, "valid_responses": 654, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.06371768214687602, "spearman": 0.06371768214687612, "kendall": 0.0637176821468761}, "p_value": {"pearson": 0.039645995567977196, "spearman": 0.03964599556797686, "kendall": 0.03970466372529936}, "kappa_score": 0.018176928076742094, "total_responses": 1043, "valid_responses": 918, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.14763272293478635, "spearman": 0.14763272293478708, "kendall": 0.14763272293478708}, "p_value": {"pearson": 1.681010612565528e-06, "spearman": 1.681010612565417e-06, "kendall": 1.8830373014106978e-06}, "kappa_score": 0.07423884504271461, "total_responses": 1043, "valid_responses": 876, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.0819013782657713, "spearman": 0.08190137826577194, "kendall": 0.08190137826577192}, "p_value": {"pearson": 0.008137233733332801, "spearman": 0.008137233733332055, "kendall": 0.00819862830145321}, "kappa_score": 0.02871636753783824, "total_responses": 1043, "valid_responses": 856, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.0433322861092687, "spearman": 0.04333228610926837, "kendall": 0.04333228610926838}, "p_value": {"pearson": 0.1619878639221638, "spearman": 0.16198786392217057, "kendall": 0.16188278432057857}, "kappa_score": 0.018236764171611797, "total_responses": 1043, "valid_responses": 696, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.06701565579714917, "spearman": 0.06701565579714942, "kendall": 0.06701565579714941}, "p_value": {"pearson": 0.030453393927246847, "spearman": 0.030453393927246632, "kendall": 0.03052064737628122}, "kappa_score": 0.03409399756399556, "total_responses": 1043, "valid_responses": 762, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.09963738380080853, "spearman": 0.09963738380080862, "kendall": 0.09963738380080864}, "p_value": {"pearson": 0.0012729816134999258, "spearman": 0.0012729816134999647, "kendall": 0.0012985626808860885}, "kappa_score": 0.03474878269818593, "total_responses": 1043, "valid_responses": 252, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.17062845050025793, "spearman": 0.17062845050026001, "kendall": 0.17062845050026004}, "p_value": {"pearson": 2.9457103126773645e-08, "spearman": 2.945710312676219e-08, "kendall": 3.631589444267644e-08}, "kappa_score": 0.15096857116626372, "total_responses": 1043, "valid_responses": 726, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.47796925397846846, "spearman": 0.47796925397847456, "kendall": 0.4779692539784746}, "p_value": {"pearson": 1.213295897876678e-60, "spearman": 1.213295897871778e-60, "kendall": 1.0470436527662326e-53}, "kappa_score": 0.4767226614535578, "total_responses": 1043, "valid_responses": 997, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.09546825614870175, "spearman": 0.0954682561487032, "kendall": 0.09546825614870319}, "p_value": {"pearson": 0.0020249311825228347, "spearman": 0.0020249311825224848, "kendall": 0.00205809937525479}, "kappa_score": 0.08318476699846478, "total_responses": 1043, "valid_responses": 900, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": -0.02242167434570506, "spearman": -0.02242167434570514, "kendall": -0.022421674345705134}, "p_value": {"pearson": 0.46946977018768177, "spearman": 0.46946977018767977, "kendall": 0.46920559697569575}, "kappa_score": -0.014171524311494377, "total_responses": 1043, "valid_responses": 805, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.014118244862387306, "spearman": 0.01411824486238759, "kendall": 0.014118244862387592}, "p_value": {"pearson": 0.6487985685534483, "spearman": 0.6487985685534423, "kendall": 0.6485789005251116}, "kappa_score": 0.007667666878719226, "total_responses": 1043, "valid_responses": 502, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": -0.002858951829593788, "spearman": -0.0028589518295938374, "kendall": -0.002858951829593837}, "p_value": {"pearson": 0.9265226280541721, "spearman": 0.9265226280541761, "kendall": 0.9264699882548182}, "kappa_score": -0.0008727574687490414, "total_responses": 1043, "valid_responses": 552, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.039361550787776436, "spearman": 0.0393615507877765, "kendall": 0.0393615507877765}, "p_value": {"pearson": 0.204024335767058, "spearman": 0.20402433576705817, "kendall": 0.20387389322296767}, "kappa_score": 0.009072779094947525, "total_responses": 1043, "valid_responses": 635, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.09633770953223189, "spearman": 0.09633770953223231, "kendall": 0.09633770953223231}, "p_value": {"pearson": 0.001840746633287459, "spearman": 0.0018407466332873523, "kendall": 0.0018722442284088133}, "kappa_score": 0.03049412519978345, "total_responses": 1043, "valid_responses": 691, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": -0.012779651615998148, "spearman": -0.012779651615998314, "kendall": -0.012779651615998314}, "p_value": {"pearson": 0.6801581734105389, "spearman": 0.6801581734105377, "kendall": 0.6799528498868693}, "kappa_score": -0.006364065611463632, "total_responses": 1043, "valid_responses": 525, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.05064144764724311, "spearman": 0.050641447647242654, "kendall": 0.05064144764724265}, "p_value": {"pearson": 0.10213731096631469, "spearman": 0.1021373109663152, "kendall": 0.10211044555508618}, "kappa_score": 0.028213052348304513, "total_responses": 1043, "valid_responses": 711, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.030535044195943318, "spearman": 0.030535044195943356, "kendall": 0.030535044195943353}, "p_value": {"pearson": 0.32452974277524954, "spearman": 0.32452974277525837, "kendall": 0.324294101942474}, "kappa_score": 0.018819470406126304, "total_responses": 1043, "valid_responses": 795, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.022541803327535935, "spearman": 0.022541803327535744, "kendall": 0.02254180332753574}, "p_value": {"pearson": 0.4670921241453596, "spearman": 0.46709212414537815, "kendall": 0.4668278832504915}, "kappa_score": 0.006420378175934105, "total_responses": 1043, "valid_responses": 739, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.10147869842746843, "spearman": 0.10147869842746798, "kendall": 0.101478698427468}, "p_value": {"pearson": 0.001031278171482693, "spearman": 0.001031278171482741, "kendall": 0.001053874333987134}, "kappa_score": 0.07436776336565865, "total_responses": 1043, "valid_responses": 509, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.013592596799459922, "spearman": 0.013592596799460349, "kendall": 0.01359259679946035}, "p_value": {"pearson": 0.6610429195760992, "spearman": 0.6610429195760884, "kendall": 0.6608286626725279}, "kappa_score": 0.008907902833533488, "total_responses": 1043, "valid_responses": 803, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.05678976533683657, "spearman": 0.05678976533683666, "kendall": 0.05678976533683665}, "p_value": {"pearson": 0.06675278644274513, "spearman": 0.06675278644274303, "kendall": 0.06677654562183946}, "kappa_score": 0.019875425159460725, "total_responses": 1043, "valid_responses": 769, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.03906296082280186, "spearman": 0.03906296082280209, "kendall": 0.0390629608228021}, "p_value": {"pearson": 0.2074794546873376, "spearman": 0.20747945468732976, "kendall": 0.20732565742863285}, "kappa_score": 0.016550457805017293, "total_responses": 1043, "valid_responses": 747, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.09701288803021645, "spearman": 0.09701288803021689, "kendall": 0.09701288803021689}, "p_value": {"pearson": 0.0017084625581260616, "spearman": 0.001708462558126027, "kendall": 0.0017386933891167472}, "kappa_score": 0.04429901181133156, "total_responses": 1043, "valid_responses": 681, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.11840856336270117, "spearman": 0.11840856336270021, "kendall": 0.11840856336270023}, "p_value": {"pearson": 0.0001266048694678604, "spearman": 0.0001266048694678799, "kendall": 0.000132249519466195}, "kappa_score": 0.042637127423140964, "total_responses": 1043, "valid_responses": 665, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": -0.009807802927043693, "spearman": -0.009807802927043786, "kendall": -0.009807802927043786}, "p_value": {"pearson": 0.7517172902936992, "spearman": 0.7517172902936968, "kendall": 0.7515500790646042}, "kappa_score": -0.001464573723967133, "total_responses": 1043, "valid_responses": 446, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.22495227154570419, "spearman": 0.2249522715457041, "kendall": 0.2249522715457041}, "p_value": {"pearson": 1.9724888583484565e-13, "spearman": 1.9724888583485696e-13, "kendall": 3.8292037435310827e-13}, "kappa_score": 0.1642096197412518, "total_responses": 1043, "valid_responses": 471, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.1695507572151034, "spearman": 0.16955075721510665, "kendall": 0.16955075721510662}, "p_value": {"pearson": 3.606818392229575e-08, "spearman": 3.606818392227514e-08, "kendall": 4.422237906869929e-08}, "kappa_score": 0.095809921335688, "total_responses": 1043, "valid_responses": 876, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.16505599952143468, "spearman": 0.16505599952143638, "kendall": 0.1650559995214364}, "p_value": {"pearson": 8.27688813764458e-08, "spearman": 8.276888137642233e-08, "kendall": 9.929369923050146e-08}, "kappa_score": 0.1197671230529328, "total_responses": 1043, "valid_responses": 342, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.12141196837179952, "spearman": 0.12141196837179874, "kendall": 0.12141196837179875}, "p_value": {"pearson": 8.46250019232893e-05, "spearman": 8.462500192329603e-05, "kendall": 8.885024495097567e-05}, "kappa_score": 0.034416674711150286, "total_responses": 1043, "valid_responses": 888, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.2064971545310298, "spearman": 0.20649715453103065, "kendall": 0.2064971545310307}, "p_value": {"pearson": 1.654747878792288e-11, "spearman": 1.6547478787919556e-11, "kendall": 2.6334716809811076e-11}, "kappa_score": 0.19725981297927575, "total_responses": 1043, "valid_responses": 950, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.09507078711343, "spearman": 0.09507078711342969, "kendall": 0.09507078711342969}, "p_value": {"pearson": 0.0021146298634516494, "spearman": 0.002114629863451703, "kendall": 0.0021485758172355538}, "kappa_score": 0.07061483773917554, "total_responses": 1043, "valid_responses": 945, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.07530635182304903, "spearman": 0.07530635182305026, "kendall": 0.07530635182305026}, "p_value": {"pearson": 0.01499103471961299, "spearman": 0.014991034719611373, "kendall": 0.01506174897720111}, "kappa_score": 0.04867412186107489, "total_responses": 1043, "valid_responses": 794, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.2648108813707054, "spearman": 0.26481088137070774, "kendall": 0.2648108813707077}, "p_value": {"pearson": 3.3873155962474086e-18, "spearman": 3.3873155962453767e-18, "kendall": 1.2512931656804469e-17}, "kappa_score": 0.18817943595464803, "total_responses": 1043, "valid_responses": 913, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.078632686969284, "spearman": 0.07863268696928342, "kendall": 0.07863268696928341}, "p_value": {"pearson": 0.01107346598648878, "spearman": 0.011073465986488994, "kendall": 0.01114035662764328}, "kappa_score": 0.027462603008403308, "total_responses": 1043, "valid_responses": 714, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.11026303134453141, "spearman": 0.11026303134453157, "kendall": 0.11026303134453157}, "p_value": {"pearson": 0.00036024655706717515, "spearman": 0.0003602465570671608, "kendall": 0.00037185394754797786}, "kappa_score": 0.0638079330782435, "total_responses": 1043, "valid_responses": 551, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.08821862025889599, "spearman": 0.08821862025889554, "kendall": 0.08821862025889554}, "p_value": {"pearson": 0.004355326599487286, "spearman": 0.004355326599487533, "kendall": 0.004403651853206926}, "kappa_score": 0.06702085846333172, "total_responses": 1043, "valid_responses": 734, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.12035657255998417, "spearman": 0.12035657255998268, "kendall": 0.12035657255998268}, "p_value": {"pearson": 9.759762531248018e-05, "spearman": 9.75976253125042e-05, "kendall": 0.00010228224220866521}, "kappa_score": 0.10689434435973955, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.21756672372479602, "spearman": 0.21756672372479496, "kendall": 0.21756672372479488}, "p_value": {"pearson": 1.218485332023832e-12, "spearman": 1.2184853320240986e-12, "kendall": 2.1706213130693723e-12}, "kappa_score": 0.21670176265296204, "total_responses": 1043, "valid_responses": 940, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": -0.008953790495844596, "spearman": -0.008953790495844436, "kendall": -0.008953790495844433}, "p_value": {"pearson": 0.7727143230822309, "spearman": 0.7727143230822374, "kendall": 0.772559507464678}, "kappa_score": -0.008083648185572612, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": -0.008587567332159065, "spearman": -0.008587567332159077, "kendall": -0.008587567332159079}, "p_value": {"pearson": 0.7817705747822249, "spearman": 0.7817705747822266, "kendall": 0.7816212522476664}, "kappa_score": -0.0051842743677510406, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": -0.04581732240405648, "spearman": -0.04581732240405705, "kendall": -0.04581732240405705}, "p_value": {"pearson": 0.13922157006328273, "spearman": 0.139221570063275, "kendall": 0.13914451021087915}, "kappa_score": -0.014582916818571823, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.04467666393739757, "spearman": 0.04467666393739758, "kendall": 0.04467666393739758}, "p_value": {"pearson": 0.14934597449730216, "spearman": 0.14934597449730355, "kendall": 0.14925616475594186}, "kappa_score": 0.04080234020091267, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.007251013991027162, "spearman": 0.007251013991027337, "kendall": 0.007251013991027337}, "p_value": {"pearson": 0.8150645793383391, "spearman": 0.8150645793383304, "kendall": 0.814936138664968}, "kappa_score": 0.006092982962749072, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.26000020269939716, "spearman": 0.26000020269939933, "kendall": 0.26000020269939933}, "p_value": {"pearson": 1.4142460236925015e-17, "spearman": 1.414246023691625e-17, "kendall": 4.7464629599985685e-17}, "kappa_score": 0.25178398378997446, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.12963310970371006, "spearman": 0.12963310970371086, "kendall": 0.12963310970371086}, "p_value": {"pearson": 2.6776758298153652e-05, "spearman": 2.677675829815244e-05, "kendall": 2.857189839169592e-05}, "kappa_score": 0.12935176806470383, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": -0.0273868947190466, "spearman": -0.0273868947190464, "kendall": -0.027386894719046397}, "p_value": {"pearson": 0.37692358428046613, "spearman": 0.37692358428047945, "kendall": 0.3766694166119898}, "kappa_score": -0.01721071653949857, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.010662272991991892, "spearman": 0.010662272991991892, "kendall": 0.010662272991991892}, "p_value": {"pearson": 0.7308910978147961, "spearman": 0.7308910978147957, "kendall": 0.7307120980205273}, "kappa_score": 0.009295822749685212, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.04429348705309698, "spearman": 0.04429348705309689, "kendall": 0.04429348705309689}, "p_value": {"pearson": 0.15287004491158898, "spearman": 0.15287004491158926, "kendall": 0.15277590481252223}, "kappa_score": 0.039625549111510394, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": -0.003393480782679568, "spearman": -0.0033934807826795613, "kendall": -0.0033934807826795613}, "p_value": {"pearson": 0.9128351940554456, "spearman": 0.912835194055448, "kendall": 0.9127728935308029}, "kappa_score": -0.003183973997545664, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.24845836135333885, "spearman": 0.24845836135334057, "kendall": 0.24845836135334054}, "p_value": {"pearson": 3.8726092487759663e-16, "spearman": 3.87260924877431e-16, "kendall": 1.0553698116250017e-15}, "kappa_score": 0.2484481755753688, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.21276529517681858, "spearman": 0.21276529517681966, "kendall": 0.21276529517681966}, "p_value": {"pearson": 3.844930900939028e-12, "spearman": 3.844930900938159e-12, "kendall": 6.50767450006045e-12}, "kappa_score": 0.18850728020451268, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.04279108252628354, "spearman": 0.04279108252628339, "kendall": 0.0427910825262834}, "p_value": {"pearson": 0.1672988708326861, "spearman": 0.16729887083268855, "kendall": 0.16718759742034917}, "kappa_score": 0.039903875526953514, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.07010180112481636, "spearman": 0.07010180112481593, "kendall": 0.07010180112481591}, "p_value": {"pearson": 0.023571383417678282, "spearman": 0.023571383417678622, "kendall": 0.02364260185842894}, "kappa_score": 0.04482098207160712, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.05973521651091879, "spearman": 0.05973521651091795, "kendall": 0.05973521651091795}, "p_value": {"pearson": 0.05378198555359697, "spearman": 0.0537819855536003, "kendall": 0.053823506933604645}, "kappa_score": 0.05966004712218109, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.19727999514102573, "spearman": 0.1972799951410256, "kendall": 0.19727999514102562}, "p_value": {"pearson": 1.302488103057194e-10, "spearman": 1.3024881030572336e-10, "kendall": 1.912555164867589e-10}, "kappa_score": 0.18223682251709528, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.05781241964815051, "spearman": 0.05781241964815033, "kendall": 0.05781241964815033}, "p_value": {"pearson": 0.06198487849114229, "spearman": 0.06198487849114635, "kendall": 0.06201529968645458}, "kappa_score": 0.028367941821678566, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.3646432299517186, "spearman": 0.3646432299517203, "kendall": 0.3646432299517204}, "p_value": {"pearson": 3.7732513017910847e-34, "spearman": 3.7732513017885903e-34, "kendall": 5.52689445131329e-32}, "kappa_score": 0.34062766432544356, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.09501100492234169, "spearman": 0.09501100492234178, "kendall": 0.09501100492234178}, "p_value": {"pearson": 0.002128431668698421, "spearman": 0.0021284316686983455, "kendall": 0.0021624953376917903}, "kappa_score": 0.0901532819426395, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.1849315893769642, "spearman": 0.18493158937696508, "kendall": 0.1849315893769651}, "p_value": {"pearson": 1.7738031727443116e-09, "spearman": 1.7738031727440326e-09, "kendall": 2.3784136314972545e-09}, "kappa_score": 0.184354582376832, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.08687536441364277, "spearman": 0.08687536441364095, "kendall": 0.08687536441364094}, "p_value": {"pearson": 0.0049907603983864735, "spearman": 0.0049907603983875976, "kendall": 0.005041987475709923}, "kappa_score": 0.0867562337220521, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.1717788957054398, "spearman": 0.17177889570544158, "kendall": 0.17177889570544158}, "p_value": {"pearson": 2.36975303288365e-08, "spearman": 2.3697530328829186e-08, "kendall": 2.9390879649224886e-08}, "kappa_score": 0.13452495835663925, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.21467737748990331, "spearman": 0.21467737748990243, "kendall": 0.21467737748990248}, "p_value": {"pearson": 2.4409380171976104e-12, "spearman": 2.4409380171982566e-12, "kendall": 4.214626192564435e-12}, "kappa_score": 0.21458652907544284, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.023393008054542336, "spearman": 0.02339300805454224, "kendall": 0.023393008054542246}, "p_value": {"pearson": 0.4504371192578148, "spearman": 0.45043711925780616, "kendall": 0.4501728563572588}, "kappa_score": 0.023386973847527415, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.06153229644893835, "spearman": 0.061532296448938276, "kendall": 0.06153229644893829}, "p_value": {"pearson": 0.046953792184598914, "spearman": 0.046953792184599226, "kendall": 0.0470040117259409}, "kappa_score": 0.03807430407181389, "total_responses": 1043, "valid_responses": 1028, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.1272581700162273, "spearman": 0.12725817001622894, "kendall": 0.12725817001622897}, "p_value": {"pearson": 3.760744105108043e-05, "spearman": 3.760744105107091e-05, "kendall": 3.992782859099823e-05}, "kappa_score": 0.12099458568024601, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": -0.019314135313728664, "spearman": -0.019314135313728786, "kendall": -0.019314135313728786}, "p_value": {"pearson": 0.5332385159518731, "spearman": 0.533238515951873, "kendall": 0.5329817764384727}, "kappa_score": -0.01857894862206133, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.061500977709244876, "spearman": 0.061500977709244425, "kendall": 0.06150097770924444}, "p_value": {"pearson": 0.047066239231351135, "spearman": 0.04706623923135132, "kendall": 0.04711632089051238}, "kappa_score": 0.043612414411640765, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.04510005411100072, "spearman": 0.045100054111000966, "kendall": 0.04510005411100096}, "p_value": {"pearson": 0.14552443184196723, "spearman": 0.1455244318419697, "kendall": 0.14543938130545253}, "kappa_score": 0.041623799388993965, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.026805313253818026, "spearman": 0.026805313253818172, "kendall": 0.026805313253818176}, "p_value": {"pearson": 0.38714385351072345, "spearman": 0.3871438535107202, "kendall": 0.3868872236334665}, "kappa_score": 0.014210272374569621, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.17664245117265226, "spearman": 0.17664245117265406, "kendall": 0.17664245117265404}, "p_value": {"pearson": 9.293911710085656e-09, "spearman": 9.293911710082363e-09, "kendall": 1.1839405578658138e-08}, "kappa_score": 0.12252790718115492, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.36880378129017544, "spearman": 0.3688037812901734, "kendall": 0.3688037812901734}, "p_value": {"pearson": 5.954783700788532e-35, "spearman": 5.954783700793781e-35, "kendall": 1.1146971976428658e-32}, "kappa_score": 0.3631091605752097, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.1466897725665557, "spearman": 0.1466897725665562, "kendall": 0.1466897725665562}, "p_value": {"pearson": 1.9600747897709626e-06, "spearman": 1.960074789770756e-06, "kendall": 2.1889369300154455e-06}, "kappa_score": 0.12618745752741067, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": -0.0172499359918677, "spearman": -0.017249935991867683, "kendall": -0.017249935991867686}, "p_value": {"pearson": 0.5778903740338046, "spearman": 0.5778903740337887, "kendall": 0.5776447044108063}, "kappa_score": -0.01599589848756744, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": -0.01923403833909168, "spearman": -0.019234038339092072, "kendall": -0.019234038339092076}, "p_value": {"pearson": 0.5349381186747705, "spearman": 0.5349381186747482, "kendall": 0.5346817171620402}, "kappa_score": -0.014650898393089529, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.06988269008177954, "spearman": 0.0698826900817789, "kendall": 0.0698826900817789}, "p_value": {"pearson": 0.02401116751848815, "spearman": 0.024011167518490126, "kendall": 0.02408222155879877}, "kappa_score": 0.02578830400566856, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.06732739210293641, "spearman": 0.06732739210293626, "kendall": 0.06732739210293626}, "p_value": {"pearson": 0.029687674958520024, "spearman": 0.029687674958520528, "kendall": 0.029755497729475326}, "kappa_score": 0.06672631982615362, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.014180630335921388, "spearman": 0.014180630335921379, "kendall": 0.01418063033592138}, "p_value": {"pearson": 0.6473515629293226, "spearman": 0.6473515629293234, "kendall": 0.6471312720722813}, "kappa_score": 0.004906637590295859, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": -0.013543629538617229, "spearman": -0.013543629538617062, "kendall": -0.01354362953861706}, "p_value": {"pearson": 0.662188244204505, "spearman": 0.6621882442045107, "kendall": 0.6619745061290443}, "kappa_score": -0.0045264641211639756, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.04958372144885946, "spearman": 0.049583721448859384, "kendall": 0.049583721448859384}, "p_value": {"pearson": 0.10951079651438417, "spearman": 0.10951079651438402, "kendall": 0.10947357495330105}, "kappa_score": 0.015586499180285207, "total_responses": 1043, "valid_responses": 1039, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": -0.013112084052103071, "spearman": -0.013112084052103004, "kendall": -0.013112084052103007}, "p_value": {"pearson": 0.6723158018807347, "spearman": 0.6723158018807378, "kendall": 0.6721067435020902}, "kappa_score": -0.011526413769270993, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": -0.05021445669707932, "spearman": -0.05021445669707917, "kendall": -0.05021445669707916}, "p_value": {"pearson": 0.10506495416004856, "spearman": 0.105064954160049, "kendall": 0.10503395901295062}, "kappa_score": -0.03520148216767005, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.234783793240104, "spearman": 0.23478379324010273, "kendall": 0.23478379324010265}, "p_value": {"pearson": 1.5787213858359716e-14, "spearman": 1.5787213858364522e-14, "kendall": 3.48693995624337e-14}, "kappa_score": 0.21388375339252574, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.02180970272528701, "spearman": 0.021809702725287337, "kendall": 0.021809702725287344}, "p_value": {"pearson": 0.4816853008728281, "spearman": 0.4816853008728236, "kendall": 0.4814217231807425}, "kappa_score": 0.009465320206400896, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": -0.02400988222069498, "spearman": -0.02400988222069495, "kendall": -0.024009882220694955}, "p_value": {"pearson": 0.43858004836388503, "spearman": 0.438580048363873, "kendall": 0.43831626426030335}, "kappa_score": -0.023962653523271316, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": -0.03732097294717984, "spearman": -0.03732097294718047, "kendall": -0.03732097294718047}, "p_value": {"pearson": 0.228483647854703, "spearman": 0.2284836478546964, "kendall": 0.2283106665012471}, "kappa_score": -0.034863829204871966, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.036522653550682536, "spearman": 0.03652265355068334, "kendall": 0.03652265355068334}, "p_value": {"pearson": 0.23859871289338863, "spearman": 0.2385987128933857, "kendall": 0.23841722534831877}, "kappa_score": 0.030551626591230563, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": -0.0483664889550759, "spearman": -0.048366488955075254, "kendall": -0.04836648895507525}, "p_value": {"pearson": 0.11850934875415028, "spearman": 0.1185093487541588, "kendall": 0.1184597140016397}, "kappa_score": -0.043725637824392205, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.02276064029239216, "spearman": 0.022760640292392376, "kendall": 0.022760640292392376}, "p_value": {"pearson": 0.4627779952163694, "spearman": 0.4627779952163532, "kendall": 0.4625136722724452}, "kappa_score": 0.010064527636046261, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.3007625002938986, "spearman": 0.3007625002939011, "kendall": 0.30076250029390106}, "p_value": {"pearson": 3.0062258966587065e-23, "spearman": 3.0062258966558e-23, "kendall": 2.7706012820472795e-22}, "kappa_score": 0.30076039765821905, "total_responses": 1043, "valid_responses": 1037, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.030954178220506313, "spearman": 0.030954178220506983, "kendall": 0.030954178220506976}, "p_value": {"pearson": 0.31792959160881623, "spearman": 0.31792959160881373, "kendall": 0.3176970215368792}, "kappa_score": 0.023450878801550612, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": -0.03823709109348027, "spearman": -0.0382370910934809, "kendall": -0.0382370910934809}, "p_value": {"pearson": 0.21725626276455706, "spearman": 0.21725626276454238, "kendall": 0.21709327847165072}, "kappa_score": -0.026062710291332225, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.02058433098513527, "spearman": 0.020584330985135277, "kendall": 0.020584330985135277}, "p_value": {"pearson": 0.5066553167187348, "spearman": 0.5066553167187344, "kendall": 0.506394205265719}, "kappa_score": 0.011312161798192943, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.17661421349310358, "spearman": 0.17661421349310302, "kendall": 0.17661421349310302}, "p_value": {"pearson": 9.345267292554017e-09, "spearman": 9.34526729255476e-09, "kendall": 1.1902896271951102e-08}, "kappa_score": 0.1766127016744884, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.1588980964741047, "spearman": 0.15889809647410189, "kendall": 0.15889809647410189}, "p_value": {"pearson": 2.491388235573054e-07, "spearman": 2.491388235574265e-07, "kendall": 2.9092277228741835e-07}, "kappa_score": 0.10253091643495638, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.1754201048229429, "spearman": 0.17542010482294362, "kendall": 0.17542010482294362}, "p_value": {"pearson": 1.1788011077977323e-08, "spearman": 1.1788011077975758e-08, "kendall": 1.4912657091447953e-08}, "kappa_score": 0.10562729276729965, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.228824294126649, "spearman": 0.22882429412665412, "kendall": 0.22882429412665412}, "p_value": {"pearson": 7.398131255253013e-14, "spearman": 7.398131255243577e-14, "kendall": 1.5079641500461868e-13}, "kappa_score": 0.18006467351222555, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.08357661822925905, "spearman": 0.08357661822925819, "kendall": 0.08357661822925819}, "p_value": {"pearson": 0.006920641604869877, "spearman": 0.0069206416048705165, "kendall": 0.006978776638202003}, "kappa_score": 0.07555729221268115, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.2284863188882026, "spearman": 0.2284863188882019, "kendall": 0.22848631888820192}, "p_value": {"pearson": 8.065066456021289e-14, "spearman": 8.065066456022711e-14, "kendall": 1.63675286579733e-13}, "kappa_score": 0.15739701208827095, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.1084500865028698, "spearman": 0.10845008650286984, "kendall": 0.10845008650286984}, "p_value": {"pearson": 0.00045046505642792835, "spearman": 0.0004504650564279192, "kendall": 0.0004639134599135904}, "kappa_score": 0.030907189820476133, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.03290693864206462, "spearman": 0.03290693864206438, "kendall": 0.03290693864206438}, "p_value": {"pearson": 0.28834485065264415, "spearman": 0.2883448506526569, "kendall": 0.28812819976607273}, "kappa_score": 0.016233121525019656, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.399655189231653, "spearman": 0.39965518923165194, "kendall": 0.39965518923165194}, "p_value": {"pearson": 2.8236993361099355e-41, "spearman": 2.8236993361116305e-41, "kendall": 4.4498978316971414e-38}, "kappa_score": 0.3995542242486, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.07784534536933663, "spearman": 0.0778453453693371, "kendall": 0.07784534536933709}, "p_value": {"pearson": 0.011908050241020748, "spearman": 0.011908050241020138, "kendall": 0.011976035296155424}, "kappa_score": 0.040988658164431646, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.22262990905054594, "spearman": 0.22262990905054253, "kendall": 0.22262990905054253}, "p_value": {"pearson": 3.5214279467278707e-13, "spearman": 3.521427946730759e-13, "kendall": 6.647378568946667e-13}, "kappa_score": 0.1692853522554486, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.01116818171627773, "spearman": 0.011168181716277868, "kendall": 0.01116818171627787}, "p_value": {"pearson": 0.7186520650820781, "spearman": 0.7186520650820727, "kendall": 0.7184663909412029}, "kappa_score": 0.0056736355601918476, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.3194033530991928, "spearman": 0.3194033530991928, "kendall": 0.3194033530991928}, "p_value": {"pearson": 3.63794131569693e-26, "spearman": 3.6379413156970025e-26, "kendall": 6.327169202999095e-25}, "kappa_score": 0.25251744089530603, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.19443745319054187, "spearman": 0.19443745319054123, "kendall": 0.19443745319054123}, "p_value": {"pearson": 2.412882530624674e-10, "spearman": 2.4128825306251546e-10, "kendall": 3.4640004347716045e-10}, "kappa_score": 0.10238920282496933, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.4217487079955936, "spearman": 0.421748707995601, "kendall": 0.4217487079956011}, "p_value": {"pearson": 3.1055515303318365e-46, "spearman": 3.1055515303195375e-46, "kendall": 3.3037470199579355e-42}, "kappa_score": 0.3678860161690546, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.46916835824161274, "spearman": 0.4691683582416068, "kendall": 0.46916835824160674}, "p_value": {"pearson": 3.3195910711739104e-58, "spearman": 3.3195910711862516e-58, "kendall": 8.204583958619751e-52}, "kappa_score": 0.3994858736903565, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.17734039923799322, "spearman": 0.1773403992379942, "kendall": 0.17734039923799422}, "p_value": {"pearson": 8.108182200070981e-09, "spearman": 8.108182200068996e-09, "kendall": 1.0370674552763715e-08}, "kappa_score": 0.148746718822379, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.3179820606154929, "spearman": 0.3179820606154912, "kendall": 0.3179820606154913}, "p_value": {"pearson": 6.175738322403922e-26, "spearman": 6.175738322407987e-26, "kendall": 1.0188012916905883e-24}, "kappa_score": 0.28348980993817263, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.3983713301098748, "spearman": 0.39837133010987297, "kendall": 0.398371330109873}, "p_value": {"pearson": 5.341411997181132e-41, "spearman": 5.341411997186233e-41, "kendall": 7.612970928581912e-38}, "kappa_score": 0.3942195541125335, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.15047164935882865, "spearman": 0.15047164935882998, "kendall": 0.15047164935882992}, "p_value": {"pearson": 1.0525516190064434e-06, "spearman": 1.05255161900622e-06, "kendall": 1.1904015259706369e-06}, "kappa_score": 0.08981008155905179, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.6617279750216081, "spearman": 0.6617279750216207, "kendall": 0.6617279750216207}, "p_value": {"pearson": 2.2716348936556398e-132, "spearman": 2.2716348936205e-132, "kendall": 3.108240266819544e-101}, "kappa_score": 0.6480626610859437, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.3624367933530691, "spearman": 0.36243679335307105, "kendall": 0.36243679335307105}, "p_value": {"pearson": 9.935364271656106e-34, "spearman": 9.935364271647544e-34, "kendall": 1.2825401010210396e-31}, "kappa_score": 0.28229051075885414, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.3524246350544039, "spearman": 0.3524246350544022, "kendall": 0.35242463505440214}, "p_value": {"pearson": 7.31343700904403e-32, "spearman": 7.313437009049305e-32, "kendall": 5.4894116395935266e-30}, "kappa_score": 0.33800986880768635, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.05907626420763434, "spearman": 0.059076264207633615, "kendall": 0.05907626420763362}, "p_value": {"pearson": 0.05648482647483406, "spearman": 0.056484826474835395, "kendall": 0.05652275362023751}, "kappa_score": 0.04101052262875993, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.05915410208386393, "spearman": 0.05915410208386371, "kendall": 0.05915410208386372}, "p_value": {"pearson": 0.056159789450665104, "spearman": 0.05615978945066673, "kendall": 0.056198152545698536}, "kappa_score": 0.04043875568117927, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.5441185757593918, "spearman": 0.544118575759391, "kendall": 0.5441185757593912}, "p_value": {"pearson": 1.982081590553055e-81, "spearman": 1.982081590554143e-81, "kendall": 4.6349534000267603e-69}, "kappa_score": 0.5424364218073533, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.3645308575655793, "spearman": 0.3645308575655776, "kendall": 0.36453085756557757}, "p_value": {"pearson": 3.964692873795367e-34, "spearman": 3.964692873797978e-34, "kendall": 5.769700840541408e-32}, "kappa_score": 0.3305679035823804, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.6168208917341172, "spearman": 0.6168208917341129, "kendall": 0.6168208917341128}, "p_value": {"pearson": 2.3520677010072886e-110, "spearman": 2.3520677010182394e-110, "kendall": 3.2676909851067314e-88}, "kappa_score": 0.616796397720379, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.2488942740961424, "spearman": 0.24889427409614287, "kendall": 0.24889427409614284}, "p_value": {"pearson": 3.4278813042434503e-16, "spearman": 3.427881304242799e-16, "kendall": 9.410442552810546e-16}, "kappa_score": 0.24794881330975382, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.2164710919154312, "spearman": 0.21647109191543212, "kendall": 0.21647109191543218}, "p_value": {"pearson": 1.5876014978664666e-12, "spearman": 1.5876014978661065e-12, "kendall": 2.794445901746208e-12}, "kappa_score": 0.20131030375223358, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.42336022497269665, "spearman": 0.4233602249726893, "kendall": 0.42336022497268927}, "p_value": {"pearson": 1.3053370927485958e-46, "spearman": 1.30533709275364e-46, "kendall": 1.6188721705700695e-42}, "kappa_score": 0.3606686647343115, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.3725304145800378, "spearman": 0.3725304145800441, "kendall": 0.3725304145800441}, "p_value": {"pearson": 1.1132192437258458e-35, "spearman": 1.1132192437226725e-35, "kendall": 2.6166453569823418e-33}, "kappa_score": 0.2935404691626534, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.4455241820449548, "spearman": 0.4455241820449529, "kendall": 0.44552418204495303}, "p_value": {"pearson": 5.32933340888089e-52, "spearman": 5.329333408886933e-52, "kendall": 6.758217707603602e-47}, "kappa_score": 0.40989965465268374, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.2056922072948813, "spearman": 0.20569220729488188, "kendall": 0.20569220729488188}, "p_value": {"pearson": 1.9892393333709317e-11, "spearman": 1.989239333370657e-11, "kendall": 3.142165963518704e-11}, "kappa_score": 0.08637904692615495, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.1673096729820938, "spearman": 0.16730967298209437, "kendall": 0.1673096729820944}, "p_value": {"pearson": 5.4726779831836736e-08, "spearman": 5.4726779831829384e-08, "kendall": 6.635901212514002e-08}, "kappa_score": 0.059824962843042395, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.2781676355044185, "spearman": 0.27816763550442053, "kendall": 0.2781676355044206}, "p_value": {"pearson": 5.483426609329519e-20, "spearman": 5.48342660932628e-20, "kendall": 2.7259845328342123e-19}, "kappa_score": 0.19802341493081954, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.10803477072915268, "spearman": 0.10803477072915357, "kendall": 0.10803477072915355}, "p_value": {"pearson": 0.00047390499872426955, "spearman": 0.0004739049987241906, "kendall": 0.00048780498410033366}, "kappa_score": 0.05253342321087506, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.2333851269032322, "spearman": 0.23338512690323038, "kendall": 0.2333851269032304}, "p_value": {"pearson": 2.2772878627535663e-14, "spearman": 2.27728786275465e-14, "kendall": 4.933080845257828e-14}, "kappa_score": 0.1270256035471793, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.11171769313860352, "spearman": 0.1117176931386042, "kendall": 0.1117176931386042}, "p_value": {"pearson": 0.00030037633427480026, "spearman": 0.0003003763342747772, "kendall": 0.0003106539779011878}, "kappa_score": 0.027038430026643634, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.18630785913830705, "spearman": 0.18630785913830727, "kendall": 0.1863078591383073}, "p_value": {"pearson": 1.3372976713797615e-09, "spearman": 1.3372976713796623e-09, "kendall": 1.8097558670774077e-09}, "kappa_score": 0.12548037092121422, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.43461556467928586, "spearman": 0.43461556467929036, "kendall": 0.4346155646792904}, "p_value": {"pearson": 2.685690441745202e-49, "spearman": 2.685690441738495e-49, "kendall": 1.0301771916025835e-44}, "kappa_score": 0.3240689246269035, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8258377575499997, "spearman": 0.8258377575499951, "kendall": 0.825837757549995}, "p_value": {"pearson": 3.0454364388167027e-261, "spearman": 3.045436438853178e-261, "kendall": 1.443138579017191e-156}, "kappa_score": 0.8242848803269118, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.3993315155361766, "spearman": 0.3993315155361801, "kendall": 0.39933151553618007}, "p_value": {"pearson": 3.3168574221599747e-41, "spearman": 3.3168574221538725e-41, "kendall": 5.095807811972693e-38}, "kappa_score": 0.3629428798671195, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.1977189039914867, "spearman": 0.19771890399148903, "kendall": 0.197718903991489}, "p_value": {"pearson": 1.1832338349560842e-10, "spearman": 1.1832338349554713e-10, "kendall": 1.743667591011257e-10}, "kappa_score": 0.14841561439813067, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.2856595506287541, "spearman": 0.2856595506287556, "kendall": 0.2856595506287557}, "p_value": {"pearson": 4.902829641149821e-21, "spearman": 4.9028296411475935e-21, "kendall": 2.9407497746327057e-20}, "kappa_score": 0.24077908677799842, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.1068036098399956, "spearman": 0.10680360983999568, "kendall": 0.10680360983999568}, "p_value": {"pearson": 0.0005502364071742173, "spearman": 0.0005502364071741905, "kendall": 0.0005655424715449021}, "kappa_score": 0.05801739540180251, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.20486146992626722, "spearman": 0.20486146992626875, "kendall": 0.20486146992626875}, "p_value": {"pearson": 2.4035937801032376e-11, "spearman": 2.4035937801023597e-11, "kendall": 3.7677818377263106e-11}, "kappa_score": 0.12202242361285243, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.08152878211336863, "spearman": 0.08152878211336918, "kendall": 0.08152878211336918}, "p_value": {"pearson": 0.008432521218388948, "spearman": 0.008432521218388857, "kendall": 0.00849460676516123}, "kappa_score": 0.033503985909661416, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.05950241253530123, "spearman": 0.05950241253530119, "kendall": 0.0595024125353012}, "p_value": {"pearson": 0.0547242993845827, "spearman": 0.05472429938458117, "kendall": 0.054764575899654444}, "kappa_score": 0.030632692421336594, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.045602198912947305, "spearman": 0.045602198912947214, "kendall": 0.04560219891294721}, "p_value": {"pearson": 0.14108949238002352, "spearman": 0.14108949238002078, "kendall": 0.14101004628094382}, "kappa_score": 0.004150489896358245, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.07900790999644586, "spearman": 0.07900790999644518, "kendall": 0.07900790999644518}, "p_value": {"pearson": 0.010694306173083335, "spearman": 0.010694306173084273, "kendall": 0.010760639661294862}, "kappa_score": 0.025544232565926306, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.030865522795037965, "spearman": 0.030865522795038052, "kendall": 0.030865522795038056}, "p_value": {"pearson": 0.3193182826735347, "spearman": 0.3193182826735347, "kendall": 0.3190850522430313}, "kappa_score": 0.009289337996433611, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.2218430339775938, "spearman": 0.22184303397759297, "kendall": 0.22184303397759295}, "p_value": {"pearson": 4.279264504794607e-13, "spearman": 4.2792645047956507e-13, "kendall": 8.003303600878796e-13}, "kappa_score": 0.11073823934211091, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.04368751239867771, "spearman": 0.04368751239867813, "kendall": 0.04368751239867812}, "p_value": {"pearson": 0.1585716303902348, "spearman": 0.1585716303902272, "kendall": 0.1584706045197184}, "kappa_score": 0.022135062716011067, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.07410864566835537, "spearman": 0.07410864566835523, "kendall": 0.07410864566835522}, "p_value": {"pearson": 0.016674890027197017, "spearman": 0.016674890027196958, "kendall": 0.01674639375304253}, "kappa_score": 0.05883715173245385, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.06573006493873089, "spearman": 0.06573006493873154, "kendall": 0.06573006493873156}, "p_value": {"pearson": 0.0337927389821719, "spearman": 0.03379273898217102, "kendall": 0.03385721457332813}, "kappa_score": 0.06431797101890013, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.2304966394557037, "spearman": 0.23049663945570492, "kendall": 0.23049663945570498}, "p_value": {"pearson": 4.8167961206875806e-14, "spearman": 4.81679612068568e-14, "kendall": 1.0035258986076963e-13}, "kappa_score": 0.13355650268320873, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.3418497166960885, "spearman": 0.3418497166960891, "kendall": 0.3418497166960891}, "p_value": {"pearson": 5.8110230649210066e-30, "spearman": 5.811023064919293e-30, "kendall": 2.5928985914730085e-28}, "kappa_score": 0.23734538975684605, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.04411584284573593, "spearman": 0.044115842845736594, "kendall": 0.0441158428457366}, "p_value": {"pearson": 0.15452511366037047, "spearman": 0.15452511366035526, "kendall": 0.15442895935099324}, "kappa_score": 0.009324473881720308, "total_responses": 1043, "valid_responses": 1033, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.5409084453363227, "spearman": 0.5409084453363194, "kendall": 0.5409084453363194}, "p_value": {"pearson": 2.602651539383529e-80, "spearman": 2.602651539390251e-80, "kendall": 2.862238488841569e-68}, "kappa_score": 0.5405117662175558, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.28189677602999286, "spearman": 0.28189677602999785, "kendall": 0.2818967760299978}, "p_value": {"pearson": 1.66382705342192e-20, "spearman": 1.66382705341922e-20, "kendall": 9.063598192325057e-20}, "kappa_score": 0.18088030557241286, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.33286281006423696, "spearman": 0.3328628100642412, "kendall": 0.3328628100642412}, "p_value": {"pearson": 2.100769426989332e-28, "spearman": 2.1007694269860387e-28, "kendall": 6.268423697996146e-27}, "kappa_score": 0.3125836454977705, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.17572014271284664, "spearman": 0.17572014271284675, "kendall": 0.17572014271284678}, "p_value": {"pearson": 1.1121560196422681e-08, "spearman": 1.1121560196421832e-08, "kendall": 1.4093364074420612e-08}, "kappa_score": 0.07094725533260349, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.3320371848924688, "spearman": 0.33203718489247347, "kendall": 0.3320371848924736}, "p_value": {"pearson": 2.9036903606818944e-28, "spearman": 2.903690360676754e-28, "kendall": 8.364313120008255e-27}, "kappa_score": 0.25247030348603605, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.41093158980793165, "spearman": 0.41093158980792044, "kendall": 0.4109315898079205}, "p_value": {"pearson": 9.256142608275607e-44, "spearman": 9.256142608328217e-44, "kendall": 3.700032845468278e-40}, "kappa_score": 0.4103407514005242, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.3111371948599201, "spearman": 0.31113719485992336, "kendall": 0.31113719485992336}, "p_value": {"pearson": 7.59104236256825e-25, "spearman": 7.591042362559348e-25, "kendall": 9.81129303665527e-24}, "kappa_score": 0.24214743922439752, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.49723923298602013, "spearman": 0.49723923298602324, "kendall": 0.4972392329860233}, "p_value": {"pearson": 3.111384240001512e-66, "spearman": 3.111384239995265e-66, "kendall": 5.6345851772028504e-58}, "kappa_score": 0.47675835280290113, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.1284989885749655, "spearman": 0.1284989885749642, "kendall": 0.12849898857496417}, "p_value": {"pearson": 3.151537412062242e-05, "spearman": 3.151537412062899e-05, "kendall": 3.354648529489722e-05}, "kappa_score": 0.06013035326649785, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.3346648949189177, "spearman": 0.3346648949189204, "kendall": 0.33466489491892043}, "p_value": {"pearson": 1.0328976175284782e-28, "spearman": 1.0328976175274506e-28, "kendall": 3.3316988134624295e-27}, "kappa_score": 0.2297535211267605, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.2741128674362172, "spearman": 0.274112867436218, "kendall": 0.27411286743621804}, "p_value": {"pearson": 1.9646120727131952e-19, "spearman": 1.964612072712597e-19, "kendall": 8.880667826889709e-19}, "kappa_score": 0.1603154584204729, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gpt-4o (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.404416276633119, "spearman": 0.4044162766331171, "kendall": 0.40441627663311713}, "p_value": {"pearson": 2.591241052940283e-42, "spearman": 2.591241052942763e-42, "kendall": 5.984900247437593e-39}, "kappa_score": 0.40438380131951446, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.3933734195444672, "spearman": 0.39337341954446664, "kendall": 0.39337341954446664}, "p_value": {"pearson": 6.2203123009695225e-40, "spearman": 6.220312300971578e-40, "kendall": 6.057981749407511e-37}, "kappa_score": 0.29164283671718616, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.4120353579699756, "spearman": 0.41203535796997653, "kendall": 0.4120353579699765}, "p_value": {"pearson": 5.225019200494077e-44, "spearman": 5.225019200491694e-44, "kendall": 2.298900228079458e-40}, "kappa_score": 0.4104439019110272, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.4785113316157919, "spearman": 0.47851133161579007, "kendall": 0.47851133161579007}, "p_value": {"pearson": 8.541207290442471e-61, "spearman": 8.541207290451756e-61, "kendall": 7.982885698894855e-54}, "kappa_score": 0.4775700747330248, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.3331643191669904, "spearman": 0.3331643191669967, "kendall": 0.33316431916699674}, "p_value": {"pearson": 1.8661040002365094e-28, "spearman": 1.8661040002319911e-28, "kendall": 5.640715146739698e-27}, "kappa_score": 0.2684613072375672, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.44421016112107703, "spearman": 0.4442101611210758, "kendall": 0.44421016112107575}, "p_value": {"pearson": 1.1413903218066563e-51, "spearman": 1.1413903218073526e-51, "kendall": 1.2463463679103364e-46}, "kappa_score": 0.44129207138016713, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.44014231825878636, "spearman": 0.44014231825878386, "kendall": 0.44014231825878386}, "p_value": {"pearson": 1.1809476739052885e-50, "spearman": 1.1809476739069844e-50, "kendall": 8.195431439764115e-46}, "kappa_score": 0.4071857817060165, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.6532127787115698, "spearman": 0.6532127787115788, "kendall": 0.6532127787115788}, "p_value": {"pearson": 6.613790655472314e-128, "spearman": 6.613790655400886e-128, "kendall": 1.0755391644027946e-98}, "kappa_score": 0.6482036883415225, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.5046007249072193, "spearman": 0.5046007249072098, "kendall": 0.5046007249072096}, "p_value": {"pearson": 1.823852603908052e-68, "spearman": 1.823852603920603e-68, "kendall": 1.1906847944452356e-59}, "kappa_score": 0.48989140106183005, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.31253736961280365, "spearman": 0.31253736961280065, "kendall": 0.31253736961280065}, "p_value": {"pearson": 4.567995394851045e-25, "spearman": 4.567995394856365e-25, "kendall": 6.1976086697107015e-24}, "kappa_score": 0.29899390968969397, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.5940164727201103, "spearman": 0.5940164727201077, "kendall": 0.5940164727201077}, "p_value": {"pearson": 1.7566503987280274e-100, "spearman": 1.7566503987321808e-100, "kendall": 6.002238310849351e-82}, "kappa_score": 0.5719553234880006, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.6168764763919405, "spearman": 0.6168764763919415, "kendall": 0.6168764763919415}, "p_value": {"pearson": 2.2201815107185037e-110, "spearman": 2.2201815107162636e-110, "kendall": 3.1527231213610016e-88}, "kappa_score": 0.6168674948133048, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.7158216399790222, "spearman": 0.7158216399790213, "kendall": 0.7158216399790213}, "p_value": {"pearson": 1.4954673862077442e-164, "spearman": 1.4954673862099524e-164, "kendall": 3.961163745205268e-118}, "kappa_score": 0.697856315179606, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.8444352370803669, "spearman": 0.8444352370803825, "kendall": 0.8444352370803824}, "p_value": {"pearson": 1.7301265237977074e-284, "spearman": 1.7301265237152642e-284, "kendall": 1.3217452120524212e-163}, "kappa_score": 0.8381942289792119, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.8967041610277198, "spearman": 0.8967041610277288, "kendall": 0.8967041610277288}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 3.184944406156878e-184}, "kappa_score": 0.8966828901054633, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.529392308337837, "spearman": 0.5293923083378334, "kendall": 0.5293923083378334}, "p_value": {"pearson": 2.1349056865527826e-76, "spearman": 2.1349056865590696e-76, "kendall": 1.798463137083494e-65}, "kappa_score": 0.5224811787685131, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.26063842344965976, "spearman": 0.26063842344965626, "kendall": 0.26063842344965626}, "p_value": {"pearson": 1.1719684018998494e-17, "spearman": 1.171968401901038e-17, "kendall": 3.9824367359401125e-17}, "kappa_score": 0.20411177713274808, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.23634562081125587, "spearman": 0.23634562081125385, "kendall": 0.2363456208112539}, "p_value": {"pearson": 1.0457141792761635e-14, "spearman": 1.045714179276686e-14, "kendall": 2.3613708963262424e-14}, "kappa_score": 0.21750547045951862, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.7998950636483337, "spearman": 0.7998950636483392, "kendall": 0.799895063648339}, "p_value": {"pearson": 4.473934823084907e-233, "spearman": 4.473934823028299e-233, "kendall": 5.201870705345194e-147}, "kappa_score": 0.7902874195733153, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.5416929224217745, "spearman": 0.5416929224217659, "kendall": 0.5416929224217659}, "p_value": {"pearson": 1.3907457136866128e-80, "spearman": 1.3907457136961245e-80, "kendall": 1.8361873433419949e-68}, "kappa_score": 0.522265764161026, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.7650873056437553, "spearman": 0.7650873056437543, "kendall": 0.7650873056437543}, "p_value": {"pearson": 3.2190939897409115e-201, "spearman": 3.2190939897472103e-201, "kendall": 1.150816943071614e-134}, "kappa_score": 0.7436664140741802, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.3648513750939837, "spearman": 0.3648513750939828, "kendall": 0.3648513750939828}, "p_value": {"pearson": 3.442552160082368e-34, "spearman": 3.442552160083558e-34, "kendall": 5.103641658910976e-32}, "kappa_score": 0.34752689965801986, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.8026818735763501, "spearman": 0.8026818735763602, "kendall": 0.8026818735763601}, "p_value": {"pearson": 6.739681242282257e-236, "spearman": 6.739681242121815e-236, "kendall": 5.059711810958492e-148}, "kappa_score": 0.8012538348672802, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.7167033787127349, "spearman": 0.7167033787127319, "kendall": 0.7167033787127319}, "p_value": {"pearson": 3.871751722167195e-165, "spearman": 3.8717517221846056e-165, "kendall": 2.0487495389583253e-118}, "kappa_score": 0.7166923203928481, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.7043363758902697, "spearman": 0.7043363758902712, "kendall": 0.7043363758902712}, "p_value": {"pearson": 4.1663311279075666e-157, "spearman": 4.1663311278985144e-157, "kendall": 1.9744405280301348e-114}, "kappa_score": 0.6876741989726579, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.7798462663266023, "spearman": 0.7798462663266065, "kendall": 0.7798462663266066}, "p_value": {"pearson": 5.1740700109726195e-214, "spearman": 5.174070010926188e-214, "kendall": 7.824782547685865e-140}, "kappa_score": 0.7790847089058022, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.305665444032724, "spearman": 0.3056654440327261, "kendall": 0.30566544403272616}, "p_value": {"pearson": 5.382359988325793e-24, "spearman": 5.3823599883215706e-24, "kendall": 5.793406489998097e-23}, "kappa_score": 0.2149430510977931, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.5427938540377313, "spearman": 0.5427938540377379, "kendall": 0.5427938540377379}, "p_value": {"pearson": 5.755371065286544e-81, "spearman": 5.755371065255613e-81, "kendall": 9.83761577369047e-69}, "kappa_score": 0.489553137823288, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.5984098537405306, "spearman": 0.5984098537405409, "kendall": 0.5984098537405408}, "p_value": {"pearson": 2.5358647405353623e-102, "spearman": 2.5358647405092846e-102, "kendall": 3.888338409475756e-83}, "kappa_score": 0.5715960688254271, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.27861295822963916, "spearman": 0.2786129582296428, "kendall": 0.2786129582296428}, "p_value": {"pearson": 4.7601029532245604e-20, "spearman": 4.7601029532187116e-20, "kendall": 2.3918974803393136e-19}, "kappa_score": 0.21897035881435245, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.36706939056314797, "spearman": 0.3670693905631482, "kendall": 0.3670693905631483}, "p_value": {"pearson": 1.2899235610437552e-34, "spearman": 1.2899235610435795e-34, "kendall": 2.1775055553972182e-32}, "kappa_score": 0.3264915477041581, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.4572143741380629, "spearman": 0.457214374138068, "kendall": 0.45721437413806804}, "p_value": {"pearson": 5.2412266698187485e-55, "spearman": 5.241226669802661e-55, "kendall": 2.6967748780181437e-49}, "kappa_score": 0.3789287504053297, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.39513415096835586, "spearman": 0.39513415096835164, "kendall": 0.39513415096835164}, "p_value": {"pearson": 2.632080377921259e-40, "spearman": 2.6320803779267877e-40, "kendall": 2.9259928152643397e-37}, "kappa_score": 0.34051556420233464, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.7831412379709227, "spearman": 0.7831412379709217, "kendall": 0.7831412379709216}, "p_value": {"pearson": 5.263843027061122e-217, "spearman": 5.263843027071491e-217, "kendall": 5.325614956945076e-141}, "kappa_score": 0.772215269086358, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.9149465246209703, "spearman": 0.9149465246209646, "kendall": 0.9149465246209645}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 1.0387497766346702e-191}, "kappa_score": 0.9149134041980405, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.5020411606322457, "spearman": 0.5020411606322486, "kendall": 0.5020411606322486}, "p_value": {"pearson": 1.1046564936484789e-67, "spearman": 1.1046564936463407e-67, "kendall": 4.581224420472318e-59}, "kappa_score": 0.4416651680600223, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.4303764442391581, "spearman": 0.4303764442391576, "kendall": 0.43037644423915755}, "p_value": {"pearson": 2.837128756778258e-48, "spearman": 2.8371287567795153e-48, "kendall": 7.027562325705772e-44}, "kappa_score": 0.41750826080886116, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.5276144255966168, "spearman": 0.527614425596622, "kendall": 0.5276144255966219}, "p_value": {"pearson": 8.322858572263938e-76, "spearman": 8.322858572231664e-76, "kendall": 4.803547396480532e-65}, "kappa_score": 0.5275092675892783, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.38339170204978623, "spearman": 0.3833917020497826, "kendall": 0.3833917020497827}, "p_value": {"pearson": 7.394647133657088e-38, "spearman": 7.394647133670141e-38, "kendall": 3.5294389712498696e-35}, "kappa_score": 0.31819532429252284, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.4246932913913074, "spearman": 0.42469329139130874, "kendall": 0.4246932913913087}, "p_value": {"pearson": 6.350362208906486e-47, "spearman": 6.350362208902606e-47, "kendall": 8.954955822874837e-43}, "kappa_score": 0.40141910575468254, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.3708051100815041, "spearman": 0.3708051100815093, "kendall": 0.37080511008150935}, "p_value": {"pearson": 2.4262749848682133e-35, "spearman": 2.4262749848626085e-35, "kendall": 5.127637080538109e-33}, "kappa_score": 0.3377534024716805, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.17258628290532357, "spearman": 0.1725862829053216, "kendall": 0.1725862829053216}, "p_value": {"pearson": 2.032408766950583e-08, "spearman": 2.0324087669512942e-08, "kendall": 2.531512477615123e-08}, "kappa_score": 0.1547485817929225, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.28645898716696916, "spearman": 0.2864589871669688, "kendall": 0.2864589871669689}, "p_value": {"pearson": 3.7727375611266496e-21, "spearman": 3.772737561127133e-21, "kendall": 2.310908814503197e-20}, "kappa_score": 0.2858897682192554, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.40362588381109427, "spearman": 0.40362588381109343, "kendall": 0.4036258838110935}, "p_value": {"pearson": 3.8626277446261954e-42, "spearman": 3.862627744627699e-42, "kendall": 8.363868673034482e-39}, "kappa_score": 0.3957244315407801, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.34269834548525707, "spearman": 0.34269834548525596, "kendall": 0.342698345485256}, "p_value": {"pearson": 4.1157446154134096e-30, "spearman": 4.11574461541509e-30, "kendall": 1.9110885398332343e-28}, "kappa_score": 0.26155371081650347, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.5324074919023096, "spearman": 0.53240749190231, "kendall": 0.5324074919023098}, "p_value": {"pearson": 2.085366708543152e-77, "spearman": 2.08536670854282e-77, "kendall": 3.373273426290175e-66}, "kappa_score": 0.5157122496194579, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.4543055973867485, "spearman": 0.45430559738675386, "kendall": 0.45430559738675386}, "p_value": {"pearson": 3.010711639162756e-54, "spearman": 3.0107116391528064e-54, "kendall": 1.080236195515372e-48}, "kappa_score": 0.4416777468874653, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.08822959617010692, "spearman": 0.08822959617010764, "kendall": 0.08822959617010766}, "p_value": {"pearson": 0.004350450738099859, "spearman": 0.004350450738099638, "kendall": 0.004398752220308943}, "kappa_score": 0.0840163934426229, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.3173658934554864, "spearman": 0.31736589345549215, "kendall": 0.3173658934554922}, "p_value": {"pearson": 7.761455020925405e-26, "spearman": 7.761455020908342e-26, "kendall": 1.2516872829541668e-24}, "kappa_score": 0.3172475190489906, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.2889691180398459, "spearman": 0.2889691180398506, "kendall": 0.28896911803985065}, "p_value": {"pearson": 1.648071552233049e-21, "spearman": 1.6480715522305095e-21, "kendall": 1.0795837815610609e-20}, "kappa_score": 0.16973404348819632, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.6113490469666005, "spearman": 0.611349046966592, "kendall": 0.6113490469665919}, "p_value": {"pearson": 6.5188345278075315e-108, "spearman": 6.518834527864294e-108, "kendall": 1.0931728635537239e-86}, "kappa_score": 0.5526890123609747, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.1786754297484106, "spearman": 0.1786754297484141, "kendall": 0.17867542974841408}, "p_value": {"pearson": 6.235679529542693e-09, "spearman": 6.2356795295386684e-09, "kendall": 8.038581649957622e-09}, "kappa_score": 0.09373601200663528, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.7619395394111532, "spearman": 0.7619395394111448, "kendall": 0.7619395394111447}, "p_value": {"pearson": 1.3029558042438394e-198, "spearman": 1.3029558042647572e-198, "kendall": 1.4138256070755263e-133}, "kappa_score": 0.7545324034486275, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.33338807447995067, "spearman": 0.3333880744799587, "kendall": 0.3333880744799587}, "p_value": {"pearson": 1.7089221618871698e-28, "spearman": 1.708922161881731e-28, "kendall": 5.215558869636736e-27}, "kappa_score": 0.23311690739379132, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.7561460266202105, "spearman": 0.7561460266202066, "kendall": 0.7561460266202067}, "p_value": {"pearson": 6.442861494619221e-194, "spearman": 6.442861494665139e-194, "kendall": 1.3922993631399725e-131}, "kappa_score": 0.7525650910384911, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.4374158985638699, "spearman": 0.437415898563865, "kendall": 0.4374158985638649}, "p_value": {"pearson": 5.555278237419008e-50, "spearman": 5.555278237434528e-50, "kendall": 2.868202167842661e-45}, "kappa_score": 0.3729458917835672, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.5852452206188354, "spearman": 0.5852452206188312, "kendall": 0.5852452206188313}, "p_value": {"pearson": 6.848629969691872e-97, "spearman": 6.848629969718675e-97, "kendall": 1.3340090019844982e-79}, "kappa_score": 0.5746946246692521, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.7878652203159564, "spearman": 0.7878652203159489, "kendall": 0.787865220315949}, "p_value": {"pearson": 2.1783993687490672e-221, "spearman": 2.178399368784546e-221, "kendall": 1.1080092579452376e-142}, "kappa_score": 0.7844977714808583, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.59550830293019, "spearman": 0.5955083029302014, "kendall": 0.5955083029302012}, "p_value": {"pearson": 4.196488041686269e-101, "spearman": 4.1964880416404254e-101, "kendall": 2.3752130832776426e-82}, "kappa_score": 0.5804055141339912, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.7974928382057842, "spearman": 0.7974928382057906, "kendall": 0.7974928382057906}, "p_value": {"pearson": 1.1159077963763105e-230, "spearman": 1.115907796359942e-230, "kendall": 3.8522518121539403e-146}, "kappa_score": 0.786411522446472, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.22918003748867052, "spearman": 0.22918003748866725, "kendall": 0.22918003748866728}, "p_value": {"pearson": 6.75462036650608e-14, "spearman": 6.754620366512044e-14, "kendall": 1.383161374586245e-13}, "kappa_score": 0.10911194996280271, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.423701891704265, "spearman": 0.4237018917042676, "kendall": 0.4237018917042676}, "p_value": {"pearson": 1.0855595028176791e-46, "spearman": 1.0855595028160763e-46, "kendall": 1.3911729931578506e-42}, "kappa_score": 0.3227941902974014, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.3429101627509493, "spearman": 0.34291016275095315, "kendall": 0.3429101627509532}, "p_value": {"pearson": 3.775591207727457e-30, "spearman": 3.775591207721852e-30, "kendall": 1.7707501059734795e-28}, "kappa_score": 0.21841088294795097, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.176533705583581, "spearman": 0.17653370558358006, "kendall": 0.17653370558358011}, "p_value": {"pearson": 9.493203036995907e-09, "spearman": 9.493203036997686e-09, "kendall": 1.2085735072151173e-08}, "kappa_score": 0.1388238108714489, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.3781635647726672, "spearman": 0.37816356477266755, "kendall": 0.3781635647726675}, "p_value": {"pearson": 8.46178205283025e-37, "spearman": 8.461782052829133e-37, "kendall": 2.847603422097845e-34}, "kappa_score": 0.3194951107317693, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.19926911537537256, "spearman": 0.19926911537537298, "kendall": 0.19926911537537295}, "p_value": {"pearson": 8.414077702013096e-11, "spearman": 8.414077702012703e-11, "kendall": 1.2559476232156323e-10}, "kappa_score": 0.16840366763483117, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.22567783383018747, "spearman": 0.2256778338301869, "kendall": 0.2256778338301869}, "p_value": {"pearson": 1.6436236882215563e-13, "spearman": 1.643623688221827e-13, "kendall": 3.219422547357573e-13}, "kappa_score": 0.1573394108213051, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.017429965898652984, "spearman": 0.017429965898653175, "kendall": 0.01742996589865318}, "p_value": {"pearson": 0.5739270614313104, "spearman": 0.5739270614313068, "kendall": 0.5736802315511622}, "kappa_score": 0.01034509494079816, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.4422038329350667, "spearman": 0.442203832935068, "kendall": 0.44220383293506804}, "p_value": {"pearson": 3.6280351986976014e-51, "spearman": 3.6280351986954435e-51, "kendall": 3.1621934007521e-46}, "kappa_score": 0.4163841990293874, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.25157284476633596, "spearman": 0.25157284476633685, "kendall": 0.25157284476633685}, "p_value": {"pearson": 1.6115304592021742e-16, "spearman": 1.6115304592018538e-16, "kendall": 4.632059299142353e-16}, "kappa_score": 0.1484630962857718, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.5115029475037874, "spearman": 0.5115029475037948, "kendall": 0.5115029475037949}, "p_value": {"pearson": 1.312569741589652e-70, "spearman": 1.3125697415827843e-70, "kendall": 3.0411763659240337e-61}, "kappa_score": 0.5010281417073028, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.4814501181173653, "spearman": 0.48145011811735816, "kendall": 0.4814501181173581}, "p_value": {"pearson": 1.2596979711803464e-61, "spearman": 1.2596979711862895e-61, "kendall": 1.8247131087495822e-54}, "kappa_score": 0.4765182476518248, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.27800132474231376, "spearman": 0.27800132474231454, "kendall": 0.2780013247423146}, "p_value": {"pearson": 5.780521758120508e-20, "spearman": 5.780521758119146e-20, "kendall": 2.862240172561316e-19}, "kappa_score": 0.2119501452765169, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.3782572967374649, "spearman": 0.3782572967374659, "kendall": 0.3782572967374659}, "p_value": {"pearson": 8.103137507509291e-37, "spearman": 8.103137507504934e-37, "kendall": 2.7436627588861933e-34}, "kappa_score": 0.3045410653875058, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.38713347658532626, "spearman": 0.38713347658532604, "kendall": 0.38713347658532604}, "p_value": {"pearson": 1.257246293416426e-38, "spearman": 1.2572462934165407e-38, "kendall": 7.783622817270729e-36}, "kappa_score": 0.336835112692764, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.26786934353890623, "spearman": 0.26786934353890685, "kendall": 0.26786934353890685}, "p_value": {"pearson": 1.3446156060133233e-18, "spearman": 1.3446156060130627e-18, "kendall": 5.295020300247955e-18}, "kappa_score": 0.18605470775706245, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.8189516704863116, "spearman": 0.8189516704863178, "kendall": 0.8189516704863177}, "p_value": {"pearson": 2.50386221607945e-253, "spearman": 2.503862216039289e-253, "kendall": 5.317114769942496e-154}, "kappa_score": 0.8128272149182694, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.5193245383906492, "spearman": 0.5193245383906484, "kendall": 0.5193245383906485}, "p_value": {"pearson": 4.261913815650007e-73, "spearman": 4.2619138156522875e-73, "kendall": 4.4891990437952435e-63}, "kappa_score": 0.48709002093510123, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.4285314575492399, "spearman": 0.4285314575492392, "kendall": 0.42853145754923927}, "p_value": {"pearson": 7.833364750664763e-48, "spearman": 7.833364750667484e-48, "kendall": 1.6114305235976824e-43}, "kappa_score": 0.4013218315402781, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.09936289390469111, "spearman": 0.09936289390468925, "kendall": 0.09936289390468926}, "p_value": {"pearson": 0.0013131893446974316, "spearman": 0.0013131893446977042, "kendall": 0.0013392353985080417}, "kappa_score": 0.04300801129622189, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.0802778842617331, "spearman": 0.08027788426173244, "kendall": 0.08027788426173245}, "p_value": {"pearson": 0.009495112300428295, "spearman": 0.009495112300428923, "kendall": 0.00955940696505364}, "kappa_score": 0.06774396831112706, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.7581005677431183, "spearman": 0.7581005677431106, "kendall": 0.7581005677431107}, "p_value": {"pearson": 1.7388742034328884e-195, "spearman": 1.7388742034575333e-195, "kendall": 2.971263564454094e-132}, "kappa_score": 0.7563774432577764, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.3886606544967585, "spearman": 0.38866065449675574, "kendall": 0.3886606544967557}, "p_value": {"pearson": 6.06007934117572e-39, "spearman": 6.060079341183571e-39, "kendall": 4.182316945437289e-36}, "kappa_score": 0.3783292028735452, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.7581643395472217, "spearman": 0.7581643395472276, "kendall": 0.7581643395472276}, "p_value": {"pearson": 1.544648967995384e-195, "spearman": 1.5446489679784784e-195, "kendall": 2.8250481205676715e-132}, "kappa_score": 0.7495557796667147, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.21277525824263377, "spearman": 0.2127752582426339, "kendall": 0.2127752582426339}, "p_value": {"pearson": 3.835881316099037e-12, "spearman": 3.835881316098903e-12, "kendall": 6.493023365129972e-12}, "kappa_score": 0.14434095448470996, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.6596685697840416, "spearman": 0.6596685697840482, "kendall": 0.6596685697840484}, "p_value": {"pearson": 2.8144288447597506e-131, "spearman": 2.814428844737249e-131, "kendall": 1.2870691976407256e-100}, "kappa_score": 0.658710066305003, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.40957713517626615, "spearman": 0.40957713517626, "kendall": 0.40957713517626}, "p_value": {"pearson": 1.861685154926952e-43, "spearman": 1.861685154933011e-43, "kendall": 6.623445346086895e-40}, "kappa_score": 0.4056189806811922, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.5464532336364673, "spearman": 0.5464532336364707, "kendall": 0.5464532336364706}, "p_value": {"pearson": 2.993467314057717e-82, "spearman": 2.993467314048815e-82, "kendall": 1.2248855677442616e-69}, "kappa_score": 0.5323448467794304, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.6367366400010659, "spearman": 0.6367366400010626, "kendall": 0.6367366400010627}, "p_value": {"pearson": 1.1477581659530495e-119, "spearman": 1.1477581659572362e-119, "kendall": 7.10590273738984e-94}, "kappa_score": 0.6192082391085197, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.21025832920186113, "spearman": 0.21025832920186133, "kendall": 0.21025832920186133}, "p_value": {"pearson": 6.930909712793784e-12, "spearman": 6.930909712793715e-12, "kendall": 1.1437497619013668e-11}, "kappa_score": 0.10127677527539514, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.20768320778204769, "spearman": 0.20768320778204907, "kendall": 0.2076832077820491}, "p_value": {"pearson": 1.2598671536881144e-11, "spearman": 1.259867153687803e-11, "kendall": 2.0276375023145316e-11}, "kappa_score": 0.0897057936332375, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.3105069173096797, "spearman": 0.3105069173096813, "kendall": 0.3105069173096813}, "p_value": {"pearson": 9.532468985906623e-25, "spearman": 9.532468985901659e-25, "kendall": 1.2057122553718254e-23}, "kappa_score": 0.23106341607265446, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.1313528905345162, "spearman": 0.1313528905345161, "kendall": 0.1313528905345161}, "p_value": {"pearson": 2.086084011443794e-05, "spearman": 2.086084011443854e-05, "kendall": 2.234455528743059e-05}, "kappa_score": 0.07504277988034114, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.22493301345794303, "spearman": 0.22493301345793998, "kendall": 0.22493301345793998}, "p_value": {"pearson": 1.9820440681846162e-13, "spearman": 1.9820440681859885e-13, "kendall": 3.8468453636322895e-13}, "kappa_score": 0.13195274250617228, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.15804332115207698, "spearman": 0.15804332115207795, "kendall": 0.15804332115207792}, "p_value": {"pearson": 2.8936709257568233e-07, "spearman": 2.893670925756344e-07, "kendall": 3.3671866231144854e-07}, "kappa_score": 0.054518443448919096, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.22854228829455425, "spearman": 0.22854228829455134, "kendall": 0.22854228829455137}, "p_value": {"pearson": 7.950680919819276e-14, "spearman": 7.950680919825034e-14, "kendall": 1.6147024230648883e-13}, "kappa_score": 0.11867054169280589, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.6426207732609912, "spearman": 0.6426207732609996, "kendall": 0.6426207732609998}, "p_value": {"pearson": 1.498094295380658e-122, "spearman": 1.4980942953662683e-122, "kendall": 1.3941906411842253e-95}, "kappa_score": 0.6123718092602746, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8546087131694394, "spearman": 0.8546087131694523, "kendall": 0.8546087131694523}, "p_value": {"pearson": 1.5407652447350953e-298, "spearman": 1.5407652446685372e-298, "kendall": 1.6028270728688227e-167}, "kappa_score": 0.8535903729257679, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.4171341183238293, "spearman": 0.41713411832383424, "kendall": 0.41713411832383424}, "p_value": {"pearson": 3.6203937345334325e-45, "spearman": 3.620393734524142e-45, "kendall": 2.509793001752167e-41}, "kappa_score": 0.3652225571062695, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.156610274134523, "spearman": 0.15661027413452377, "kendall": 0.15661027413452377}, "p_value": {"pearson": 3.712448390783198e-07, "spearman": 3.7124483907826856e-07, "kendall": 4.2952669657537295e-07}, "kappa_score": 0.07845166145380156, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.3647164167882969, "spearman": 0.3647164167882985, "kendall": 0.3647164167882985}, "p_value": {"pearson": 3.653528075147522e-34, "spearman": 3.653528075144686e-34, "kendall": 5.374241524232925e-32}, "kappa_score": 0.2909405119668601, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.22071546419794102, "spearman": 0.22071546419794208, "kendall": 0.22071546419794202}, "p_value": {"pearson": 5.650839277693761e-13, "spearman": 5.650839277692303e-13, "kendall": 1.0430713202401995e-12}, "kappa_score": 0.12023065501881836, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.2126237559959856, "spearman": 0.21262375599598687, "kendall": 0.21262375599598687}, "p_value": {"pearson": 3.975772961477629e-12, "spearman": 3.975772961476358e-12, "kendall": 6.719347156569896e-12}, "kappa_score": 0.12355195801857277, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.2501754064415656, "spearman": 0.25017540644156816, "kendall": 0.2501754064415682}, "p_value": {"pearson": 2.3918407187788065e-16, "spearman": 2.3918407187770346e-16, "kendall": 6.710806605918294e-16}, "kappa_score": 0.18329526916802608, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.07535935877740449, "spearman": 0.07535935877740421, "kendall": 0.07535935877740421}, "p_value": {"pearson": 0.014920098537355656, "spearman": 0.014920098537355455, "kendall": 0.014990769866918928}, "kappa_score": 0.07532976922870271, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.08680943422277365, "spearman": 0.08680943422277361, "kendall": 0.08680943422277362}, "p_value": {"pearson": 0.005024002733441413, "spearman": 0.005024002733441523, "kendall": 0.005075371591529056}, "kappa_score": 0.02728829413802325, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.1563392710418818, "spearman": 0.1563392710418809, "kendall": 0.1563392710418809}, "p_value": {"pearson": 3.8905869821861206e-07, "spearman": 3.890586982186716e-07, "kendall": 4.4965792493173074e-07}, "kappa_score": 0.1124717895593621, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.10789751093682687, "spearman": 0.10789751093682681, "kendall": 0.1078975109368268}, "p_value": {"pearson": 0.00048189828062664483, "spearman": 0.00048189828062666657, "kendall": 0.0004959500112743455}, "kappa_score": 0.034255213068598356, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.40637976143393917, "spearman": 0.40637976143393884, "kendall": 0.4063797614339388}, "p_value": {"pearson": 9.567172264075393e-43, "spearman": 9.567172264076993e-43, "kendall": 2.5987400843122225e-39}, "kappa_score": 0.35339854450616737, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.1340802247135231, "spearman": 0.13408022471352496, "kendall": 0.13408022471352496}, "p_value": {"pearson": 1.3951174389498477e-05, "spearman": 1.3951174389494213e-05, "kendall": 1.5039232405782828e-05}, "kappa_score": 0.10967089538518116, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.06161678706823425, "spearman": 0.06161678706823443, "kendall": 0.061616787068234424}, "p_value": {"pearson": 0.0466515616023011, "spearman": 0.04665156160230048, "kendall": 0.046702150715065845}, "kappa_score": 0.05539970400477123, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.13343581016479478, "spearman": 0.1334358101647957, "kendall": 0.13343581016479572}, "p_value": {"pearson": 1.5353279297661625e-05, "spearman": 1.5353279297659738e-05, "kendall": 1.6525099618542943e-05}, "kappa_score": 0.10372710920862305, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.15513158877086197, "spearman": 0.15513158877086292, "kendall": 0.15513158877086294}, "p_value": {"pearson": 4.789622525587517e-07, "spearman": 4.789622525586647e-07, "kendall": 5.509817104839064e-07}, "kappa_score": 0.06150047439957029, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.30536443862696994, "spearman": 0.30536443862696894, "kendall": 0.30536443862696894}, "p_value": {"pearson": 5.987538385971426e-24, "spearman": 5.9875383859730976e-24, "kendall": 6.382184557313308e-23}, "kappa_score": 0.1829719058884659, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.06494812231433683, "spearman": 0.06494812231433764, "kendall": 0.06494812231433764}, "p_value": {"pearson": 0.03597303153622874, "spearman": 0.035973031536226545, "kendall": 0.03603546755129775}, "kappa_score": 0.016694265330765123, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.764001895321718, "spearman": 0.764001895321726, "kendall": 0.7640018953217259}, "p_value": {"pearson": 2.5784326990658736e-200, "spearman": 2.578432699026448e-200, "kendall": 2.736241348839226e-134}, "kappa_score": 0.7612854584864763, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.2521884537702139, "spearman": 0.25218845377021976, "kendall": 0.2521884537702197}, "p_value": {"pearson": 1.3531798228782865e-16, "spearman": 1.3531798228761105e-16, "kendall": 3.931629112510787e-16}, "kappa_score": 0.12806872641734446, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.2675333895528903, "spearman": 0.26753338955289113, "kendall": 0.2675333895528911}, "p_value": {"pearson": 1.4891142446858732e-18, "spearman": 1.489114244685326e-18, "kendall": 5.822343460689624e-18}, "kappa_score": 0.16088050006471177, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.17450323567379233, "spearman": 0.1745032356737924, "kendall": 0.17450323567379242}, "p_value": {"pearson": 1.4073641014139096e-08, "spearman": 1.4073641014138797e-08, "kendall": 1.771335421713827e-08}, "kappa_score": 0.07007092198581566, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.5968339939328117, "spearman": 0.596833993932811, "kendall": 0.5968339939328111}, "p_value": {"pearson": 1.1683979496113266e-101, "spearman": 1.1683979496122424e-101, "kendall": 1.0401265331146837e-82}, "kappa_score": 0.5955628197484124, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.3492891563182058, "spearman": 0.3492891563181963, "kendall": 0.3492891563181963}, "p_value": {"pearson": 2.7234771923359445e-31, "spearman": 2.723477192346513e-31, "kendall": 1.7425458751471117e-29}, "kappa_score": 0.34192720231490537, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.4910597018308018, "spearman": 0.4910597018308057, "kendall": 0.4910597018308057}, "p_value": {"pearson": 2.1131496160188144e-64, "spearman": 2.1131496160133575e-64, "kendall": 1.3744122731566765e-56}, "kappa_score": 0.4161917362100549, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.6990954384437889, "spearman": 0.6990954384437928, "kendall": 0.6990954384437927}, "p_value": {"pearson": 7.918926541181259e-154, "spearman": 7.918926541135952e-154, "kendall": 9.182048925794076e-113}, "kappa_score": 0.6935057302380252, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.17075128837799985, "spearman": 0.1707512883779985, "kendall": 0.1707512883779985}, "p_value": {"pearson": 2.8782707353915955e-08, "spearman": 2.8782707353924686e-08, "kendall": 3.550697361974373e-08}, "kappa_score": 0.07438935841989847, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.34578015445978627, "spearman": 0.34578015445978805, "kendall": 0.34578015445978805}, "p_value": {"pearson": 1.1655177425361473e-30, "spearman": 1.165517742535258e-30, "kendall": 6.271455229328261e-29}, "kappa_score": 0.22598780324169798, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.2673861268770993, "spearman": 0.2673861268770998, "kendall": 0.26738612687709973}, "p_value": {"pearson": 1.5571837189152915e-18, "spearman": 1.557183718915023e-18, "kendall": 6.0695268419690655e-18}, "kappa_score": 0.14362000950717058, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": 0.3498341667706236, "spearman": 0.3498341667706209, "kendall": 0.3498341667706209}, "p_value": {"pearson": 2.1693780929503917e-31, "spearman": 2.1693780929527253e-31, "kendall": 1.4266018196426625e-29}, "kappa_score": 0.3359323816817842, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.46529896818116284, "spearman": 0.4652989681811596, "kendall": 0.4652989681811596}, "p_value": {"pearson": 3.717758741200115e-57, "spearman": 3.7177587412073515e-57, "kendall": 5.442070955236069e-51}, "kappa_score": 0.404946227828194, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": 0.11601351305734249, "spearman": 0.1160135130573426, "kendall": 0.11601351305734256}, "p_value": {"pearson": 0.00017340497335301374, "spearman": 0.0001734049733530107, "kendall": 0.00018045193035020482}, "kappa_score": 0.041046841766189224, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.24678720507210353, "spearman": 0.24678720507210486, "kendall": 0.24678720507210478}, "p_value": {"pearson": 6.168176448172656e-16, "spearman": 6.168176448171101e-16, "kendall": 1.6349959384205704e-15}, "kappa_score": 0.1585122072796601, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.08573357177754534, "spearman": 0.0857335717775461, "kendall": 0.0857335717775461}, "p_value": {"pearson": 0.005595452270084803, "spearman": 0.005595452270084518, "kendall": 0.005649119582057763}, "kappa_score": 0.04415460022585782, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.3256244323214356, "spearman": 0.32562443232143595, "kendall": 0.32562443232143595}, "p_value": {"pearson": 3.469144110653279e-27, "spearman": 3.469144110653097e-27, "kendall": 7.673985337864476e-26}, "kappa_score": 0.21127778721646473, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.15881839294687655, "spearman": 0.15881839294687555, "kendall": 0.15881839294687558}, "p_value": {"pearson": 2.526490561060426e-07, "spearman": 2.5264905610607716e-07, "kendall": 2.94924825846097e-07}, "kappa_score": 0.05452178069322422, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.5523203431040337, "spearman": 0.5523203431040314, "kendall": 0.5523203431040316}, "p_value": {"pearson": 2.422584269029103e-84, "spearman": 2.4225842690331137e-84, "kendall": 4.215269145787236e-71}, "kappa_score": 0.5015833370500871, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.47475553175401963, "spearman": 0.47475553175401386, "kendall": 0.4747555317540138}, "p_value": {"pearson": 9.59737923877556e-60, "spearman": 9.597379238810236e-60, "kendall": 5.195823836300683e-53}, "kappa_score": 0.3982149095091001, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.16561535638084018, "spearman": 0.1656153563808412, "kendall": 0.1656153563808412}, "p_value": {"pearson": 7.473097116530574e-08, "spearman": 7.473097116529228e-08, "kendall": 8.988554585283071e-08}, "kappa_score": 0.0712987986460707, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": 0.30175536163924144, "spearman": 0.3017553616392442, "kendall": 0.3017553616392442}, "p_value": {"pearson": 2.1276210540064117e-23, "spearman": 2.12762105400416e-23, "kendall": 2.0221555261457574e-22}, "kappa_score": 0.1938380806477329, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.38092727900437584, "spearman": 0.38092727900437817, "kendall": 0.3809272790043781}, "p_value": {"pearson": 2.3458094728641044e-37, "spearman": 2.3458094728614625e-37, "kendall": 9.476962916558588e-35}, "kappa_score": 0.2871528189737429, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.1950481103576649, "spearman": 0.1950481103576658, "kendall": 0.1950481103576658}, "p_value": {"pearson": 2.1152047805233607e-10, "spearman": 2.1152047805229618e-10, "kendall": 3.051137018310839e-10}, "kappa_score": 0.07594464322340977, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.8307123157814112, "spearman": 0.8307123157814245, "kendall": 0.8307123157814245}, "p_value": {"pearson": 4.642358301249506e-267, "spearman": 4.642358301079345e-267, "kendall": 2.136294518892242e-158}, "kappa_score": 0.8166261318017991, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.6497526626489152, "spearman": 0.6497526626489151, "kendall": 0.6497526626489152}, "p_value": {"pearson": 3.921072829918719e-126, "spearman": 3.9210728299191356e-126, "kendall": 1.132476540364053e-97}, "kappa_score": 0.6044169457911981, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.2943025526073032, "spearman": 0.29430255260730354, "kendall": 0.29430255260730354}, "p_value": {"pearson": 2.7581781256826423e-22, "spearman": 2.7581781256822435e-22, "kendall": 2.097015413330295e-21}, "kappa_score": 0.19244214014645356, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.07132756406447255, "spearman": 0.07132756406447162, "kendall": 0.07132756406447163}, "p_value": {"pearson": 0.02123766097987132, "spearman": 0.021237660979873566, "kendall": 0.021309496183153052}, "kappa_score": 0.028127686614585423, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.10463362855370757, "spearman": 0.10463362855370587, "kendall": 0.10463362855370588}, "p_value": {"pearson": 0.0007132406334740454, "spearman": 0.0007132406334742067, "kendall": 0.0007312770935125111}, "kappa_score": 0.042750281382909816, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.751925600817184, "spearman": 0.7519256008171784, "kendall": 0.7519256008171783}, "p_value": {"pearson": 1.4009434024123616e-190, "spearman": 1.400943402426631e-190, "kendall": 3.8572746913451946e-130}, "kappa_score": 0.7389046803837334, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.6361618038279271, "spearman": 0.6361618038279225, "kendall": 0.6361618038279225}, "p_value": {"pearson": 2.179015829719966e-119, "spearman": 2.1790158297310782e-119, "kendall": 1.0412892245313029e-93}, "kappa_score": 0.6356402592865737, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.6467417103503798, "spearman": 0.6467417103503783, "kendall": 0.6467417103503783}, "p_value": {"pearson": 1.310515367972898e-124, "spearman": 1.3105153679751485e-124, "kendall": 8.695879973844348e-97}, "kappa_score": 0.6324597345346756, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.318240646597453, "spearman": 0.3182406465974513, "kendall": 0.3182406465974514}, "p_value": {"pearson": 5.610037829527872e-26, "spearman": 5.610037829531278e-26, "kendall": 9.343675148583504e-25}, "kappa_score": 0.20349167121863776, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.568185699762205, "spearman": 0.568185699762202, "kendall": 0.568185699762202}, "p_value": {"pearson": 3.267709219767884e-90, "spearman": 3.2677092197760975e-90, "kendall": 3.892176740213342e-75}, "kappa_score": 0.4984617611929495, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.595086364890007, "spearman": 0.5950863648899977, "kendall": 0.5950863648899977}, "p_value": {"pearson": 6.296246139538966e-101, "spearman": 6.296246139594386e-101, "kendall": 3.087989529291926e-82}, "kappa_score": 0.5387741636601013, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.5814268294550575, "spearman": 0.5814268294550574, "kendall": 0.5814268294550575}, "p_value": {"pearson": 2.3166954848263826e-95, "spearman": 2.3166954848267735e-95, "kendall": 1.3676160780325045e-78}, "kappa_score": 0.5240829883706113, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.5728366788009233, "spearman": 0.572836678800915, "kendall": 0.5728366788009152}, "p_value": {"pearson": 5.3977539354603114e-92, "spearman": 5.397753935499251e-92, "kendall": 2.4316470502721357e-76}, "kappa_score": 0.5100212439562815, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": 0.21392448576766623, "spearman": 0.2139244857676678, "kendall": 0.2139244857676678}, "p_value": {"pearson": 2.9206528653848608e-12, "spearman": 2.9206528653837916e-12, "kendall": 5.003124287657627e-12}, "kappa_score": 0.10445934342973029, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.1543424156455085, "spearman": 0.15434241564550782, "kendall": 0.15434241564550782}, "p_value": {"pearson": 5.481864604369351e-07, "spearman": 5.48186460436974e-07, "kendall": 6.287288272341588e-07}, "kappa_score": 0.051411606940457655, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.36397866636641174, "spearman": 0.3639786663664119, "kendall": 0.36397866636641196}, "p_value": {"pearson": 5.054806433223082e-34, "spearman": 5.054806433222292e-34, "kendall": 7.125650958888076e-32}, "kappa_score": 0.24305573704578587, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.1716208779864087, "spearman": 0.17162087798640993, "kendall": 0.17162087798640993}, "p_value": {"pearson": 2.4418498553693143e-08, "spearman": 2.44184985536877e-08, "kendall": 3.025991496292213e-08}, "kappa_score": 0.06900418274231501, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.2330784159859556, "spearman": 0.23307841598595502, "kendall": 0.2330784159859551}, "p_value": {"pearson": 2.4670148157663068e-14, "spearman": 2.4670148157664548e-14, "kendall": 5.3216062295424176e-14}, "kappa_score": 0.12046458808846505, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.21666460226828, "spearman": 0.21666460226828135, "kendall": 0.21666460226828133}, "p_value": {"pearson": 1.5152661121257592e-12, "spearman": 1.5152661121251966e-12, "kendall": 2.672743168327768e-12}, "kappa_score": 0.10082573379851023, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.196010193052978, "spearman": 0.1960101930529778, "kendall": 0.19601019305297776}, "p_value": {"pearson": 1.7174492766972634e-10, "spearman": 1.7174492766973911e-10, "kendall": 2.4962723285944815e-10}, "kappa_score": 0.09053384625767702, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.5331161566860422, "spearman": 0.5331161566860485, "kendall": 0.5331161566860485}, "p_value": {"pearson": 1.2030095034272777e-77, "spearman": 1.2030095034212996e-77, "kendall": 2.2731252957254913e-66}, "kappa_score": 0.4426257524258018, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.8965736042122375, "spearman": 0.8965736042122492, "kendall": 0.8965736042122492}, "p_value": {"pearson": 0.0, "spearman": 0.0, "kendall": 3.5986509164183555e-184}, "kappa_score": 0.8959443227302294, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.42714901865856975, "spearman": 0.42714901865857113, "kendall": 0.42714901865857113}, "p_value": {"pearson": 1.6697533612648852e-47, "spearman": 1.6697533612635998e-47, "kendall": 2.9940438083113195e-43}, "kappa_score": 0.32267946636549727, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.08988633011664612, "spearman": 0.08988633011664665, "kendall": 0.08988633011664665}, "p_value": {"pearson": 0.003668699018139121, "spearman": 0.00366869901813879, "kendall": 0.0037134170801749935}, "kappa_score": 0.04280670099083839, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.41217098923207895, "spearman": 0.4121709892320835, "kendall": 0.41217098923208356}, "p_value": {"pearson": 4.869757457589724e-44, "spearman": 4.869757457578328e-44, "kendall": 2.1681271303032375e-40}, "kappa_score": 0.33851997758456953, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.22960840149752787, "spearman": 0.22960840149752765, "kendall": 0.22960840149752768}, "p_value": {"pearson": 6.052354320245645e-14, "spearman": 6.05235432024585e-14, "kendall": 1.2462956270437384e-13}, "kappa_score": 0.1461656279708462, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.21787992784081942, "spearman": 0.2178799278408198, "kendall": 0.21787992784081978}, "p_value": {"pearson": 1.1294186851443436e-12, "spearman": 1.1294186851442745e-12, "kendall": 2.0189389478426743e-12}, "kappa_score": 0.10062145044750381, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.184117395247067, "spearman": 0.1841173952470685, "kendall": 0.18411739524706852}, "p_value": {"pearson": 2.094321593533317e-09, "spearman": 2.0943215935326234e-09, "kendall": 2.7931651505085865e-09}, "kappa_score": 0.08017986026024249, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.12277450569118507, "spearman": 0.12277450569118441, "kendall": 0.12277450569118442}, "p_value": {"pearson": 7.02731547177747e-05, "spearman": 7.027315471778322e-05, "kendall": 7.396290794234057e-05}, "kappa_score": 0.037007565518728525, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.04040891291224498, "spearman": 0.04040891291224481, "kendall": 0.04040891291224482}, "p_value": {"pearson": 0.1922355625576051, "spearman": 0.1922355625576113, "kendall": 0.19209699315536277}, "kappa_score": 0.007331865183413333, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.11365938239046322, "spearman": 0.11365938239046326, "kendall": 0.11365938239046326}, "p_value": {"pearson": 0.00023487526717710244, "spearman": 0.00023487526717711488, "kendall": 0.00024356996237982664}, "kappa_score": 0.06691029182123232, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.07468991511675217, "spearman": 0.07468991511675283, "kendall": 0.0746899151167528}, "p_value": {"pearson": 0.015838019175036012, "spearman": 0.01583801917503495, "kendall": 0.01590918383354122}, "kappa_score": 0.017173662746279406, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.3187505664628933, "spearman": 0.3187505664628932, "kendall": 0.3187505664628931}, "p_value": {"pearson": 4.6405528673019203e-26, "spearman": 4.64055286730185e-26, "kendall": 7.8766228935459745e-25}, "kappa_score": 0.1990008706264328, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.10100756250779495, "spearman": 0.10100756250779569, "kendall": 0.1010075625077957}, "p_value": {"pearson": 0.0010887178486000473, "spearman": 0.0010887178485999474, "kendall": 0.0011120552760291581}, "kappa_score": 0.08683909836917003, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.06492148881281237, "spearman": 0.06492148881281225, "kendall": 0.06492148881281225}, "p_value": {"pearson": 0.03604935566024983, "spearman": 0.03604935566024927, "kendall": 0.03611171741644833}, "kappa_score": 0.04204066296497322, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.0634368510970219, "spearman": 0.0634368510970228, "kendall": 0.0634368510970228}, "p_value": {"pearson": 0.04052746573917827, "spearman": 0.04052746573917603, "kendall": 0.04058517579666746}, "kappa_score": 0.05736267640992765, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.17984001853100748, "spearman": 0.17984001853100764, "kendall": 0.17984001853100764}, "p_value": {"pearson": 4.951032518794609e-09, "spearman": 4.9510325187943066e-09, "kendall": 6.427377298042179e-09}, "kappa_score": 0.07362049714990881, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": 0.284482266807894, "spearman": 0.2844822668078951, "kendall": 0.28448226680789507}, "p_value": {"pearson": 7.200296892942998e-21, "spearman": 7.200296892941088e-21, "kendall": 4.188769854870934e-20}, "kappa_score": 0.16129866027196615, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.11852704883316705, "spearman": 0.11852704883316834, "kendall": 0.11852704883316836}, "p_value": {"pearson": 0.00012463078784373885, "spearman": 0.00012463078784371754, "kendall": 0.0001302126413101852}, "kappa_score": 0.027708061439614573, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.6887578514681854, "spearman": 0.6887578514681791, "kendall": 0.688757851468179}, "p_value": {"pearson": 1.4491896157273116e-147, "spearman": 1.4491896157396116e-147, "kendall": 1.6430658057374886e-109}, "kappa_score": 0.6511908150940684, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.28223301097090014, "spearman": 0.2822330109709028, "kendall": 0.2822330109709028}, "p_value": {"pearson": 1.492859239892392e-20, "spearman": 1.4928592398911736e-20, "kendall": 8.20117921944297e-20}, "kappa_score": 0.15221755496154066, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.463265247138239, "spearman": 0.46326524713824396, "kendall": 0.4632652471382441}, "p_value": {"pearson": 1.307236118247922e-56, "spearman": 1.3072361182439004e-56, "kendall": 1.4619838723542777e-50}, "kappa_score": 0.38276527730041376, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.18482313343758683, "spearman": 0.18482313343758672, "kendall": 0.18482313343758672}, "p_value": {"pearson": 1.8135662547813939e-09, "spearman": 1.8135662547814969e-09, "kendall": 2.4299835073990253e-09}, "kappa_score": 0.0699008999368429, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.6186296199178519, "spearman": 0.6186296199178491, "kendall": 0.6186296199178494}, "p_value": {"pearson": 3.575759118873491e-111, "spearman": 3.5757591188845996e-111, "kendall": 1.0170909627651874e-88}, "kappa_score": 0.6172361217780165, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": 0.726028857550548, "spearman": 0.7260288575505388, "kendall": 0.7260288575505388}, "p_value": {"pearson": 1.74042070798179e-171, "spearman": 1.7404207080074947e-171, "kendall": 1.8266477132496252e-121}, "kappa_score": 0.722925706189675, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.3165161006564393, "spearman": 0.3165161006564414, "kendall": 0.31651610065644137}, "p_value": {"pearson": 1.0627960035562807e-25, "spearman": 1.0627960035553471e-25, "kendall": 1.6615833473314985e-24}, "kappa_score": 0.18880114564601025, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.7702806424355007, "spearman": 0.7702806424355156, "kendall": 0.7702806424355156}, "p_value": {"pearson": 1.3045099306074967e-205, "spearman": 1.3045099305690335e-205, "kendall": 1.794291763751875e-136}, "kappa_score": 0.7701124090808904, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.1537565352070525, "spearman": 0.1537565352070513, "kendall": 0.1537565352070513}, "p_value": {"pearson": 6.057078373348466e-07, "spearman": 6.057078373349524e-07, "kendall": 6.931798349670403e-07}, "kappa_score": 0.049414040376756896, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.2872466325225984, "spearman": 0.28724663252259847, "kendall": 0.28724663252259847}, "p_value": {"pearson": 2.911956920446736e-21, "spearman": 2.911956920446433e-21, "kendall": 1.821258905859061e-20}, "kappa_score": 0.15611274262181385, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.22913359545063589, "spearman": 0.2291335954506375, "kendall": 0.2291335954506375}, "p_value": {"pearson": 6.835403351848089e-14, "spearman": 6.835403351845536e-14, "kendall": 1.3988592474289586e-13}, "kappa_score": 0.10592499106701225, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Simple": {"corr_coeff": {"pearson": -0.07139389578165302, "spearman": -0.07139389578165256, "kendall": -0.07139389578165256}, "p_value": {"pearson": 0.021117315160239722, "spearman": 0.02111731516024016, "kendall": 0.021189169556259522}, "kappa_score": -0.06083619251685013, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Copula": {"corr_coeff": {"pearson": 0.06341145819078585, "spearman": 0.06341145819078607, "kendall": 0.06341145819078606}, "p_value": {"pearson": 0.040607980430430346, "spearman": 0.0406079804304294, "kendall": 0.04066560203042417}, "kappa_score": 0.06289941228129436, "total_responses": 1043, "valid_responses": 1022, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Pred/SC": {"corr_coeff": {"pearson": -0.04693297693134058, "spearman": -0.046932976931341235, "kendall": -0.04693297693134122}, "p_value": {"pearson": 0.12983784512350077, "spearman": 0.1298378451234964, "kendall": 0.1297729970895283}, "kappa_score": -0.0338147895855343, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Result/Depictive": {"corr_coeff": {"pearson": 0.04700926527970854, "spearman": 0.04700926527970796, "kendall": 0.047009265279707946}, "p_value": {"pearson": 0.1292145465624818, "spearman": 0.12921454656248363, "kendall": 0.1291505225758256}, "kappa_score": 0.04397232581208166, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Particle": {"corr_coeff": {"pearson": 0.0319267648222174, "spearman": 0.03192676482221779, "kendall": 0.03192676482221779}, "p_value": {"pearson": 0.3029549153891295, "spearman": 0.3029549153891416, "kendall": 0.30272995623628307}, "kappa_score": 0.030902646340204343, "total_responses": 1043, "valid_responses": 1034, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP Adjunct": {"corr_coeff": {"pearson": 0.17280615512902456, "spearman": 0.17280615512902403, "kendall": 0.17280615512902403}, "p_value": {"pearson": 1.9489229159609714e-08, "spearman": 1.9489229159612063e-08, "kendall": 2.430383497738701e-08}, "kappa_score": 0.1721792408743963, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NP Adjunct": {"corr_coeff": {"pearson": 0.0973211674436758, "spearman": 0.09732116744367571, "kendall": 0.09732116744367571}, "p_value": {"pearson": 0.0016510159547484192, "spearman": 0.001651015954748381, "kendall": 0.001680677635560967}, "kappa_score": 0.07645951359576353, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Temporal": {"corr_coeff": {"pearson": 0.14453286233456508, "spearman": 0.14453286233456586, "kendall": 0.14453286233456586}, "p_value": {"pearson": 2.7751721071431565e-06, "spearman": 2.775172107142771e-06, "kendall": 3.0783099558612403e-06}, "kappa_score": 0.13774047234242226, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Locative": {"corr_coeff": {"pearson": 0.07523161522008884, "spearman": 0.07523161522008806, "kendall": 0.07523161522008807}, "p_value": {"pearson": 0.015091554421875406, "spearman": 0.015091554421877469, "kendall": 0.015162328095200376}, "kappa_score": 0.07515624776533503, "total_responses": 1043, "valid_responses": 1030, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Misc": {"corr_coeff": {"pearson": 0.1437567762443619, "spearman": 0.1437567762443624, "kendall": 0.1437567762443624}, "p_value": {"pearson": 3.1412218197981936e-06, "spearman": 3.141221819798072e-06, "kendall": 3.476137720259705e-06}, "kappa_score": 0.13071773728775982, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Oblique": {"corr_coeff": {"pearson": -0.013266396012878268, "spearman": -0.013266396012878157, "kendall": -0.013266396012878158}, "p_value": {"pearson": 0.6686874477198587, "spearman": 0.6686874477198621, "kendall": 0.6684766939373251}, "kappa_score": -0.011509095292951521, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PP Arg-VP": {"corr_coeff": {"pearson": 0.2901411490046676, "spearman": 0.2901411490046672, "kendall": 0.2901411490046672}, "p_value": {"pearson": 1.1163158475844465e-21, "spearman": 1.1163158475844892e-21, "kendall": 7.550242764330272e-21}, "kappa_score": 0.2901317800190568, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "PPArg-NP/AP": {"corr_coeff": {"pearson": 0.11720287142992544, "spearman": 0.11720287142992593, "kendall": 0.1172028714299259}, "p_value": {"pearson": 0.0001484373423074843, "spearman": 0.00014843734230747413, "kendall": 0.00015475547763882814}, "kappa_score": 0.10938792297960032, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "by-Phrase": {"corr_coeff": {"pearson": 0.4950431779264538, "spearman": 0.4950431779264544, "kendall": 0.49504317792645436}, "p_value": {"pearson": 1.4070104018268179e-65, "spearman": 1.4070104018263251e-65, "kendall": 1.7612882500615032e-57}, "kappa_score": 0.4381224058406743, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Expletive": {"corr_coeff": {"pearson": 0.350606892883661, "spearman": 0.3506068928836607, "kendall": 0.3506068928836607}, "p_value": {"pearson": 1.5701361294875775e-31, "spearman": 1.5701361294878519e-31, "kendall": 1.0737222355545357e-29}, "kappa_score": 0.34713731638401557, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "High Arity": {"corr_coeff": {"pearson": 0.01136339085500784, "spearman": 0.011363390855007758, "kendall": 0.011363390855007758}, "p_value": {"pearson": 0.7139485329128473, "spearman": 0.7139485329128514, "kendall": 0.7137603462498017}, "kappa_score": 0.008752807943322782, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Drop Arg": {"corr_coeff": {"pearson": 0.013442329132629103, "spearman": 0.01344232913262896, "kendall": 0.01344232913262896}, "p_value": {"pearson": 0.6645601239246262, "spearman": 0.6645601239246308, "kendall": 0.664347467079508}, "kappa_score": 0.004194087359770893, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Add Arg": {"corr_coeff": {"pearson": 0.026512964569659393, "spearman": 0.026512964569659125, "kendall": 0.02651296456965913}, "p_value": {"pearson": 0.39234450052745407, "spearman": 0.3923445005274674, "kendall": 0.3920867549147997}, "kappa_score": 0.01702071513392267, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Passive": {"corr_coeff": {"pearson": 0.17275995650364778, "spearman": 0.17275995650364573, "kendall": 0.17275995650364576}, "p_value": {"pearson": 1.9661839649210486e-08, "spearman": 1.9661839649217722e-08, "kendall": 2.4513014907203548e-08}, "kappa_score": 0.1035668242372152, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Imperative": {"corr_coeff": {"pearson": 0.37430828541661165, "spearman": 0.37430828541661054, "kendall": 0.37430828541661054}, "p_value": {"pearson": 4.963179229005508e-36, "spearman": 4.963179229008204e-36, "kendall": 1.3039793292482362e-33}, "kappa_score": 0.24577821259943, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Refl": {"corr_coeff": {"pearson": 0.4021013784779135, "spearman": 0.4021013784779168, "kendall": 0.4021013784779168}, "p_value": {"pearson": 8.317046370784216e-42, "spearman": 8.317046370770237e-42, "kendall": 1.5920770413902888e-38}, "kappa_score": 0.3965255377316188, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Binding:Other": {"corr_coeff": {"pearson": 0.01910275953995727, "spearman": 0.019102759539957444, "kendall": 0.019102759539957447}, "p_value": {"pearson": 0.5377296516972251, "spearman": 0.5377296516972235, "kendall": 0.5374738201759186}, "kappa_score": 0.018352941176470683, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Matrix Q": {"corr_coeff": {"pearson": 0.12177229793279101, "spearman": 0.12177229793279043, "kendall": 0.12177229793279044}, "p_value": {"pearson": 8.058165996851454e-05, "spearman": 8.058165996852522e-05, "kendall": 8.465917308525653e-05}, "kappa_score": 0.10632497273718644, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Emb Q": {"corr_coeff": {"pearson": 0.3773071958537035, "spearman": 0.37730719585370254, "kendall": 0.37730719585370254}, "p_value": {"pearson": 1.256085873536055e-36, "spearman": 1.2560858735367187e-36, "kendall": 3.997952540417608e-34}, "kappa_score": 0.35914834504314375, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Complex QP": {"corr_coeff": {"pearson": 0.2360630446504129, "spearman": 0.23606304465041789, "kendall": 0.2360630446504179}, "p_value": {"pearson": 1.126872624766928e-14, "spearman": 1.1268726247654483e-14, "kendall": 2.534381664681035e-14}, "kappa_score": 0.21250854955187026, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "RC": {"corr_coeff": {"pearson": 0.42610087740419017, "spearman": 0.4261008774041864, "kendall": 0.42610087740418645}, "p_value": {"pearson": 2.9570168002316524e-47, "spearman": 2.9570168002377136e-47, "kendall": 4.782677577845216e-43}, "kappa_score": 0.3891708667565841, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Island": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Subj": {"corr_coeff": {"pearson": 0.07952704883852316, "spearman": 0.07952704883852281, "kendall": 0.07952704883852281}, "p_value": {"pearson": 0.010188737526250692, "spearman": 0.01018873752625136, "kendall": 0.010254264973476633}, "kappa_score": 0.04100041892678563, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg VP": {"corr_coeff": {"pearson": 0.1932196577008588, "spearman": 0.1932196577008581, "kendall": 0.19321965770085817}, "p_value": {"pearson": 3.133439236550677e-10, "spearman": 3.133439236550862e-10, "kendall": 4.4565640808026825e-10}, "kappa_score": 0.1849174562860213, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "CP Arg NP/AP": {"corr_coeff": {"pearson": 0.08075324785787995, "spearman": 0.08075324785788077, "kendall": 0.08075324785788075}, "p_value": {"pearson": 0.009078015575873476, "spearman": 0.009078015575872503, "kendall": 0.009141492148747505}, "kappa_score": 0.0765886596984553, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite CP": {"corr_coeff": {"pearson": 0.10304905380766971, "spearman": 0.10304905380766925, "kendall": 0.10304905380766927}, "p_value": {"pearson": 0.0008594351751244825, "spearman": 0.0008594351751245324, "kendall": 0.0008796737037827791}, "kappa_score": 0.03104331621222778, "total_responses": 1043, "valid_responses": 1040, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "No C-izer": {"corr_coeff": {"pearson": 0.06304522558336959, "spearman": 0.0630452255833703, "kendall": 0.0630452255833703}, "p_value": {"pearson": 0.04178435477447095, "spearman": 0.041784354774467354, "kendall": 0.04184066670564902}, "kappa_score": 0.023293711153080765, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deep Embed": {"corr_coeff": {"pearson": 0.17628965458026635, "spearman": 0.1762896545802635, "kendall": 0.17628965458026352}, "p_value": {"pearson": 9.955677505339009e-09, "spearman": 9.955677505344265e-09, "kendall": 1.265682299976964e-08}, "kappa_score": 0.1517494071619967, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Neg": {"corr_coeff": {"pearson": 0.576625080301602, "spearman": 0.5766250803016022, "kendall": 0.5766250803016023}, "p_value": {"pearson": 1.817447753843358e-93, "spearman": 1.8174477538429604e-93, "kendall": 2.4988775271379852e-77}, "kappa_score": 0.5765575398281166, "total_responses": 1043, "valid_responses": 1042, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Modal": {"corr_coeff": {"pearson": 0.5117312253031334, "spearman": 0.5117312253031371, "kendall": 0.5117312253031371}, "p_value": {"pearson": 1.1127758827699532e-70, "spearman": 1.1127758827669678e-70, "kendall": 2.6915181179727596e-61}, "kappa_score": 0.489471160569796, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Aux": {"corr_coeff": {"pearson": 0.2278891905593334, "spearman": 0.22788919055933413, "kendall": 0.22788919055933413}, "p_value": {"pearson": 9.390563262664686e-14, "spearman": 9.390563262663391e-14, "kendall": 1.8912211358495619e-13}, "kappa_score": 0.2276653212345605, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Psuedo-Aux": {"corr_coeff": {"pearson": 0.26789914463866127, "spearman": 0.2678991446386666, "kendall": 0.2678991446386666}, "p_value": {"pearson": 1.3324864240104525e-18, "spearman": 1.3324864240083267e-18, "kendall": 5.2505866821655514e-18}, "kappa_score": 0.22621697197968382, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Control": {"corr_coeff": {"pearson": 0.20777543897179623, "spearman": 0.20777543897179754, "kendall": 0.20777543897179754}, "p_value": {"pearson": 1.2333525309760342e-11, "spearman": 1.2333525309756436e-11, "kendall": 1.986712720433568e-11}, "kappa_score": 0.12180149764629378, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Raising": {"corr_coeff": {"pearson": 0.06281462838008083, "spearman": 0.06281462838008066, "kendall": 0.06281462838008066}, "p_value": {"pearson": 0.042539734824639, "spearman": 0.04253973482463937, "kendall": 0.04259518944156445}, "kappa_score": 0.024383575048856354, "total_responses": 1043, "valid_responses": 1027, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP+Extract": {"corr_coeff": {"pearson": 0.07150899235112335, "spearman": 0.07150899235112292, "kendall": 0.0715089923511229}, "p_value": {"pearson": 0.020909902616336656, "spearman": 0.020909902616337687, "kendall": 0.020981786968399637}, "kappa_score": 0.0477415713550573, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "VP arg-NP/AP": {"corr_coeff": {"pearson": 0.08997079845816396, "spearman": 0.08997079845816547, "kendall": 0.08997079845816548}, "p_value": {"pearson": 0.0036366917452247175, "spearman": 0.0036366917452241637, "kendall": 0.0036812278171940048}, "kappa_score": 0.07635540686805087, "total_responses": 1043, "valid_responses": 1029, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Non-finite VP Misc": {"corr_coeff": {"pearson": 0.09630409989820281, "spearman": 0.09630409989820303, "kendall": 0.09630409989820304}, "p_value": {"pearson": 0.001847570859004188, "spearman": 0.0018475708590041543, "kendall": 0.0018791322234248944}, "kappa_score": 0.08545112528385035, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Deverbal": {"corr_coeff": {"pearson": 0.08569643541006994, "spearman": 0.08569643541006972, "kendall": 0.08569643541006972}, "p_value": {"pearson": 0.005616183585175147, "spearman": 0.005616183585175403, "kendall": 0.005669929614153498}, "kappa_score": 0.033017722748239664, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel NP": {"corr_coeff": {"pearson": 0.05701015004777156, "spearman": 0.05701015004777156, "kendall": 0.057010150047771546}, "p_value": {"pearson": 0.06570057199300351, "spearman": 0.06570057199300562, "kendall": 0.06572581117965415}, "kappa_score": 0.050695829737466336, "total_responses": 1043, "valid_responses": 1036, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans NP": {"corr_coeff": {"pearson": 0.08369521428072277, "spearman": 0.08369521428072288, "kendall": 0.08369521428072288}, "p_value": {"pearson": 0.006841041933545775, "spearman": 0.0068410419335458526, "kendall": 0.006898938065748021}, "kappa_score": 0.04475403772654407, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Compx NP": {"corr_coeff": {"pearson": 0.04796988719163659, "spearman": 0.047969887191636744, "kendall": 0.04796988719163674}, "p_value": {"pearson": 0.1215631680033956, "spearman": 0.1215631680033906, "kendall": 0.12150938431463898}, "kappa_score": 0.040005508004725354, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NNCompd": {"corr_coeff": {"pearson": 0.12576160745052523, "spearman": 0.12576160745052717, "kendall": 0.12576160745052717}, "p_value": {"pearson": 4.6442283412763554e-05, "spearman": 4.644228341275086e-05, "kendall": 4.915941964095799e-05}, "kappa_score": 0.07025498294128207, "total_responses": 1043, "valid_responses": 1025, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Rel Adj": {"corr_coeff": {"pearson": 0.02615544562023088, "spearman": 0.026155445620230793, "kendall": 0.026155445620230793}, "p_value": {"pearson": 0.3987616585411146, "spearman": 0.39876165854112755, "kendall": 0.3985026616219063}, "kappa_score": 0.0225120565437259, "total_responses": 1043, "valid_responses": 1038, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Trans Adj": {"corr_coeff": {"pearson": 0.18777385764430352, "spearman": 0.1877738576443063, "kendall": 0.18777385764430632}, "p_value": {"pearson": 9.874817474750464e-10, "spearman": 9.874817474744407e-10, "kendall": 1.3498812088563334e-09}, "kappa_score": 0.18271684314158854, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Dislocation": {"corr_coeff": {"pearson": 0.057577870024939956, "spearman": 0.05757787002494048, "kendall": 0.057577870024940477}, "p_value": {"pearson": 0.06305277962758987, "spearman": 0.0630527796275873, "kendall": 0.06308171927716573}, "kappa_score": 0.05702908341036761, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Info Struc": {"corr_coeff": {"pearson": -0.015387405871574432, "spearman": -0.015387405871574632, "kendall": -0.015387405871574633}, "p_value": {"pearson": 0.6196280150885753, "spearman": 0.6196280150885691, "kendall": 0.6193965015181959}, "kappa_score": -0.012344142754038057, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Frag/Paren": {"corr_coeff": {"pearson": 0.09593087247376714, "spearman": 0.09593087247376957, "kendall": 0.09593087247376955}, "p_value": {"pearson": 0.0019249279744237946, "spearman": 0.001924927974423227, "kendall": 0.0019572019073494052}, "kappa_score": 0.07613368764447892, "total_responses": 1043, "valid_responses": 1041, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Coord": {"corr_coeff": {"pearson": 0.4468916976078797, "spearman": 0.4468916976078795, "kendall": 0.4468916976078794}, "p_value": {"pearson": 2.40382827245846e-52, "spearman": 2.4038282724588948e-52, "kendall": 3.5676201942447825e-47}, "kappa_score": 0.38945560279059943, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Subordinate/Cond": {"corr_coeff": {"pearson": 0.17280920861596663, "spearman": 0.17280920861597138, "kendall": 0.17280920861597138}, "p_value": {"pearson": 1.94778724187474e-08, "spearman": 1.9477872418729142e-08, "kendall": 2.4290070486146414e-08}, "kappa_score": 0.17249824650162704, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Ellipsis/Anaphor": {"corr_coeff": {"pearson": 0.25256864668641854, "spearman": 0.2525686466864218, "kendall": 0.2525686466864218}, "p_value": {"pearson": 1.2144746376444093e-16, "spearman": 1.2144746376431725e-16, "kendall": 3.5523423373472473e-16}, "kappa_score": 0.19537538316595782, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "S-Adjunct": {"corr_coeff": {"pearson": 0.1307809048047513, "spearman": 0.13078090480475033, "kendall": 0.13078090480475035}, "p_value": {"pearson": 2.267479340136662e-05, "spearman": 2.2674793401369235e-05, "kendall": 2.4256261877032696e-05}, "kappa_score": 0.10019135342003704, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Quantifier": {"corr_coeff": {"pearson": 0.23365007581923553, "spearman": 0.23365007581923877, "kendall": 0.23365007581923875}, "p_value": {"pearson": 2.124987504098387e-14, "spearman": 2.1249875040966006e-14, "kendall": 4.620011256196738e-14}, "kappa_score": 0.16103399105434413, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Partitive": {"corr_coeff": {"pearson": -0.02576814094443171, "spearman": -0.02576814094443119, "kendall": -0.025768140944431195}, "p_value": {"pearson": 0.4057841829553445, "spearman": 0.40578418295535434, "kendall": 0.40552397320622324}, "kappa_score": -0.023983169705469765, "total_responses": 1043, "valid_responses": 1026, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "NPI/FCI": {"corr_coeff": {"pearson": 0.23337784706339407, "spearman": 0.23337784706339593, "kendall": 0.2333778470633959}, "p_value": {"pearson": 2.2816204099998302e-14, "spearman": 2.2816204099987725e-14, "kendall": 4.941970940384571e-14}, "kappa_score": 0.15930080024444582, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Comparative": {"corr_coeff": {"pearson": 0.33679938664992704, "spearman": 0.3367993866499374, "kendall": 0.3367993866499374}, "p_value": {"pearson": 4.427927959691011e-29, "spearman": 4.427927959672537e-29, "kendall": 1.5691170872938194e-27}, "kappa_score": 0.33673135104927443, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Sem  Violation": {"corr_coeff": {"pearson": 0.05478112737370703, "spearman": 0.05478112737370699, "kendall": 0.05478112737370699}, "p_value": {"pearson": 0.07699556169974238, "spearman": 0.07699556169974138, "kendall": 0.07700472399729011}, "kappa_score": 0.054397098821396206, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Infl/Agr Violation": {"corr_coeff": {"pearson": 0.02070255611573951, "spearman": 0.020702556115739793, "kendall": 0.020702556115739797}, "p_value": {"pearson": 0.5042169240522715, "spearman": 0.5042169240522665, "kendall": 0.5039555000050624}, "kappa_score": 0.019807706209788223, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}, "Extra/Mising Expr": {"corr_coeff": {"pearson": 0.13986875540093688, "spearman": 0.1398687554009382, "kendall": 0.1398687554009382}, "p_value": {"pearson": 5.787127973014606e-06, "spearman": 5.787127973013177e-06, "kendall": 6.332665879308884e-06}, "kappa_score": 0.11871567384875381, "total_responses": 1043, "valid_responses": 1043, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Acceptability"}}}