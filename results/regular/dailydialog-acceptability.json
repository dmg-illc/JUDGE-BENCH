{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.6276301630998431, "spearman": 0.6127123541805172, "kendall": 0.5173682358363313}, "p_value": {"pearson": 2.7864337498567047e-12, "spearman": 1.2443628505498792e-11, "kendall": 1.3118060528325426e-10}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.7383707484970162, "spearman": 0.6044546693023249, "kendall": 0.5150832365292194}, "p_value": {"pearson": 1.8492653622902437e-18, "spearman": 2.755941855437589e-11, "kendall": 9.881362378068363e-10}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.5822915406214306, "spearman": 0.47663429945345165, "kendall": 0.4085182021495168}, "p_value": {"pearson": 2.088391742155304e-10, "spearman": 5.359907920623504e-07, "kendall": 8.210713565936037e-07}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.08644140616455064, "spearman": 0.06560090386047869, "kendall": 0.05190391820085345}, "p_value": {"pearson": 0.39246899094493015, "spearman": 0.5166872050986291, "kendall": 0.5106251700338715}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 62, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.09703353360742861, "spearman": 0.08672831026865299, "kendall": 0.07110587241446893}, "p_value": {"pearson": 0.33685166242400144, "spearman": 0.39089388052562335, "kendall": 0.3937083887111027}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 89, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.3101210984177676, "spearman": 0.2274680989808735, "kendall": 0.18148350985263093}, "p_value": {"pearson": 0.001689368832419831, "spearman": 0.0228456533100383, "kendall": 0.02311253197539315}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 69, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "gpt-4o (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.8723812975284289, "spearman": 0.6863686102381712, "kendall": 0.5906018147509685}, "p_value": {"pearson": 3.16433070149511e-32, "spearman": 3.229554319574093e-15, "kendall": 1.2235846197962332e-12}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.7719847936620992, "spearman": 0.6338536857345637, "kendall": 0.5321785912467695}, "p_value": {"pearson": 5.3638863349909445e-21, "spearman": 1.4571597445731203e-12, "kendall": 6.1709420997195e-11}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 99, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.6857114338104306, "spearman": 0.5714397418713019, "kendall": 0.45903195340157743}, "p_value": {"pearson": 3.513914223693594e-15, "spearman": 5.331824579848224e-10, "kendall": 5.151007001445067e-09}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.7303545051435052, "spearman": 0.625731741983424, "kendall": 0.5201543175064787}, "p_value": {"pearson": 6.5380640590715745e-18, "spearman": 3.3859700081106816e-12, "kendall": 5.325319710515413e-10}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.6694182346757287, "spearman": 0.551249916121172, "kendall": 0.4678608881368862}, "p_value": {"pearson": 2.6587870969447548e-14, "spearman": 2.7928980417213547e-09, "kendall": 3.4920845573255606e-08}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"acceptability": {"corr_coeff": {"pearson": 0.6524532861642337, "spearman": 0.5246124350374416, "kendall": 0.4484363076105307}, "p_value": {"pearson": 1.9185310601372804e-13, "spearman": 2.1123072656167317e-08, "kendall": 6.048944753897342e-08}, "kappa_score": NaN, "total_responses": 100, "valid_responses": 100, "krippendorff_alpha": 0.5869691321185129, "type": "graded", "expert": "false", "task": "Acceptability"}}}