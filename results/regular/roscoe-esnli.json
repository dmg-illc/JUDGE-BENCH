{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.3405798631897469, "spearman": 0.2973697543307567, "kendall": 0.2702946738452476}, "p_value": {"pearson": 1.877564170297673e-05, "spearman": 0.0002088888471589818, "kendall": 0.00022964769031899807}, "kappa_score": 0.14873329621380837, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.06722511425293254, "spearman": 0.07393281217784348, "kendall": 0.0715117533100943}, "p_value": {"pearson": 0.4121364277094691, "spearman": 0.3669572320426796, "kendall": 0.3655866798728079}, "kappa_score": -0.011593101154558916, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.3236778960707954, "spearman": 0.3236778960707954, "kendall": 0.32367789607079545}, "p_value": {"pearson": 5.033772924832954e-05, "spearman": 5.0337729248329925e-05, "kendall": 7.363371766166954e-05}, "kappa_score": 0.2806888970318798, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5775774913799921, "spearman": 0.5155781616814705, "kendall": 0.46692160401466076}, "p_value": {"pearson": 8.239507397340491e-15, "spearman": 1.2501513030720203e-11, "kendall": 1.6162193740541524e-10}, "kappa_score": 0.17289325842696623, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.34488954647424513, "spearman": 0.29397799336602637, "kendall": 0.28475982997185256}, "p_value": {"pearson": 1.4465456478694413e-05, "spearman": 0.0002485595721235696, "kendall": 0.00030114664826945246}, "kappa_score": 0.17486338797814216, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.5012296046559956, "spearman": 0.5012296046559958, "kendall": 0.5012296046559958}, "p_value": {"pearson": 5.562900458754678e-11, "spearman": 5.562900458754643e-11, "kendall": 8.31556072071627e-10}, "kappa_score": 0.4389527348137907, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.4024658799976481, "spearman": 0.40246587999764805, "kendall": 0.4024658799976481}, "p_value": {"pearson": 3.0101896178204717e-07, "spearman": 3.010189617820483e-07, "kendall": 8.25753737306391e-07}, "kappa_score": 0.3293147208121826, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4758481868310312, "spearman": 0.4050235097235752, "kendall": 0.36954708979563955}, "p_value": {"pearson": 6.621836645529263e-10, "spearman": 2.490006163926969e-07, "kendall": 8.591485121620915e-07}, "kappa_score": 0.10806115357887425, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.1986365457632128, "spearman": 0.23305326981218544, "kendall": 0.2219415666659956}, "p_value": {"pearson": 0.014484473237799193, "spearman": 0.003979630190803374, "kendall": 0.004656493107028096}, "kappa_score": 0.14326241134751772, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.04536440692545769, "spearman": -0.04536440692545769, "kendall": -0.04536440692545769}, "p_value": {"pearson": 0.5801951190615257, "spearman": 0.5801951190615264, "kendall": 0.5784855299268024}, "kappa_score": -0.04405373370209409, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.199068279841714, "spearman": 0.19906827984171396, "kendall": 0.19906827984171396}, "p_value": {"pearson": 0.014268114297938844, "spearman": 0.014268114297938844, "kendall": 0.01476556519795082}, "kappa_score": 0.07623529411764696, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.20502794827310242, "spearman": 0.22621502405818458, "kendall": 0.1988527667614938}, "p_value": {"pearson": 0.011557425580211285, "spearman": 0.00522253561149589, "kendall": 0.006031235483254667}, "kappa_score": 0.07815644706829472, "total_responses": 151, "valid_responses": 135, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.04548851489551351, "spearman": -0.008029712813253124, "kendall": -0.007247228036564589}, "p_value": {"pearson": 0.5791583886620807, "spearman": 0.9220494990566512, "kendall": 0.9239775641367599}, "kappa_score": 0.019393292411707175, "total_responses": 151, "valid_responses": 134, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.15566455594754913, "spearman": -0.15566455594754922, "kendall": -0.15566455594754922}, "p_value": {"pearson": 0.05631449377123534, "spearman": 0.056314493771235305, "kendall": 0.05658618674932762}, "kappa_score": -0.10692336171788241, "total_responses": 151, "valid_responses": 129, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.05821615696304418, "spearman": 0.05821615696304415, "kendall": 0.058216156963044156}, "p_value": {"pearson": 0.4776855445522878, "spearman": 0.4776855445522864, "kendall": 0.4758461304412409}, "kappa_score": 0.023132719074691388, "total_responses": 151, "valid_responses": 91, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.1075972778529576, "spearman": 0.15657950320110525, "kendall": 0.14546769184468825}, "p_value": {"pearson": 0.1885060559063298, "spearman": 0.054863949301434574, "kendall": 0.05465506969782662}, "kappa_score": -0.011683277962347693, "total_responses": 151, "valid_responses": 150, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.07475443250860075, "spearman": 0.0650699907791702, "kendall": 0.06186199840361567}, "p_value": {"pearson": 0.3616415203613183, "spearman": 0.42731730892444264, "kendall": 0.4251864067995972}, "kappa_score": -0.002804014167650637, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.052814983861483866, "spearman": 0.052814983861483804, "kendall": 0.052814983861483804}, "p_value": {"pearson": 0.5195378141024335, "spearman": 0.519537814102434, "kendall": 0.5177298013058682}, "kappa_score": 0.05252149663025796, "total_responses": 151, "valid_responses": 126, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.127440322688417, "spearman": -0.127440322688417, "kendall": -0.127440322688417}, "p_value": {"pearson": 0.11891007141321577, "spearman": 0.11891007141321636, "kendall": 0.11856650652402555}, "kappa_score": -0.04205569538036835, "total_responses": 151, "valid_responses": 55, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.48497372200403577, "spearman": 0.42699803109515244, "kendall": 0.39094653516118405}, "p_value": {"pearson": 2.7818663292137055e-10, "spearman": 4.563480965801946e-08, "kendall": 1.5864165838120729e-07}, "kappa_score": 0.10332541567695952, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.08580196785636852, "spearman": 0.12763836765040804, "kendall": 0.12340312851062346}, "p_value": {"pearson": 0.29485802047268417, "spearman": 0.11833321351122783, "kendall": 0.11547363811259902}, "kappa_score": 0.06638962092033229, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.04984825458176529, "spearman": -0.0498482545817653, "kendall": -0.04984825458176529}, "p_value": {"pearson": 0.5432979063313643, "spearman": 0.5432979063313649, "kendall": 0.5415214110234945}, "kappa_score": -0.013099041533546352, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.44489197428962846, "spearman": 0.3998042638459157, "kendall": 0.3595724401739402}, "p_value": {"pearson": 1.0453319138053065e-08, "spearman": 3.6610752774609184e-07, "kendall": 1.3369914765803451e-06}, "kappa_score": 0.09796893667861417, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.306223069951403, "spearman": 0.27606147294609856, "kendall": 0.26179109876987955}, "p_value": {"pearson": 0.00013133458786140985, "spearman": 0.0006012871103234644, "kendall": 0.0007863867326335994}, "kappa_score": 0.10234575835475568, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.03240543852046967, "spearman": -0.032405438520469704, "kendall": -0.032405438520469704}, "p_value": {"pearson": 0.6928432952009275, "spearman": 0.692843295200928, "kendall": 0.6914530430299879}, "kappa_score": -0.027040477770404747, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.21552462474039702, "spearman": 0.21552462474039705, "kendall": 0.21552462474039707}, "p_value": {"pearson": 0.007867295263720712, "spearman": 0.007867295263720774, "kendall": 0.008299737123616247}, "kappa_score": 0.11801707353601909, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.6908637073067024, "spearman": 0.6572185654014067, "kendall": 0.5695575449732126}, "p_value": {"pearson": 9.602756274569836e-23, "spearman": 4.963480940329275e-20, "kendall": 1.6767279655716608e-16}, "kappa_score": 0.1611111111111111, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3144486348435638, "spearman": 0.3151723663461358, "kendall": 0.3030398440848849}, "p_value": {"pearson": 8.420071872544389e-05, "spearman": 8.092026420805657e-05, "kendall": 0.00012114805020352}, "kappa_score": 0.1629711751662971, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.4209045370710484, "spearman": 0.4209045370710478, "kendall": 0.4209045370710478}, "p_value": {"pearson": 7.394954475085697e-08, "spearman": 7.394954475086134e-08, "kendall": 2.53621818525025e-07}, "kappa_score": 0.3293147208121826, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.33356350314644434, "spearman": 0.33356350314644456, "kendall": 0.3335635031464446}, "p_value": {"pearson": 2.8473433176908663e-05, "spearman": 2.8473433176908304e-05, "kendall": 4.4019543954016934e-05}, "kappa_score": 0.24462231115557775, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4520522193850887, "spearman": 0.4015848454280884, "kendall": 0.36931386655246623}, "p_value": {"pearson": 5.657332336295416e-09, "spearman": 3.2123069045603654e-07, "kendall": 9.087687334095193e-07}, "kappa_score": 0.09505386132605076, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.17983331540809233, "spearman": 0.22836304147862413, "kendall": 0.22097979179351845}, "p_value": {"pearson": 0.027139128594152892, "spearman": 0.004799106782856009, "kendall": 0.005339348230718041}, "kappa_score": 0.09651404786680551, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.02197370229467554, "spearman": 0.02197370229467553, "kendall": 0.02197370229467553}, "p_value": {"pearson": 0.788848720797765, "spearman": 0.7888487207977658, "kendall": 0.7878359613475221}, "kappa_score": 0.018735758291838933, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.17260273972602697, "spearman": 0.17260273972602735, "kendall": 0.1726027397260274}, "p_value": {"pearson": 0.034066347723831124, "spearman": 0.0340663477238307, "kendall": 0.03452011868332339}, "kappa_score": 0.17260273972602747, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5455835392410747, "spearman": 0.49499853348386835, "kendall": 0.43990950422188535}, "p_value": {"pearson": 4.354427848278345e-13, "spearman": 1.0413524104812475e-10, "kendall": 4.382453335932003e-10}, "kappa_score": -0.0014417531718571297, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.24011505903459593, "spearman": 0.2031675225262975, "kendall": 0.18939074967926733}, "p_value": {"pearson": 0.002981535104119835, "spearman": 0.012350468298032713, "kendall": 0.013630538270685307}, "kappa_score": 0.008752735229759168, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.12649497541743226, "spearman": -0.12649497541743251, "kendall": -0.12649497541743251}, "p_value": {"pearson": 0.1216937591819525, "spearman": 0.12169375918195198, "kendall": 0.12132386317541934}, "kappa_score": -0.021825275864171045, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.28537079737790827, "spearman": 0.2853707973779085, "kendall": 0.28537079737790844}, "p_value": {"pearson": 0.00038274731860743846, "spearman": 0.00038274731860743385, "kendall": 0.0004739477294111772}, "kappa_score": 0.2335025380710659, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5690065524144399, "spearman": 0.5076762992969556, "kendall": 0.47025132625756383}, "p_value": {"pearson": 2.487683088380388e-14, "spearman": 2.8690618071397327e-11, "kendall": 2.8711082370139076e-10}, "kappa_score": 0.12271503471730216, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.27221045338744576, "spearman": 0.2604800134850941, "kendall": 0.25039635676841343}, "p_value": {"pearson": 0.000721530843682306, "spearman": 0.0012371138448887234, "kendall": 0.0013862742690287017}, "kappa_score": 0.1596622529265016, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.05186585586671168, "spearman": 0.051865855866711615, "kendall": 0.051865855866711615}, "p_value": {"pearson": 0.5270811010075467, "spearman": 0.5270811010075465, "kendall": 0.5252820653767516}, "kappa_score": 0.04422314119334969, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.31587758314269754, "spearman": 0.3158775831426982, "kendall": 0.3158775831426981}, "p_value": {"pearson": 7.783908480522115e-05, "spearman": 7.783908480521855e-05, "kendall": 0.00010941963464904355}, "kappa_score": 0.2238317757009345, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.2286414707999312, "spearman": 0.1452644033499861, "kendall": 0.12317669343565388}, "p_value": {"pearson": 0.004746535147437677, "spearman": 0.07513201060056703, "kendall": 0.08203883528515825}, "kappa_score": 0.03532506576475014, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.05374136515599837, "spearman": 0.025621257032295987, "kendall": 0.024534601959975155}, "p_value": {"pearson": 0.5122288585567205, "spearman": 0.7548320807046629, "kendall": 0.7521107702145193}, "kappa_score": 0.010792723159581574, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.1897694407994068, "spearman": 0.18976944079940627, "kendall": 0.18976944079940627}, "p_value": {"pearson": 0.01960639209924237, "spearman": 0.01960639209924275, "kendall": 0.020115233014989662}, "kappa_score": 0.06952125138252496, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 151, "valid_responses": 151, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}