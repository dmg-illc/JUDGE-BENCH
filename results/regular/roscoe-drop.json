{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.35709598084745453, "spearman": 0.2974059439372484, "kendall": 0.2640811428659021}, "p_value": {"pearson": 1.0354778909781792e-07, "spearman": 1.166812066355456e-05, "kendall": 1.809782814931957e-05}, "kappa_score": 0.04692867723533689, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.17050229192845334, "spearman": 0.15809129767864818, "kendall": 0.14989706713871498}, "p_value": {"pearson": 0.013353141252122893, "spearman": 0.021921973572638274, "kendall": 0.0237246534526442}, "kappa_score": 0.007586121129212975, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.036199465609333376, "spearman": 0.03619946560933339, "kendall": 0.03619946560933338}, "p_value": {"pearson": 0.601934922398095, "spearman": 0.6019349223980955, "kendall": 0.6007449034627306}, "kappa_score": 0.03347280334728042, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.7208312046507372, "spearman": 0.6960016986831096, "kendall": 0.617536923658162}, "p_value": {"pearson": 5.882964742602632e-35, "spearman": 9.474049600166643e-32, "kendall": 1.5737878870540584e-24}, "kappa_score": 0.23664635993403116, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.41268168584803944, "spearman": 0.4764635373031489, "kendall": 0.4443302201984274}, "p_value": {"pearson": 4.838101579390169e-10, "spearman": 2.6743733554950564e-13, "kendall": 5.0553013719529365e-12}, "kappa_score": 0.22605707455550583, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.32982256509918706, "spearman": 0.32982256509918706, "kendall": 0.329822565099187}, "p_value": {"pearson": 1.0158640317219507e-06, "spearman": 1.015864031721948e-06, "kendall": 1.8588888371290344e-06}, "kappa_score": 0.31971564833978217, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.263087509059495, "spearman": 0.2630875090594951, "kendall": 0.2630875090594951}, "p_value": {"pearson": 0.00011435218496322974, "spearman": 0.00011435218496322877, "kendall": 0.00014271670708898392}, "kappa_score": 0.21825143586470963, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.3844115105387541, "spearman": 0.37118126516535765, "kendall": 0.3329415796372556}, "p_value": {"pearson": 8.397961100828904e-09, "spearman": 2.9188542103020482e-08, "kendall": 8.791660583489404e-08}, "kappa_score": 0.14421724548306825, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.08257288713706096, "spearman": 0.06396572547693119, "kendall": 0.06102404604716624}, "p_value": {"pearson": 0.2334618778379773, "spearman": 0.3563389115815798, "kendall": 0.3549002287384513}, "kappa_score": 0.044671489298232614, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.16576344106599994, "spearman": 0.16576344106599997, "kendall": 0.16576344106599997}, "p_value": {"pearson": 0.016196340174307634, "spearman": 0.016196340174307544, "kendall": 0.016556366101707454}, "kappa_score": 0.14725568942436418, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.0412861411922385, "spearman": 0.04128614119223852, "kendall": 0.041286141192238515}, "p_value": {"pearson": 0.55185969560382, "spearman": 0.55185969560382, "kendall": 0.5505963018118551}, "kappa_score": 0.04109589041095896, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.2703094123799163, "spearman": 0.30131020806509723, "kendall": 0.2658556342578217}, "p_value": {"pearson": 7.25107206602016e-05, "spearman": 8.827907365115075e-06, "kendall": 1.4201391265471916e-05}, "kappa_score": 0.06495744910050638, "total_responses": 210, "valid_responses": 195, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.016241722253325885, "spearman": 0.00803018714855708, "kendall": 0.00671971254580523}, "p_value": {"pearson": 0.8150039855724832, "spearman": 0.9079095199765786, "kendall": 0.9134664431844848}, "kappa_score": 0.0013162923018131822, "total_responses": 210, "valid_responses": 163, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.012368705607335218, "spearman": 0.012368705607335214, "kendall": 0.012368705607335214}, "p_value": {"pearson": 0.8585843234619289, "spearman": 0.858584323461928, "kendall": 0.8580850848443617}, "kappa_score": 0.0074871314927468235, "total_responses": 210, "valid_responses": 181, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.009385211916397223, "spearman": -0.009385211916397221, "kendall": -0.009385211916397221}, "p_value": {"pearson": 0.8924570352617297, "spearman": 0.89245703526173, "kendall": 0.8920739154981482}, "kappa_score": -0.00421163464069485, "total_responses": 210, "valid_responses": 104, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.25236225531367745, "spearman": 0.28306271203468464, "kendall": 0.2556881486905179}, "p_value": {"pearson": 0.00021968047495143176, "spearman": 3.1416980341057226e-05, "kendall": 3.861982329281644e-05}, "kappa_score": 0.007331087774915868, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.06689140527351302, "spearman": 0.04332393158131145, "kendall": 0.04087439461129198}, "p_value": {"pearson": 0.3347233250280274, "spearman": 0.5323850521128428, "kendall": 0.5295946656794969}, "kappa_score": 0.00043271311120740563, "total_responses": 210, "valid_responses": 206, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.06089970737203489, "spearman": 0.060899707372035046, "kendall": 0.060899707372035046}, "p_value": {"pearson": 0.3799066010262784, "spearman": 0.3799066010262777, "kendall": 0.3786335282792457}, "kappa_score": 0.03128020384851948, "total_responses": 210, "valid_responses": 183, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.024673188560991363, "spearman": -0.024673188560991335, "kendall": -0.024673188560991335}, "p_value": {"pearson": 0.7222386538317048, "spearman": 0.7222386538317059, "kendall": 0.7213192886523612}, "kappa_score": -0.012145748987854033, "total_responses": 210, "valid_responses": 33, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5155016564318184, "spearman": 0.4964947392188625, "kendall": 0.44876171020496364}, "p_value": {"pearson": 1.1827234255805427e-15, "spearman": 1.8055134568501844e-14, "kendall": 7.423771578950235e-13}, "kappa_score": 0.09983925701018048, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.29885741213554207, "spearman": 0.2415469320771977, "kendall": 0.23292895301212724}, "p_value": {"pearson": 1.0523708973867047e-05, "spearman": 0.0004125882857166933, "kendall": 0.000465343982520359}, "kappa_score": 0.12837236881114755, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.07658474625645978, "spearman": 0.07658474625645992, "kendall": 0.07658474625645992}, "p_value": {"pearson": 0.26923863107252805, "spearman": 0.26923863107252743, "kendall": 0.2682192108468202}, "kappa_score": 0.065254161844565, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.038447322405439716, "spearman": -0.038447322405439625, "kendall": -0.03844732240543962}, "p_value": {"pearson": 0.5795555600073027, "spearman": 0.5795555600073027, "kendall": 0.5783294731507844}, "kappa_score": -0.034782608695652195, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.7611001969014882, "spearman": 0.729571505774792, "kendall": 0.6402999242313578}, "p_value": {"pearson": 5.694299928356842e-41, "spearman": 3.602307299930881e-36, "kendall": 1.052146999925315e-27}, "kappa_score": 0.2897332153243142, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3852246325152667, "spearman": 0.41962919227313417, "kendall": 0.3906886562514284}, "p_value": {"pearson": 7.764786976168204e-09, "spearman": 2.3008976168898796e-10, "kendall": 1.5398025184090342e-09}, "kappa_score": 0.22628951747088177, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.3506850513677445, "spearman": 0.35068505136774514, "kendall": 0.3506850513677452}, "p_value": {"pearson": 1.8062603904796597e-07, "spearman": 1.8062603904795858e-07, "kendall": 3.9824447039986526e-07}, "kappa_score": 0.34907466496490114, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.32455194722120784, "spearman": 0.3245519472212076, "kendall": 0.32455194722120767}, "p_value": {"pearson": 1.5408496696972644e-06, "spearman": 1.5408496696972932e-06, "kendall": 2.7055629193078108e-06}, "kappa_score": 0.23113658070678123, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.45391827525572803, "spearman": 0.4378811736574787, "kendall": 0.38455002687515055}, "p_value": {"pearson": 4.5365630666307824e-12, "spearman": 3.0062515028927593e-11, "kendall": 3.4743399592873877e-10}, "kappa_score": 0.09961412033728756, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.2143138783785879, "spearman": 0.2636641674908117, "kendall": 0.2417693440977927}, "p_value": {"pearson": 0.0017868982588085103, "spearman": 0.00011031967392090293, "kendall": 0.00016651720024549228}, "kappa_score": 0.11838790931989929, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.21962877091356367, "spearman": 0.21962877091356384, "kendall": 0.21962877091356384}, "p_value": {"pearson": 0.0013603955609471853, "spearman": 0.001360395560947159, "kendall": 0.0014976613116061104}, "kappa_score": 0.17917740072843558, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.08395581319478204, "spearman": 0.08395581319478197, "kendall": 0.08395581319478197}, "p_value": {"pearson": 0.22569860953350887, "spearman": 0.22569860953350787, "kendall": 0.22484889193241597}, "kappa_score": 0.08296943231441045, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5806075142728182, "spearman": 0.5304305525780237, "kendall": 0.45113853281170524}, "p_value": {"pearson": 2.539654410785474e-20, "spearman": 1.2303410031671035e-16, "kendall": 5.411913906224925e-15}, "kappa_score": 0.1694342129098484, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3925192423612363, "spearman": 0.346136438145637, "kendall": 0.3225009125532036}, "p_value": {"pearson": 3.806567989373823e-09, "spearman": 2.660760170041663e-07, "kendall": 3.637709630276052e-07}, "kappa_score": 0.1340050919783411, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.13981512537768814, "spearman": 0.13981512537768798, "kendall": 0.13981512537768798}, "p_value": {"pearson": 0.04297297646998991, "spearman": 0.04297297646999021, "kendall": 0.043250393114973945}, "kappa_score": 0.05200789993416732, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.12309149097933317, "spearman": 0.12309149097933272, "kendall": 0.12309149097933272}, "p_value": {"pearson": 0.07509346040366535, "spearman": 0.07509346040366695, "kendall": 0.07515568862181482}, "kappa_score": 0.11764705882352944, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4125346394969716, "spearman": 0.4050506104054887, "kendall": 0.35845078723744206}, "p_value": {"pearson": 4.913910213612943e-10, "spearman": 1.073483381553783e-09, "kendall": 5.932075937622135e-09}, "kappa_score": 0.1242093556683117, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.2630642284573984, "spearman": 0.23888145663843244, "kendall": 0.22460763497725855}, "p_value": {"pearson": 0.00011451784671041358, "spearman": 0.00047987019531779777, "kendall": 0.0005569431547009249}, "kappa_score": 0.12350597609561753, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.2813005036142924, "spearman": 0.28130050361429293, "kendall": 0.28130050361429293}, "p_value": {"pearson": 3.535267346508369e-05, "spearman": 3.535267346508289e-05, "kendall": 4.7680658180538524e-05}, "kappa_score": 0.2788070492544058, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.017225834749087957, "spearman": -0.017225834749087888, "kendall": -0.017225834749087888}, "p_value": {"pearson": 0.8040148530266212, "spearman": 0.8040148530266211, "kendall": 0.8033367989254111}, "kappa_score": -0.016333938294010864, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.5972101569404507, "spearman": 0.5441613828354146, "kendall": 0.48953763414681284}, "p_value": {"pearson": 1.097550824040068e-21, "spearman": 1.387613763761376e-17, "kendall": 3.5458246582581833e-15}, "kappa_score": 0.21876086503024816, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.3686876823432525, "spearman": 0.3331405744602269, "kendall": 0.31650960240430615}, "p_value": {"pearson": 3.6686148482538354e-08, "spearman": 7.78376082622252e-07, "kendall": 1.3169641464603537e-06}, "kappa_score": 0.23324463147472008, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.2840359418550398, "spearman": 0.28403594185504016, "kendall": 0.28403594185504016}, "p_value": {"pearson": 2.942441673459514e-05, "spearman": 2.9424416734594412e-05, "kendall": 4.021168870432094e-05}, "kappa_score": 0.2802303262955854, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.13752311475791879, "spearman": 0.13752311475791867, "kendall": 0.13752311475791865}, "p_value": {"pearson": 0.04653900651518317, "spearman": 0.046539006515183494, "kendall": 0.046795256960786326}, "kappa_score": 0.10999408633944419, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4302812657548006, "spearman": 0.3701434961101414, "kendall": 0.31451837364000695}, "p_value": {"pearson": 7.12007236632805e-11, "spearman": 3.2109721228764675e-08, "kendall": 6.351649758339834e-08}, "kappa_score": 0.06339410939691448, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.10001714048753513, "spearman": 0.05687647813571135, "kendall": 0.05325896331392227}, "p_value": {"pearson": 0.148637957570008, "spearman": 0.4122372370142965, "kendall": 0.4031234233387183}, "kappa_score": 0.0036769066540149886, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.07404807302726604, "spearman": 0.07404807302726624, "kendall": 0.07404807302726624}, "p_value": {"pearson": 0.2854660288758281, "spearman": 0.285466028875828, "kendall": 0.28439405096943826}, "kappa_score": 0.05892270831484614, "total_responses": 210, "valid_responses": 209, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 210, "valid_responses": 210, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}