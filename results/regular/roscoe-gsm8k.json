{"Meta-Llama-3.1-8B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.8410436879780716, "spearman": 0.8604207813366178, "kendall": 0.7902569723805399}, "p_value": {"pearson": 9.889904692907104e-55, "spearman": 7.020246819877057e-60, "kendall": 1.8176795201320508e-35}, "kappa_score": 0.29284088920007, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.5617662073967618, "spearman": 0.6521197786003494, "kendall": 0.5814262488276529}, "p_value": {"pearson": 4.963416547369684e-18, "spearman": 1.3289236066489898e-25, "kendall": 2.84094614208125e-20}, "kappa_score": 0.2871054275530077, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.6390644422470536, "spearman": 0.6390644422470537, "kendall": 0.6390644422470537}, "p_value": {"pearson": 2.371195911456015e-24, "spearman": 2.3711959114558936e-24, "kendall": 1.9666695831283725e-19}, "kappa_score": 0.5799522673031026, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.14572821411885215, "spearman": 0.14572821411885215, "kendall": 0.14572821411885212}, "p_value": {"pearson": 0.039494720542132204, "spearman": 0.03949472054213201, "kendall": 0.03980667361271937}, "kappa_score": 0.1454689984101749, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Meta-Llama-3.1-70B-Instruct (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.9055343760520413, "spearman": 0.9062778604506405, "kendall": 0.819641219813901}, "p_value": {"pearson": 1.1734017216415187e-75, "spearman": 5.573629595592356e-76, "kendall": 4.075154627342999e-39}, "kappa_score": 0.534130838169687, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6412788699870737, "spearman": 0.7484998659214975, "kendall": 0.6873001681054796}, "p_value": {"pearson": 1.4687602165923613e-24, "spearman": 3.58391580999737e-37, "kendall": 2.5922159747957415e-27}, "kappa_score": 0.40067424147833686, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.8340076771449321, "spearman": 0.8340076771449321, "kendall": 0.8340076771449321}, "p_value": {"pearson": 4.970153199897586e-53, "spearman": 4.970153199897539e-53, "kendall": 5.903806458914992e-32}, "kappa_score": 0.8340076771449321, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.5413083018299851, "spearman": 0.541308301829985, "kendall": 0.541308301829985}, "p_value": {"pearson": 1.276886218873438e-16, "spearman": 1.27688621887344e-16, "kendall": 2.2391209382276122e-14}, "kappa_score": 0.45322714846071555, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mistral-7B-Instruct-v0.3 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.7269919650801239, "spearman": 0.7598093889553611, "kendall": 0.6836957089781885}, "p_value": {"pearson": 3.653609410956272e-34, "spearman": 7.029473335524136e-39, "kendall": 1.5438867497659642e-27}, "kappa_score": 0.3993993993993994, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.4493585991387851, "spearman": 0.5007980064258137, "kendall": 0.457036945552651}, "p_value": {"pearson": 2.4813833075871522e-11, "spearman": 4.289339299980006e-14, "kendall": 7.011552068551601e-13}, "kappa_score": 0.29567131327953045, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.7073788041866459, "spearman": 0.7073788041866457, "kendall": 0.7073788041866458}, "p_value": {"pearson": 1.1646516165708786e-31, "spearman": 1.1646516165709785e-31, "kendall": 1.8872399227733957e-23}, "kappa_score": 0.7048592811215347, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.24522001683979885, "spearman": 0.2452200168397989, "kendall": 0.24522001683979888}, "p_value": {"pearson": 0.00046563038696663904, "spearman": 0.00046563038696663747, "kendall": 0.0005416737592306604}, "kappa_score": 0.22611850060459493, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "OLMo-7B-0724-Instruct-hf (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.12174282202146303, "spearman": 0.15167045106896895, "kendall": 0.1404976458406194}, "p_value": {"pearson": 0.08592339332953378, "spearman": 0.03203945185011534, "kendall": 0.032532581234417365}, "kappa_score": 0.06298299845440491, "total_responses": 200, "valid_responses": 190, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.08195533175965215, "spearman": 0.05606138902368785, "kendall": 0.051472236624634536}, "p_value": {"pearson": 0.24862299035344565, "spearman": 0.43041679549112877, "kendall": 0.42100034656276075}, "kappa_score": 0.029028016587438144, "total_responses": 200, "valid_responses": 174, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.09374263735183337, "spearman": -0.09374263735183334, "kendall": -0.09374263735183336}, "p_value": {"pearson": 0.186727958846393, "spearman": 0.1867279588463922, "kendall": 0.18603411184574326}, "kappa_score": -0.026641778381130132, "total_responses": 200, "valid_responses": 192, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.007444168734491309, "spearman": 0.007444168734491313, "kendall": 0.007444168734491315}, "p_value": {"pearson": 0.9166789195891671, "spearman": 0.9166789195891656, "kendall": 0.916365554407796}, "kappa_score": 0.007444168734491274, "total_responses": 200, "valid_responses": 128, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Starling-LM-7B-alpha (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.4992031693174425, "spearman": 0.5511711537623882, "kendall": 0.4827664541175495}, "p_value": {"pearson": 5.3106939677299896e-14, "spearman": 2.7430733918888242e-17, "kendall": 3.683072180280498e-15}, "kappa_score": 0.13957347427939282, "total_responses": 200, "valid_responses": 164, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.28240931720645096, "spearman": 0.3692645729897204, "kendall": 0.3159283741699934}, "p_value": {"pearson": 5.086422021058133e-05, "spearman": 7.413665649737652e-08, "kendall": 2.5526619803201584e-07}, "kappa_score": 0.16714531878230898, "total_responses": 200, "valid_responses": 170, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": -0.04157104827821218, "spearman": -0.0415710482782121, "kendall": -0.0415710482782121}, "p_value": {"pearson": 0.5589033795498658, "spearman": 0.5589033795498666, "kendall": 0.5575853781070612}, "kappa_score": -0.025641025641025772, "total_responses": 200, "valid_responses": 181, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": -0.061184223767363, "spearman": -0.06118422376736287, "kendall": -0.06118422376736288}, "p_value": {"pearson": 0.38942605590542295, "spearman": 0.389426055905424, "kendall": 0.3880771602984373}, "kappa_score": -0.03672985781990534, "total_responses": 200, "valid_responses": 185, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-v01 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.766986203541736, "spearman": 0.7556185872218133, "kendall": 0.6807058722006806}, "p_value": {"pearson": 5.1716521698244716e-40, "spearman": 3.0936802724865697e-38, "kendall": 2.5537491261658964e-27}, "kappa_score": 0.439980521061602, "total_responses": 200, "valid_responses": 196, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.523997838741509, "spearman": 0.6456578815727291, "kendall": 0.576194552292143}, "p_value": {"pearson": 1.68617687117863e-15, "spearman": 5.630419907774214e-25, "kendall": 1.0286445202022689e-19}, "kappa_score": 0.3319792371925073, "total_responses": 200, "valid_responses": 196, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.3000011027488335, "spearman": 0.30000110274883357, "kendall": 0.30000110274883357}, "p_value": {"pearson": 1.5895891329928894e-05, "spearman": 1.5895891329928827e-05, "kendall": 2.31584968252975e-05}, "kappa_score": 0.23371647509578541, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.19933829611249032, "spearman": 0.19933829611248968, "kendall": 0.19933829611248965}, "p_value": {"pearson": 0.004656901171562164, "spearman": 0.004656901171562259, "kendall": 0.00492325572756702}, "kappa_score": 0.19419822723609992, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-3.5-turbo-0125 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.8307969210754071, "spearman": 0.890267656604331, "kendall": 0.7944721687300352}, "p_value": {"pearson": 2.7950531072315902e-52, "spearman": 1.4856271551800248e-69, "kendall": 7.977138811683073e-38}, "kappa_score": 0.38844762650557485, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6479898019389928, "spearman": 0.7223787960623389, "kendall": 0.639872385118881}, "p_value": {"pearson": 3.357432152170889e-25, "spearman": 1.4820929320885604e-33, "kendall": 4.663235601508433e-25}, "kappa_score": 0.3122977346278317, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.8046575696136516, "spearman": 0.8046575696136523, "kendall": 0.8046575696136522}, "p_value": {"pearson": 1.0428494285434286e-46, "spearman": 1.0428494285430951e-46, "kendall": 7.324229487624316e-30}, "kappa_score": 0.79, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.3701192852934699, "spearman": 0.3701192852934691, "kendall": 0.37011928529346905}, "p_value": {"pearson": 6.880504637302135e-08, "spearman": 6.880504637302461e-08, "kendall": 1.7779139249807795e-07}, "kappa_score": 0.3358633776091081, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gpt-4o (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.9476958814998373, "spearman": 0.9077984898569298, "kendall": 0.8338150575451361}, "p_value": {"pearson": 3.7479210974556607e-100, "spearman": 1.1923131780597674e-76, "kendall": 5.18115440534255e-38}, "kappa_score": 0.5422799195043997, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6518334601000724, "spearman": 0.7330564612736212, "kendall": 0.6630284374017168}, "p_value": {"pearson": 1.4177726774551445e-25, "spearman": 5.546922830841961e-35, "kendall": 2.0340674949082026e-26}, "kappa_score": 0.4297387011660566, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.8501621658374563, "spearman": 0.8501621658374553, "kendall": 0.8501621658374553}, "p_value": {"pearson": 4.602834471939192e-57, "spearman": 4.602834471942e-57, "kendall": 3.8658201375813224e-33}, "kappa_score": 0.8390827717992557, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.4548063298630485, "spearman": 0.4548063298630472, "kendall": 0.4548063298630472}, "p_value": {"pearson": 1.3289570311413387e-11, "spearman": 1.3289570311415412e-11, "kendall": 1.4005507948599977e-10}, "kappa_score": 0.3427915710411017, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x7B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.904455756888533, "spearman": 0.8827340034149274, "kendall": 0.8082274821111901}, "p_value": {"pearson": 3.417872911203387e-75, "spearman": 7.223731362545711e-67, "kendall": 2.123461738076903e-37}, "kappa_score": 0.5770294452578493, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6404054464868748, "spearman": 0.7028832487725563, "kendall": 0.6329985297515542}, "p_value": {"pearson": 1.7750106228145145e-24, "spearman": 4.083839404467303e-31, "kendall": 1.4706510069870806e-23}, "kappa_score": 0.34757788289022995, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.8375343041752271, "spearman": 0.8375343041752273, "kendall": 0.8375343041752273}, "p_value": {"pearson": 7.142546501939816e-54, "spearman": 7.142546501938589e-54, "kendall": 3.2703377486994925e-32}, "kappa_score": 0.8359479134625244, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.42270338747237013, "spearman": 0.4227033874723689, "kendall": 0.42270338747236885}, "p_value": {"pearson": 4.512094484760169e-10, "spearman": 4.512094484760636e-10, "kendall": 2.477013661470428e-09}, "kappa_score": 0.32907693972513796, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "gemini-1.5-flash-latest (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.8700773160516103, "spearman": 0.8984459823648383, "kendall": 0.8196895971388182}, "p_value": {"pearson": 9.5877596940302e-63, "spearman": 1.0555773414679824e-72, "kendall": 5.815831683243859e-40}, "kappa_score": 0.5113198182720574, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6551312241903756, "spearman": 0.7253240250578205, "kendall": 0.6576378264235574}, "p_value": {"pearson": 6.699359725088655e-26, "spearman": 6.081845938895506e-34, "kendall": 7.478658656028145e-26}, "kappa_score": 0.4025580612588354, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.7926618847951377, "spearman": 0.7926618847951384, "kendall": 0.7926618847951383}, "p_value": {"pearson": 1.9965095855368912e-44, "spearman": 1.996509585536254e-44, "kendall": 5.0023542789831584e-29}, "kappa_score": 0.7717348154029376, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.47333193408511776, "spearman": 0.473331934085117, "kendall": 0.473331934085117}, "p_value": {"pearson": 1.460802338811011e-12, "spearman": 1.460802338811124e-12, "kendall": 2.436026085671428e-11}, "kappa_score": 0.4337016574585636, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "Mixtral-8x22B-Instruct-v0.1 (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.9486374325128681, "spearman": 0.910872159818836, "kendall": 0.8424056135907645}, "p_value": {"pearson": 6.503041088754916e-101, "spearman": 4.857508957244187e-78, "kendall": 1.0087027092703823e-37}, "kappa_score": 0.5320617044057581, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.6334377237281925, "spearman": 0.7061176010977178, "kendall": 0.6369934726926337}, "p_value": {"pearson": 7.869681112803152e-24, "spearman": 1.6599550964842276e-31, "kendall": 7.002201725714371e-23}, "kappa_score": 0.337369109947644, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": 0.8938959977561863, "spearman": 0.8938959977561877, "kendall": 0.8938959977561879}, "p_value": {"pearson": 6.411048046512444e-71, "spearman": 6.411048046504221e-71, "kendall": 1.8609963885484852e-36}, "kappa_score": 0.8883021933387489, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": 0.4457211433454277, "spearman": 0.4457211433454262, "kendall": 0.44572114334542623}, "p_value": {"pearson": 3.7420342629267094e-11, "spearman": 3.742034262927402e-11, "kendall": 3.2226501593241576e-10}, "kappa_score": 0.3447905477980665, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}, "c4ai-command-r-plus (SP: None, AP: 1)": {"Overall Quality": {"corr_coeff": {"pearson": 0.8340055469053971, "spearman": 0.8229891895031772, "kendall": 0.7529470497911052}, "p_value": {"pearson": 4.97591207972929e-53, "spearman": 1.607833096128975e-50, "kendall": 4.3122932632016565e-31}, "kappa_score": 0.3225362548957341, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Coherency": {"corr_coeff": {"pearson": 0.46593868823467954, "spearman": 0.5391240225557398, "kendall": 0.4723799724905456}, "p_value": {"pearson": 3.582670503501351e-12, "spearman": 1.7829252789542077e-16, "kendall": 3.6624068556697367e-14}, "kappa_score": 0.2566877680212376, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "graded", "expert": "true", "task": "Reasoning"}, "Missing Steps": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}, "Contradiction": {"corr_coeff": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "p_value": {"pearson": NaN, "spearman": NaN, "kendall": NaN}, "kappa_score": 0.0, "total_responses": 200, "valid_responses": 200, "krippendorff_alpha": NaN, "type": "categorical", "expert": "true", "task": "Reasoning"}}}